# Generated by the protocol buffer compiler.  DO NOT EDIT!
# sources: waymo_open_dataset/dataset.proto, waymo_open_dataset/label.proto, waymo_open_dataset/protos/box.proto, waymo_open_dataset/protos/breakdown.proto, waymo_open_dataset/protos/camera_segmentation.proto, waymo_open_dataset/protos/camera_segmentation_metrics.proto, waymo_open_dataset/protos/camera_segmentation_submission.proto, waymo_open_dataset/protos/camera_tokens.proto, waymo_open_dataset/protos/compressed_lidar.proto, waymo_open_dataset/protos/conversion_config.proto, waymo_open_dataset/protos/map.proto, waymo_open_dataset/protos/metrics.proto, waymo_open_dataset/protos/motion_metrics.proto, waymo_open_dataset/protos/motion_submission.proto, waymo_open_dataset/protos/occupancy_flow_metrics.proto, waymo_open_dataset/protos/scenario.proto, waymo_open_dataset/protos/segmentation.proto, waymo_open_dataset/protos/segmentation_metrics.proto, waymo_open_dataset/protos/segmentation_submission.proto, waymo_open_dataset/protos/sim_agents_metrics.proto, waymo_open_dataset/protos/sim_agents_submission.proto, waymo_open_dataset/protos/submission.proto, waymo_open_dataset/protos/vector.proto
# plugin: python-betterproto2
# This file has been @generated

__all__ = (
    "BreakdownGeneratorId",
    "CameraCalibrationRollingShutterReadOutDirection",
    "CameraNameName",
    "CameraSegmentationType",
    "ConfigLongitudinalErrorTolerantConfigAlignType",
    "LabelBoxType",
    "LabelDifficultyLevel",
    "LabelType",
    "LaneCenterLaneType",
    "LaserNameName",
    "MatcherProtoType",
    "MotionChallengeSubmissionSubmissionType",
    "RequiredPredictionDifficultyLevel",
    "RoadEdgeRoadEdgeType",
    "RoadLineRoadLineType",
    "SegmentationType",
    "SemanticSegmentationSubmissionSensorType",
    "SimAgentsChallengeSubmissionSubmissionType",
    "SubmissionSensorType",
    "SubmissionTask",
    "TrackObjectType",
    "TrafficSignalLaneStateState",
    "BoundarySegment",
    "Box2D",
    "Box3D",
    "Breakdown",
    "CameraCalibration",
    "CameraImage",
    "CameraLabels",
    "CameraName",
    "CameraSegmentation",
    "CameraSegmentationFrame",
    "CameraSegmentationFrameList",
    "CameraSegmentationLabel",
    "CameraSegmentationLabelInstanceIdToGlobalIdMapping",
    "CameraSegmentationMetrics",
    "CameraSegmentationSubmission",
    "CameraTokens",
    "ChallengeScenarioPredictions",
    "CompressedFrameLaserData",
    "CompressedLaser",
    "CompressedRangeImage",
    "Config",
    "ConfigLongitudinalErrorTolerantConfig",
    "ConfigLongitudinalErrorTolerantConfigLocation3D",
    "Context",
    "ContextStats",
    "ContextStatsObjectCount",
    "Crosswalk",
    "DeltaEncodedData",
    "DetectionMeasurement",
    "DetectionMeasurementDetails",
    "DetectionMeasurements",
    "DetectionMetrics",
    "Difficulty",
    "Driveway",
    "DynamicMapState",
    "DynamicState",
    "Frame",
    "FrameCameraTokens",
    "JointPrediction",
    "JointScene",
    "JointTrajectories",
    "Label",
    "LabelAssociation",
    "LabelBox",
    "LabelMetadata",
    "LaneCenter",
    "LaneNeighbor",
    "Laser",
    "LaserCalibration",
    "LaserName",
    "Map",
    "MapFeature",
    "MapPoint",
    "MatcherProto",
    "MatrixFloat",
    "MatrixInt32",
    "MatrixShape",
    "Metadata",
    "MotionChallengeSubmission",
    "MotionExampleConversionConfig",
    "MotionMetrics",
    "MotionMetricsBundle",
    "MotionMetricsConfig",
    "MotionMetricsConfigMeasurementStepConfig",
    "MultimodalPrediction",
    "NoLabelZoneObject",
    "Object",
    "Objects",
    "ObjectState",
    "ObjectTrajectory",
    "OccupancyFlowMetrics",
    "OccupancyFlowTaskConfig",
    "Polygon2DProto",
    "PredictionSet",
    "RangeImage",
    "RequiredPrediction",
    "RoadEdge",
    "RoadLine",
    "Scenario",
    "ScenarioPredictions",
    "ScenarioRollouts",
    "ScoredJointTrajectory",
    "ScoredTrajectory",
    "Segmentation",
    "SegmentationFrame",
    "SegmentationFrameList",
    "SegmentationMeasurements",
    "SegmentationMetrics",
    "SegmentationMetricsConfig",
    "SemanticSegmentationSubmission",
    "SimAgentMetrics",
    "SimAgentMetricsConfig",
    "SimAgentMetricsConfigBernoulliEstimate",
    "SimAgentMetricsConfigFeatureConfig",
    "SimAgentMetricsConfigHistogramEstimate",
    "SimAgentMetricsConfigKernelDensityEstimate",
    "SimAgentsBucketedMetrics",
    "SimAgentsChallengeSubmission",
    "SimulatedTrajectory",
    "SingleObjectPrediction",
    "SingleTrajectory",
    "SpeedBump",
    "StopSign",
    "Submission",
    "Track",
    "TrackingMeasurement",
    "TrackingMeasurementDetails",
    "TrackingMeasurements",
    "TrackingMetrics",
    "TrafficSignalLaneState",
    "Trajectory",
    "Transform",
    "Vector2D",
    "Vector3D",
    "Velocity",
)

import warnings
from dataclasses import dataclass

import betterproto2

from ...message_pool import default_message_pool

betterproto2.check_compiler_version("0.3.1")


class BreakdownGeneratorId(betterproto2.Enum):
    @staticmethod
    def _serialized_pb():
        return b"\n\x15Breakdown.GeneratorId\x12\t\n\x07UNKNOWN\x12\r\n\tONE_SHARD\x10\x01\x12\x0f\n\x0bOBJECT_TYPE\x10\x02\x12\t\n\x05RANGE\x10\x03\x12\x0f\n\x0bTIME_OF_DAY\x10\x04\x12\x0c\n\x08LOCATION\x10\x05\x12\x0b\n\x07WEATHER\x10\x06\x12\x0c\n\x08VELOCITY\x10\x07\x12\x10\n\x0cALL_BUT_SIGN\x10\x08\x12\x08\n\x04SIZE\x10\t\x12\n\n\x06CAMERA\x10\n"

    UNKNOWN = 0

    ONE_SHARD = 1
    """
    Everything is in one shard.
    """

    OBJECT_TYPE = 2
    """
    Shard by object types.
    """

    RANGE = 3
    """
    Shard by box center distance.
    """

    TIME_OF_DAY = 4
    """
    Shard by time of the day at which the scene is.
    """

    LOCATION = 5
    """
    Shard by location of the scene.
    """

    WEATHER = 6
    """
    Shard by the weather of the scene.
    """

    VELOCITY = 7
    """
    Shard by object velocity.
    """

    ALL_BUT_SIGN = 8
    """
    All types except SIGN.
    This is NOT the same as ALL_NS in the leaderboard!!
    ALL_NS in the leaderboard is the mean of VEHICLE, PED, CYCLIST metrics.
    """

    SIZE = 9
    """
    Shard by the object size (the max of length, width, height).
    """

    CAMERA = 10
    """
    Shard by the corresponding camera.
    """


class CameraCalibrationRollingShutterReadOutDirection(betterproto2.Enum):
    @staticmethod
    def _serialized_pb():
        return b"\n0CameraCalibration.RollingShutterReadOutDirection\x12\t\n\x07UNKNOWN\x12\x11\n\rTOP_TO_BOTTOM\x10\x01\x12\x11\n\rLEFT_TO_RIGHT\x10\x02\x12\x11\n\rBOTTOM_TO_TOP\x10\x03\x12\x11\n\rRIGHT_TO_LEFT\x10\x04\x12\x12\n\x0eGLOBAL_SHUTTER\x10\x05"

    UNKNOWN = 0

    TOP_TO_BOTTOM = 1

    LEFT_TO_RIGHT = 2

    BOTTOM_TO_TOP = 3

    RIGHT_TO_LEFT = 4

    GLOBAL_SHUTTER = 5


class CameraNameName(betterproto2.Enum):
    @staticmethod
    def _serialized_pb():
        return b"\n\x0fCameraName.Name\x12\t\n\x07UNKNOWN\x12\t\n\x05FRONT\x10\x01\x12\x0e\n\nFRONT_LEFT\x10\x02\x12\x0f\n\x0bFRONT_RIGHT\x10\x03\x12\r\n\tSIDE_LEFT\x10\x04\x12\x0e\n\nSIDE_RIGHT\x10\x05\x12\r\n\tREAR_LEFT\x10\x06\x12\x08\n\x04REAR\x10\x07\x12\x0e\n\nREAR_RIGHT\x10\x08"

    UNKNOWN = 0

    FRONT = 1

    FRONT_LEFT = 2

    FRONT_RIGHT = 3

    SIDE_LEFT = 4

    SIDE_RIGHT = 5

    REAR_LEFT = 6

    REAR = 7

    REAR_RIGHT = 8


class CameraSegmentationType(betterproto2.Enum):
    @staticmethod
    def _serialized_pb():
        return b"\n\x17CameraSegmentation.Type\x12\x10\n\x0eTYPE_UNDEFINED\x12\x14\n\x10TYPE_EGO_VEHICLE\x10\x01\x12\x0c\n\x08TYPE_CAR\x10\x02\x12\x0e\n\nTYPE_TRUCK\x10\x03\x12\x0c\n\x08TYPE_BUS\x10\x04\x12\x1c\n\x18TYPE_OTHER_LARGE_VEHICLE\x10\x05\x12\x10\n\x0cTYPE_BICYCLE\x10\x06\x12\x13\n\x0fTYPE_MOTORCYCLE\x10\x07\x12\x10\n\x0cTYPE_TRAILER\x10\x08\x12\x13\n\x0fTYPE_PEDESTRIAN\x10\t\x12\x10\n\x0cTYPE_CYCLIST\x10\n\x12\x15\n\x11TYPE_MOTORCYCLIST\x10\x0b\x12\r\n\tTYPE_BIRD\x10\x0c\x12\x16\n\x12TYPE_GROUND_ANIMAL\x10\r\x12\x1f\n\x1bTYPE_CONSTRUCTION_CONE_POLE\x10\x0e\x12\r\n\tTYPE_POLE\x10\x0f\x12\x1a\n\x16TYPE_PEDESTRIAN_OBJECT\x10\x10\x12\r\n\tTYPE_SIGN\x10\x11\x12\x16\n\x12TYPE_TRAFFIC_LIGHT\x10\x12\x12\x11\n\rTYPE_BUILDING\x10\x13\x12\r\n\tTYPE_ROAD\x10\x14\x12\x14\n\x10TYPE_LANE_MARKER\x10\x15\x12\x14\n\x10TYPE_ROAD_MARKER\x10\x16\x12\x11\n\rTYPE_SIDEWALK\x10\x17\x12\x13\n\x0fTYPE_VEGETATION\x10\x18\x12\x0c\n\x08TYPE_SKY\x10\x19\x12\x0f\n\x0bTYPE_GROUND\x10\x1a\x12\x10\n\x0cTYPE_DYNAMIC\x10\x1b\x12\x0f\n\x0bTYPE_STATIC\x10\x1c"

    TYPE_UNDEFINED = 0
    """
    Anything that does not fit the other classes or is too ambiguous to
    label.
    """

    TYPE_EGO_VEHICLE = 1
    """
    The Waymo vehicle.
    """

    TYPE_CAR = 2
    """
    Small vehicle such as a sedan, SUV, pickup truck, minivan or golf cart.
    """

    TYPE_TRUCK = 3
    """
    Large vehicle that carries cargo.
    """

    TYPE_BUS = 4
    """
    Large vehicle that carries more than 8 passengers.
    """

    TYPE_OTHER_LARGE_VEHICLE = 5
    """
    Large vehicle that is not a truck or a bus.
    """

    TYPE_BICYCLE = 6
    """
    Bicycle with no rider.
    """

    TYPE_MOTORCYCLE = 7
    """
    Motorcycle with no rider.
    """

    TYPE_TRAILER = 8
    """
    Trailer attached to another vehicle or horse.
    """

    TYPE_PEDESTRIAN = 9
    """
    Pedestrian. Does not include objects associated with the pedestrian, such
    as suitcases, strollers or cars.
    """

    TYPE_CYCLIST = 10
    """
    Bicycle with rider.
    """

    TYPE_MOTORCYCLIST = 11
    """
    Motorcycle with rider.
    """

    TYPE_BIRD = 12
    """
    Birds, including ones on the ground.
    """

    TYPE_GROUND_ANIMAL = 13
    """
    Animal on the ground such as a dog, cat, cow, etc.
    """

    TYPE_CONSTRUCTION_CONE_POLE = 14
    """
    Cone or short pole related to construction.
    """

    TYPE_POLE = 15
    """
    Permanent horizontal and vertical lamp pole, traffic sign pole, etc.
    """

    TYPE_PEDESTRIAN_OBJECT = 16
    """
    Large object carried/pushed/dragged by a pedestrian.
    """

    TYPE_SIGN = 17
    """
    Sign related to traffic, including front and back facing signs.
    """

    TYPE_TRAFFIC_LIGHT = 18
    """
    The box that contains traffic lights regardless of front or back facing.
    """

    TYPE_BUILDING = 19
    """
    Permanent building and walls, including solid fences.
    """

    TYPE_ROAD = 20
    """
    Drivable road with proper markings, including parking lots and gas
    stations.
    """

    TYPE_LANE_MARKER = 21
    """
    Marking on the road that is parallel to the ego vehicle and defines
    lanes.
    """

    TYPE_ROAD_MARKER = 22
    """
    All markings on the road other than lane markers.
    """

    TYPE_SIDEWALK = 23
    """
    Paved walkable surface for pedestrians, including curbs.
    """

    TYPE_VEGETATION = 24
    """
    Vegetation including tree trunks, tree branches, bushes, tall grasses,
    flowers and so on.
    """

    TYPE_SKY = 25
    """
    The sky, including clouds.
    """

    TYPE_GROUND = 26
    """
    Other horizontal surfaces that are drivable or walkable.
    """

    TYPE_DYNAMIC = 27
    """
    Object that is not permanent in its current position and does not belong
    to any of the above classes.
    """

    TYPE_STATIC = 28
    """
    Object that is permanent in its current position and does not belong to
    any of the above classes.
    """


class ConfigLongitudinalErrorTolerantConfigAlignType(betterproto2.Enum):
    """
    Describes how a prediction box aligns with a ground truth box to minimize
    the longitudinal error.
    """

    @staticmethod
    def _serialized_pb():
        return b'\n0Config.LongitudinalErrorTolerantConfig.AlignType\x12\x0e\n\x0cTYPE_UNKNOWN\x12\x14\n\x10TYPE_NOT_ALIGNED\x10\x01\x12\x16\n\x12TYPE_RANGE_ALIGNED\x10\x02\x12\x17\n\x13TYPE_CENTER_ALIGNED\x10\x03\x12#\n\x1fTYPE_FURTHER_ONLY_RANGE_ALIGNED\x10\x04\x12&\n"TYPE_ANY_CLOSER_ONLY_RANGE_ALIGNED\x10\x05\x121\n-TYPE_BETWEEN_ORIGIN_AND_GT_ONLY_RANGE_ALIGNED\x10\x06'

    TYPE_UNKNOWN = 0

    TYPE_NOT_ALIGNED = 1
    """
    No alignment is performed.
    """

    TYPE_RANGE_ALIGNED = 2
    """
    The center of the prediction box moves along the line of sight such
    that it has the closest distance to the center of the ground truth box.
    """

    TYPE_CENTER_ALIGNED = 3
    """
    The center of the prediction box moves to the center of the ground
    truth box, which means no localization error after alignment.
    """

    TYPE_FURTHER_ONLY_RANGE_ALIGNED = 4
    """
    The center of the prediction box moves along the line of sight such
    that it has the closest distance to the center of the ground truth box.
    Same as `TYPE_RANGE_ALIGNED` except this only applies if the prediction
    is beyond the ground truth. Example: given O is sensor origin, G ground
    truth center, and P prediction center (O -> G [P]) P will only be moved
    if it is beyond G in reference to O.
    """

    TYPE_ANY_CLOSER_ONLY_RANGE_ALIGNED = 5
    """
    The center of the prediction box moves along the line of sight such
    that it has the closest distance to the center of the ground truth box.
    Same as `TYPE_RANGE_ALIGNED` except this only applies if the prediction
    is before the ground truth in references to the sensor origin. Example:
    given O is sensor origin, G ground truth center, and P(1/2) the
    prediction center ([P1] O -> [P2] -> G ) P will only be moved if it is
    before G in reference to O.
    """

    TYPE_BETWEEN_ORIGIN_AND_GT_ONLY_RANGE_ALIGNED = 6
    """
    The center of the prediction box moves along the line of sight such
    that it has the closest distance to the center of the ground truth box.
    Same as `TYPE_RANGE_ALIGNED` except this only applies if the prediction
    is between the sensor origin and ground truth. Example: given O is
    sensor origin, G ground truth center, and P prediction center (O -> [P]
    -> G ) P will only be moved if it is between G and O.
    """


class LabelBoxType(betterproto2.Enum):
    @staticmethod
    def _serialized_pb():
        return b"\n\x0eLabel.Box.Type\x12\x0e\n\x0cTYPE_UNKNOWN\x12\x0b\n\x07TYPE_3D\x10\x01\x12\x0b\n\x07TYPE_2D\x10\x02\x12\x0e\n\nTYPE_AA_2D\x10\x03"

    TYPE_UNKNOWN = 0

    TYPE_3D = 1
    """
    7-DOF 3D (a.k.a upright 3D box).
    """

    TYPE_2D = 2
    """
    5-DOF 2D. Mostly used for laser top down representation.
    """

    TYPE_AA_2D = 3
    """
    Axis aligned 2D. Mostly used for image.
    """


class LabelDifficultyLevel(betterproto2.Enum):
    """
    The difficulty level of this label. The higher the level, the harder it is.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x15Label.DifficultyLevel\x12\t\n\x07UNKNOWN\x12\x0b\n\x07LEVEL_1\x10\x01\x12\x0b\n\x07LEVEL_2\x10\x02"

    UNKNOWN = 0

    LEVEL_1 = 1

    LEVEL_2 = 2


class LabelType(betterproto2.Enum):
    @staticmethod
    def _serialized_pb():
        return b"\n\nLabel.Type\x12\x0e\n\x0cTYPE_UNKNOWN\x12\x10\n\x0cTYPE_VEHICLE\x10\x01\x12\x13\n\x0fTYPE_PEDESTRIAN\x10\x02\x12\r\n\tTYPE_SIGN\x10\x03\x12\x10\n\x0cTYPE_CYCLIST\x10\x04"

    TYPE_UNKNOWN = 0

    TYPE_VEHICLE = 1

    TYPE_PEDESTRIAN = 2

    TYPE_SIGN = 3

    TYPE_CYCLIST = 4


class LaneCenterLaneType(betterproto2.Enum):
    """
    Type of this lane.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x13LaneCenter.LaneType\x12\x10\n\x0eTYPE_UNDEFINED\x12\x10\n\x0cTYPE_FREEWAY\x10\x01\x12\x17\n\x13TYPE_SURFACE_STREET\x10\x02\x12\x12\n\x0eTYPE_BIKE_LANE\x10\x03"

    TYPE_UNDEFINED = 0

    TYPE_FREEWAY = 1

    TYPE_SURFACE_STREET = 2

    TYPE_BIKE_LANE = 3


class LaserNameName(betterproto2.Enum):
    @staticmethod
    def _serialized_pb():
        return b"\n\x0eLaserName.Name\x12\t\n\x07UNKNOWN\x12\x07\n\x03TOP\x10\x01\x12\t\n\x05FRONT\x10\x02\x12\r\n\tSIDE_LEFT\x10\x03\x12\x0e\n\nSIDE_RIGHT\x10\x04\x12\x08\n\x04REAR\x10\x05"

    UNKNOWN = 0

    TOP = 1

    FRONT = 2

    SIDE_LEFT = 3

    SIDE_RIGHT = 4

    REAR = 5


class MatcherProtoType(betterproto2.Enum):
    @staticmethod
    def _serialized_pb():
        return b"\n\x11MatcherProto.Type\x12\x0e\n\x0cTYPE_UNKNOWN\x12\x12\n\x0eTYPE_HUNGARIAN\x10\x01\x12\x14\n\x10TYPE_SCORE_FIRST\x10\x02\x12\x1c\n\x18TYPE_HUNGARIAN_TEST_ONLY\x10d"

    TYPE_UNKNOWN = 0

    TYPE_HUNGARIAN = 1
    """
    The Hungarian algorithm based matching that maximizes the sum of IoUs of
    all matched pairs. Detection scores have no effect on this matcher.
    https://en.wikipedia.org/wiki/Hungarian_algorithm
    """

    TYPE_SCORE_FIRST = 2
    """
    A COCO-style matcher: matches detections (ordered by scores) one by one
    to the groundtruth of largest IoUs.
    """

    TYPE_HUNGARIAN_TEST_ONLY = 100
    """
    TEST ONLY.
    """


class MotionChallengeSubmissionSubmissionType(betterproto2.Enum):
    @staticmethod
    def _serialized_pb():
        return b"\n(MotionChallengeSubmission.SubmissionType\x12\t\n\x07UNKNOWN\x12\x15\n\x11MOTION_PREDICTION\x10\x01\x12\x1a\n\x16INTERACTION_PREDICTION\x10\x02"

    UNKNOWN = 0

    MOTION_PREDICTION = 1
    """
    A submission for the Waymo open dataset motion prediction challenge.
    """

    INTERACTION_PREDICTION = 2
    """
    A submission for the Waymo open dataset interaction prediction challenge.
    """


class RequiredPredictionDifficultyLevel(betterproto2.Enum):
    """
    A difficulty level for predicting a given track.
    """

    @staticmethod
    def _serialized_pb():
        return b'\n"RequiredPrediction.DifficultyLevel\x12\x06\n\x04NONE\x12\x0b\n\x07LEVEL_1\x10\x01\x12\x0b\n\x07LEVEL_2\x10\x02'

    NONE = 0

    LEVEL_1 = 1

    LEVEL_2 = 2


class RoadEdgeRoadEdgeType(betterproto2.Enum):
    """
    Type of this road edge.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x15RoadEdge.RoadEdgeType\x12\x0e\n\x0cTYPE_UNKNOWN\x12\x1b\n\x17TYPE_ROAD_EDGE_BOUNDARY\x10\x01\x12\x19\n\x15TYPE_ROAD_EDGE_MEDIAN\x10\x02"

    TYPE_UNKNOWN = 0

    TYPE_ROAD_EDGE_BOUNDARY = 1
    """
    Physical road boundary that doesn't have traffic on the other side (e.g.,
    a curb or the k-rail on the right side of a freeway).
    """

    TYPE_ROAD_EDGE_MEDIAN = 2
    """
    Physical road boundary that separates the car from other traffic
    (e.g. a k-rail or an island).
    """


class RoadLineRoadLineType(betterproto2.Enum):
    """
    Type of this road line.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x15RoadLine.RoadLineType\x12\x0e\n\x0cTYPE_UNKNOWN\x12\x1c\n\x18TYPE_BROKEN_SINGLE_WHITE\x10\x01\x12\x1b\n\x17TYPE_SOLID_SINGLE_WHITE\x10\x02\x12\x1b\n\x17TYPE_SOLID_DOUBLE_WHITE\x10\x03\x12\x1d\n\x19TYPE_BROKEN_SINGLE_YELLOW\x10\x04\x12\x1d\n\x19TYPE_BROKEN_DOUBLE_YELLOW\x10\x05\x12\x1c\n\x18TYPE_SOLID_SINGLE_YELLOW\x10\x06\x12\x1c\n\x18TYPE_SOLID_DOUBLE_YELLOW\x10\x07\x12\x1e\n\x1aTYPE_PASSING_DOUBLE_YELLOW\x10\x08"

    TYPE_UNKNOWN = 0

    TYPE_BROKEN_SINGLE_WHITE = 1

    TYPE_SOLID_SINGLE_WHITE = 2

    TYPE_SOLID_DOUBLE_WHITE = 3

    TYPE_BROKEN_SINGLE_YELLOW = 4

    TYPE_BROKEN_DOUBLE_YELLOW = 5

    TYPE_SOLID_SINGLE_YELLOW = 6

    TYPE_SOLID_DOUBLE_YELLOW = 7

    TYPE_PASSING_DOUBLE_YELLOW = 8


class SegmentationType(betterproto2.Enum):
    @staticmethod
    def _serialized_pb():
        return b"\n\x11Segmentation.Type\x12\x10\n\x0eTYPE_UNDEFINED\x12\x0c\n\x08TYPE_CAR\x10\x01\x12\x0e\n\nTYPE_TRUCK\x10\x02\x12\x0c\n\x08TYPE_BUS\x10\x03\x12\x16\n\x12TYPE_OTHER_VEHICLE\x10\x04\x12\x15\n\x11TYPE_MOTORCYCLIST\x10\x05\x12\x12\n\x0eTYPE_BICYCLIST\x10\x06\x12\x13\n\x0fTYPE_PEDESTRIAN\x10\x07\x12\r\n\tTYPE_SIGN\x10\x08\x12\x16\n\x12TYPE_TRAFFIC_LIGHT\x10\t\x12\r\n\tTYPE_POLE\x10\n\x12\x1a\n\x16TYPE_CONSTRUCTION_CONE\x10\x0b\x12\x10\n\x0cTYPE_BICYCLE\x10\x0c\x12\x13\n\x0fTYPE_MOTORCYCLE\x10\r\x12\x11\n\rTYPE_BUILDING\x10\x0e\x12\x13\n\x0fTYPE_VEGETATION\x10\x0f\x12\x13\n\x0fTYPE_TREE_TRUNK\x10\x10\x12\r\n\tTYPE_CURB\x10\x11\x12\r\n\tTYPE_ROAD\x10\x12\x12\x14\n\x10TYPE_LANE_MARKER\x10\x13\x12\x15\n\x11TYPE_OTHER_GROUND\x10\x14\x12\x11\n\rTYPE_WALKABLE\x10\x15\x12\x11\n\rTYPE_SIDEWALK\x10\x16"

    TYPE_UNDEFINED = 0

    TYPE_CAR = 1

    TYPE_TRUCK = 2

    TYPE_BUS = 3

    TYPE_OTHER_VEHICLE = 4
    """
    Other small vehicles (e.g. pedicab) and large vehicles (e.g. construction
    vehicles, RV, limo, tram).
    """

    TYPE_MOTORCYCLIST = 5

    TYPE_BICYCLIST = 6

    TYPE_PEDESTRIAN = 7

    TYPE_SIGN = 8

    TYPE_TRAFFIC_LIGHT = 9

    TYPE_POLE = 10
    """
    Lamp post, traffic sign pole etc.
    """

    TYPE_CONSTRUCTION_CONE = 11
    """
    Construction cone/pole.
    """

    TYPE_BICYCLE = 12

    TYPE_MOTORCYCLE = 13

    TYPE_BUILDING = 14

    TYPE_VEGETATION = 15
    """
    Bushes, tree branches, tall grasses, flowers etc.
    """

    TYPE_TREE_TRUNK = 16

    TYPE_CURB = 17
    """
    Curb on the edge of roads. This does not include road boundaries if
    there’s no curb.
    """

    TYPE_ROAD = 18
    """
    Surface a vehicle could drive on. This include the driveway connecting
    parking lot and road over a section of sidewalk.
    """

    TYPE_LANE_MARKER = 19
    """
    Marking on the road that’s specifically for defining lanes such as
    single/double white/yellow lines.
    """

    TYPE_OTHER_GROUND = 20
    """
    Marking on the road other than lane markers, bumps, cateyes, railtracks
    etc.
    """

    TYPE_WALKABLE = 21
    """
    Most horizontal surface that’s not drivable, e.g. grassy hill,
    pedestrian walkway stairs etc.
    """

    TYPE_SIDEWALK = 22
    """
    Nicely paved walkable surface when pedestrians most likely to walk on.
    """


class SemanticSegmentationSubmissionSensorType(betterproto2.Enum):
    @staticmethod
    def _serialized_pb():
        return b"\n)SemanticSegmentationSubmission.SensorType\x12\t\n\x07INVALID\x12\r\n\tLIDAR_ALL\x10\x01\x12\r\n\tLIDAR_TOP\x10\x02\x12\x0e\n\nCAMERA_ALL\x10\x03\x12\x14\n\x10CAMERA_LIDAR_TOP\x10\x04\x12\x14\n\x10CAMERA_LIDAR_ALL\x10\x05"

    INVALID = 0

    LIDAR_ALL = 1

    LIDAR_TOP = 2

    CAMERA_ALL = 3

    CAMERA_LIDAR_TOP = 4

    CAMERA_LIDAR_ALL = 5


class SimAgentsChallengeSubmissionSubmissionType(betterproto2.Enum):
    """
    The challenge submission type.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n+SimAgentsChallengeSubmission.SubmissionType\x12\t\n\x07UNKNOWN\x12\x19\n\x15SIM_AGENTS_SUBMISSION\x10\x01"

    UNKNOWN = 0

    SIM_AGENTS_SUBMISSION = 1
    """
    A submission for the Waymo open dataset Sim Agents challenge.
    """


class SubmissionSensorType(betterproto2.Enum):
    @staticmethod
    def _serialized_pb():
        return b"\n\x15Submission.SensorType\x12\t\n\x07INVALID\x12\r\n\tLIDAR_ALL\x10\x01\x12\r\n\tLIDAR_TOP\x10\x02\x12\x0e\n\nCAMERA_ALL\x10\x03\x12\x14\n\x10CAMERA_LIDAR_TOP\x10\x04\x12\x14\n\x10CAMERA_LIDAR_ALL\x10\x05"

    INVALID = 0

    LIDAR_ALL = 1

    LIDAR_TOP = 2

    CAMERA_ALL = 3

    CAMERA_LIDAR_TOP = 4

    CAMERA_LIDAR_ALL = 5


class SubmissionTask(betterproto2.Enum):
    """
    These values correspond to the tasks on the waymo.com/open site.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x0fSubmission.Task\x12\t\n\x07UNKNOWN\x12\x10\n\x0cDETECTION_2D\x10\x01\x12\x10\n\x0cDETECTION_3D\x10\x02\x12\x0f\n\x0bTRACKING_2D\x10\x03\x12\x0f\n\x0bTRACKING_3D\x10\x04\x12\x15\n\x11DOMAIN_ADAPTATION\x10\x05\x12\x1c\n\x18CAMERA_ONLY_DETECTION_3D\x10\x06"

    UNKNOWN = 0

    DETECTION_2D = 1

    DETECTION_3D = 2

    TRACKING_2D = 3

    TRACKING_3D = 4

    DOMAIN_ADAPTATION = 5

    CAMERA_ONLY_DETECTION_3D = 6


class TrackObjectType(betterproto2.Enum):
    @staticmethod
    def _serialized_pb():
        return b"\n\x10Track.ObjectType\x12\x0c\n\nTYPE_UNSET\x12\x10\n\x0cTYPE_VEHICLE\x10\x01\x12\x13\n\x0fTYPE_PEDESTRIAN\x10\x02\x12\x10\n\x0cTYPE_CYCLIST\x10\x03\x12\x0e\n\nTYPE_OTHER\x10\x04"

    TYPE_UNSET = 0
    """
    This is an invalid state that indicates an error.
    """

    TYPE_VEHICLE = 1

    TYPE_PEDESTRIAN = 2

    TYPE_CYCLIST = 3

    TYPE_OTHER = 4


class TrafficSignalLaneStateState(betterproto2.Enum):
    @staticmethod
    def _serialized_pb():
        return b"\n\x1cTrafficSignalLaneState.State\x12\x14\n\x12LANE_STATE_UNKNOWN\x12\x19\n\x15LANE_STATE_ARROW_STOP\x10\x01\x12\x1c\n\x18LANE_STATE_ARROW_CAUTION\x10\x02\x12\x17\n\x13LANE_STATE_ARROW_GO\x10\x03\x12\x13\n\x0fLANE_STATE_STOP\x10\x04\x12\x16\n\x12LANE_STATE_CAUTION\x10\x05\x12\x11\n\rLANE_STATE_GO\x10\x06\x12\x1c\n\x18LANE_STATE_FLASHING_STOP\x10\x07\x12\x1f\n\x1bLANE_STATE_FLASHING_CAUTION\x10\x08"

    LANE_STATE_UNKNOWN = 0

    LANE_STATE_ARROW_STOP = 1
    """
    States for traffic signals with arrows.
    """

    LANE_STATE_ARROW_CAUTION = 2

    LANE_STATE_ARROW_GO = 3

    LANE_STATE_STOP = 4
    """
    Standard round traffic signals.
    """

    LANE_STATE_CAUTION = 5

    LANE_STATE_GO = 6

    LANE_STATE_FLASHING_STOP = 7
    """
    Flashing light signals.
    """

    LANE_STATE_FLASHING_CAUTION = 8


@dataclass(eq=False, repr=False)
class BoundarySegment(betterproto2.Message):
    """
    A segment of a lane with a given adjacent boundary.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x0fBoundarySegment\x12(\n\x10lane_start_index\x18\x01 \x01(\x05R\x0elaneStartIndex\x12$\n\x0elane_end_index\x18\x02 \x01(\x05R\x0claneEndIndex\x12.\n\x13boundary_feature_id\x18\x03 \x01(\x03R\x11boundaryFeatureId\x12N\n\rboundary_type\x18\x04 \x01(\x0e2).waymo.open_dataset.RoadLine.RoadLineTypeR\x0cboundaryType"

    lane_start_index: "int" = betterproto2.field(1, betterproto2.TYPE_INT32)
    """
    The index into the lane's polyline where this lane boundary starts.
    """

    lane_end_index: "int" = betterproto2.field(2, betterproto2.TYPE_INT32)
    """
    The index into the lane's polyline where this lane boundary ends.
    """

    boundary_feature_id: "int" = betterproto2.field(3, betterproto2.TYPE_INT64)
    """
    The adjacent boundary feature ID of the MapFeature for the boundary. This
    can either be a RoadLine feature or a RoadEdge feature.
    """

    boundary_type: "RoadLineRoadLineType" = betterproto2.field(
        4, betterproto2.TYPE_ENUM, default_factory=lambda: RoadLineRoadLineType(0)
    )
    """
    The adjacent boundary type. If the boundary is a road edge instead of a
    road line, this will be set to TYPE_UNKNOWN.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "BoundarySegment", BoundarySegment
)


@dataclass(eq=False, repr=False)
class Box2D(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x05Box2d\x124\n\x06center\x18\x01 \x01(\x0b2\x1c.waymo.open_dataset.Vector2dR\x06center\x120\n\x04size\x18\x02 \x01(\x0b2\x1c.waymo.open_dataset.Vector2dR\x04size\x12\x18\n\x07heading\x18\x03 \x01(\x01R\x07heading"

    center: "Vector2D | None" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Box coordinates in image frame.
    """

    size: "Vector2D | None" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Dimensions of the box. length: dim x. width: dim y.
    """

    heading: "float" = betterproto2.field(3, betterproto2.TYPE_DOUBLE)
    """
    The heading of the bounding box (in radians).  The heading is the angle
    required to rotate +x to the surface normal of the box front face. It is
    normalized to [-pi, pi).
    """


default_message_pool.register_message("waymo.open_dataset", "Box2d", Box2D)


@dataclass(eq=False, repr=False)
class Box3D(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x05Box3d\x124\n\x06center\x18\x01 \x01(\x0b2\x1c.waymo.open_dataset.Vector3dR\x06center\x120\n\x04size\x18\x02 \x01(\x0b2\x1c.waymo.open_dataset.Vector3dR\x04size\x12\x18\n\x07heading\x18\x03 \x01(\x01R\x07heading"

    center: "Vector3D | None" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Box coordinates in image frame.
    """

    size: "Vector3D | None" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Dimensions of the box. length: dim x. width: dim y.
    """

    heading: "float" = betterproto2.field(3, betterproto2.TYPE_DOUBLE)
    """
    The heading of the bounding box (in radians).  The heading is the angle
    required to rotate +x to the surface normal of the box front face. It is
    normalized to [-pi, pi).
    """


default_message_pool.register_message("waymo.open_dataset", "Box3d", Box3D)


@dataclass(eq=False, repr=False)
class Breakdown(betterproto2.Message):
    """
    A breakdown generator defines a way to shard a set of objects such that users
    can compute metrics for different subsets of objects. Each breakdown
    generator comes with a unique breakdown generator ID.
    """

    @staticmethod
    def _serialized_pb():
        return b'\n\tBreakdown\x12L\n\x0cgenerator_id\x18\x01 \x01(\x0e2).waymo.open_dataset.Breakdown.GeneratorIdR\x0bgeneratorId\x12\x14\n\x05shard\x18\x02 \x01(\x05R\x05shard\x12T\n\x10difficulty_level\x18\x03 \x01(\x0e2).waymo.open_dataset.Label.DifficultyLevelR\x0fdifficultyLevel"\xaf\x01\n\x15Breakdown.GeneratorId\x12\t\n\x07UNKNOWN\x12\r\n\tONE_SHARD\x10\x01\x12\x0f\n\x0bOBJECT_TYPE\x10\x02\x12\t\n\x05RANGE\x10\x03\x12\x0f\n\x0bTIME_OF_DAY\x10\x04\x12\x0c\n\x08LOCATION\x10\x05\x12\x0b\n\x07WEATHER\x10\x06\x12\x0c\n\x08VELOCITY\x10\x07\x12\x10\n\x0cALL_BUT_SIGN\x10\x08\x12\x08\n\x04SIZE\x10\t\x12\n\n\x06CAMERA\x10\n'

    generator_id: "BreakdownGeneratorId" = betterproto2.field(
        1, betterproto2.TYPE_ENUM, default_factory=lambda: BreakdownGeneratorId(0)
    )
    """
    The breakdown generator ID.
    """

    shard: "int" = betterproto2.field(2, betterproto2.TYPE_INT32)
    """
    The breakdown generator shard.
    """

    difficulty_level: "LabelDifficultyLevel" = betterproto2.field(
        3, betterproto2.TYPE_ENUM, default_factory=lambda: LabelDifficultyLevel(0)
    )
    """
    The difficulty level.
    """


default_message_pool.register_message("waymo.open_dataset", "Breakdown", Breakdown)


@dataclass(eq=False, repr=False)
class CameraCalibration(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b'\n\x11CameraCalibration\x127\n\x04name\x18\x01 \x01(\x0e2#.waymo.open_dataset.CameraName.NameR\x04name\x12\x1c\n\tintrinsic\x18\x02 \x03(\x01R\tintrinsic\x12;\n\textrinsic\x18\x03 \x01(\x0b2\x1d.waymo.open_dataset.TransformR\textrinsic\x12\x14\n\x05width\x18\x04 \x01(\x05R\x05width\x12\x16\n\x06height\x18\x05 \x01(\x05R\x06height\x12\x80\x01\n\x19rolling_shutter_direction\x18\x06 \x01(\x0e2D.waymo.open_dataset.CameraCalibration.RollingShutterReadOutDirectionR\x17rollingShutterDirection"\x9d\x01\n0CameraCalibration.RollingShutterReadOutDirection\x12\t\n\x07UNKNOWN\x12\x11\n\rTOP_TO_BOTTOM\x10\x01\x12\x11\n\rLEFT_TO_RIGHT\x10\x02\x12\x11\n\rBOTTOM_TO_TOP\x10\x03\x12\x11\n\rRIGHT_TO_LEFT\x10\x04\x12\x12\n\x0eGLOBAL_SHUTTER\x10\x05'

    name: "CameraNameName" = betterproto2.field(
        1, betterproto2.TYPE_ENUM, default_factory=lambda: CameraNameName(0)
    )

    intrinsic: "list[float]" = betterproto2.field(
        2, betterproto2.TYPE_DOUBLE, repeated=True
    )
    """
    1d Array of [f_u, f_v, c_u, c_v, k{1, 2}, p{1, 2}, k{3}].
    Note that this intrinsic corresponds to the images after scaling.
    Camera model: pinhole camera.
    Lens distortion:
      Radial distortion coefficients: k1, k2, k3.
      Tangential distortion coefficients: p1, p2.
    k_{1, 2, 3}, p_{1, 2} follows the same definition as OpenCV.
    https://en.wikipedia.org/wiki/Distortion_(optics)
    https://docs.opencv.org/2.4/doc/tutorials/calib3d/camera_calibration/camera_calibration.html
    """

    extrinsic: "Transform | None" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Camera frame to vehicle frame.
    """

    width: "int" = betterproto2.field(4, betterproto2.TYPE_INT32)
    """
    Camera image size.
    """

    height: "int" = betterproto2.field(5, betterproto2.TYPE_INT32)

    rolling_shutter_direction: "CameraCalibrationRollingShutterReadOutDirection" = (
        betterproto2.field(
            6,
            betterproto2.TYPE_ENUM,
            default_factory=lambda: CameraCalibrationRollingShutterReadOutDirection(0),
        )
    )


default_message_pool.register_message(
    "waymo.open_dataset", "CameraCalibration", CameraCalibration
)


@dataclass(eq=False, repr=False)
class CameraImage(betterproto2.Message):
    """
    All timestamps in this proto are represented as seconds since Unix epoch.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x0bCameraImage\x127\n\x04name\x18\x01 \x01(\x0e2#.waymo.open_dataset.CameraName.NameR\x04name\x12\x14\n\x05image\x18\x02 \x01(\x0cR\x05image\x121\n\x04pose\x18\x03 \x01(\x0b2\x1d.waymo.open_dataset.TransformR\x04pose\x128\n\x08velocity\x18\x04 \x01(\x0b2\x1c.waymo.open_dataset.VelocityR\x08velocity\x12%\n\x0epose_timestamp\x18\x05 \x01(\x01R\rposeTimestamp\x12\x18\n\x07shutter\x18\x06 \x01(\x01R\x07shutter\x12.\n\x13camera_trigger_time\x18\x07 \x01(\x01R\x11cameraTriggerTime\x127\n\x18camera_readout_done_time\x18\x08 \x01(\x01R\x15cameraReadoutDoneTime\x12g\n\x19camera_segmentation_label\x18\n \x01(\x0b2+.waymo.open_dataset.CameraSegmentationLabelR\x17cameraSegmentationLabel"

    name: "CameraNameName" = betterproto2.field(
        1, betterproto2.TYPE_ENUM, default_factory=lambda: CameraNameName(0)
    )

    image: "bytes" = betterproto2.field(2, betterproto2.TYPE_BYTES)
    """
    JPEG image.
    """

    pose: "Transform | None" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    SDC pose.
    """

    velocity: "Velocity | None" = betterproto2.field(
        4, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    SDC velocity at 'pose_timestamp' below. The velocity value is represented
    at *global* frame.
    With this velocity, the pose can be extrapolated.
    r(t+dt) = r(t) + dr/dt * dt where dr/dt = v_{x,y,z}.
    dR(t)/dt = W*R(t) where W = SkewSymmetric(w_{x,y,z})
    This differential equation solves to: R(t) = exp(Wt)*R(0) if W is constant.
    When dt is small: R(t+dt) = (I+W*dt)R(t)
    r(t) = (x(t), y(t), z(t)) is vehicle location at t in the global frame.
    R(t) = Rotation Matrix (3x3) from the body frame to the global frame at t.
    SkewSymmetric(x,y,z) is defined as the cross-product matrix in the
    following:
    https://en.wikipedia.org/wiki/Cross_product#Conversion_to_matrix_multiplication
    """

    pose_timestamp: "float" = betterproto2.field(5, betterproto2.TYPE_DOUBLE)
    """
    Timestamp of the `pose` above.
    """

    shutter: "float" = betterproto2.field(6, betterproto2.TYPE_DOUBLE)
    """
    Rolling shutter params.
    The following explanation assumes left->right rolling shutter.

    Rolling shutter cameras expose and read the image column by column, offset
    by the read out time for each column. The desired timestamp for each column
    is the middle of the exposure of that column as outlined below for an image
    with 3 columns:
    ------time------>
    |---- exposure col 1----| read |
    -------|---- exposure col 2----| read |
    --------------|---- exposure col 3----| read |
    ^trigger time                                ^readout end time
                ^time for row 1 (= middle of exposure of row 1)
                       ^time image center (= middle of exposure of middle row)
    Shutter duration in seconds. Exposure time per column.
    """

    camera_trigger_time: "float" = betterproto2.field(7, betterproto2.TYPE_DOUBLE)
    """
    Time when the sensor was triggered and when last readout finished.
    The difference between trigger time and readout done time includes
    the exposure time and the actual sensor readout time.
    """

    camera_readout_done_time: "float" = betterproto2.field(8, betterproto2.TYPE_DOUBLE)

    camera_segmentation_label: "CameraSegmentationLabel | None" = betterproto2.field(
        10, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Panoptic segmentation labels for this camera image.
    NOTE: Not every image has panoptic segmentation labels.
    """


default_message_pool.register_message("waymo.open_dataset", "CameraImage", CameraImage)


@dataclass(eq=False, repr=False)
class CameraLabels(betterproto2.Message):
    """
    The camera labels associated with a given camera image. This message
    indicates the ground truth information for the camera image
    recorded by the given camera. If there are no labeled objects in the image,
    then the labels field is empty.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x0cCameraLabels\x127\n\x04name\x18\x01 \x01(\x0e2#.waymo.open_dataset.CameraName.NameR\x04name\x121\n\x06labels\x18\x02 \x03(\x0b2\x19.waymo.open_dataset.LabelR\x06labels"

    name: "CameraNameName" = betterproto2.field(
        1, betterproto2.TYPE_ENUM, default_factory=lambda: CameraNameName(0)
    )

    labels: "list[Label]" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, repeated=True
    )


default_message_pool.register_message(
    "waymo.open_dataset", "CameraLabels", CameraLabels
)


@dataclass(eq=False, repr=False)
class CameraName(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b'\n\nCameraName"\x90\x01\n\x0fCameraName.Name\x12\t\n\x07UNKNOWN\x12\t\n\x05FRONT\x10\x01\x12\x0e\n\nFRONT_LEFT\x10\x02\x12\x0f\n\x0bFRONT_RIGHT\x10\x03\x12\r\n\tSIDE_LEFT\x10\x04\x12\x0e\n\nSIDE_RIGHT\x10\x05\x12\r\n\tREAR_LEFT\x10\x06\x12\x08\n\x04REAR\x10\x07\x12\x0e\n\nREAR_RIGHT\x10\x08'

    pass


default_message_pool.register_message("waymo.open_dataset", "CameraName", CameraName)


@dataclass(eq=False, repr=False)
class CameraSegmentation(betterproto2.Message):
    """
    Semantic classes for the camera segmentation labels.
    """

    @staticmethod
    def _serialized_pb():
        return b'\n\x12CameraSegmentation"\xd4\x04\n\x17CameraSegmentation.Type\x12\x10\n\x0eTYPE_UNDEFINED\x12\x14\n\x10TYPE_EGO_VEHICLE\x10\x01\x12\x0c\n\x08TYPE_CAR\x10\x02\x12\x0e\n\nTYPE_TRUCK\x10\x03\x12\x0c\n\x08TYPE_BUS\x10\x04\x12\x1c\n\x18TYPE_OTHER_LARGE_VEHICLE\x10\x05\x12\x10\n\x0cTYPE_BICYCLE\x10\x06\x12\x13\n\x0fTYPE_MOTORCYCLE\x10\x07\x12\x10\n\x0cTYPE_TRAILER\x10\x08\x12\x13\n\x0fTYPE_PEDESTRIAN\x10\t\x12\x10\n\x0cTYPE_CYCLIST\x10\n\x12\x15\n\x11TYPE_MOTORCYCLIST\x10\x0b\x12\r\n\tTYPE_BIRD\x10\x0c\x12\x16\n\x12TYPE_GROUND_ANIMAL\x10\r\x12\x1f\n\x1bTYPE_CONSTRUCTION_CONE_POLE\x10\x0e\x12\r\n\tTYPE_POLE\x10\x0f\x12\x1a\n\x16TYPE_PEDESTRIAN_OBJECT\x10\x10\x12\r\n\tTYPE_SIGN\x10\x11\x12\x16\n\x12TYPE_TRAFFIC_LIGHT\x10\x12\x12\x11\n\rTYPE_BUILDING\x10\x13\x12\r\n\tTYPE_ROAD\x10\x14\x12\x14\n\x10TYPE_LANE_MARKER\x10\x15\x12\x14\n\x10TYPE_ROAD_MARKER\x10\x16\x12\x11\n\rTYPE_SIDEWALK\x10\x17\x12\x13\n\x0fTYPE_VEGETATION\x10\x18\x12\x0c\n\x08TYPE_SKY\x10\x19\x12\x0f\n\x0bTYPE_GROUND\x10\x1a\x12\x10\n\x0cTYPE_DYNAMIC\x10\x1b\x12\x0f\n\x0bTYPE_STATIC\x10\x1c'

    pass


default_message_pool.register_message(
    "waymo.open_dataset", "CameraSegmentation", CameraSegmentation
)


@dataclass(eq=False, repr=False)
class CameraSegmentationFrame(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x17CameraSegmentationFrame\x12g\n\x19camera_segmentation_label\x18\x01 \x01(\x0b2+.waymo.open_dataset.CameraSegmentationLabelR\x17cameraSegmentationLabel\x12!\n\x0ccontext_name\x18\x02 \x01(\tR\x0bcontextName\x124\n\x16frame_timestamp_micros\x18\x03 \x01(\x03R\x14frameTimestampMicros\x12D\n\x0bcamera_name\x18\x04 \x01(\x0e2#.waymo.open_dataset.CameraName.NameR\ncameraName"

    camera_segmentation_label: "CameraSegmentationLabel | None" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Segmentation label for a camera.
    """

    context_name: "str" = betterproto2.field(2, betterproto2.TYPE_STRING)
    """
    These must be set when evaluating on the leaderboard.
    This should be set to Context.name defined in
    dataset.proto::Context.
    """

    frame_timestamp_micros: "int" = betterproto2.field(3, betterproto2.TYPE_INT64)
    """
    This should be set to Frame.timestamp_micros defined in
    dataset.proto::Frame.
    """

    camera_name: "CameraNameName" = betterproto2.field(
        4, betterproto2.TYPE_ENUM, default_factory=lambda: CameraNameName(0)
    )
    """
    The camera associated with this label.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "CameraSegmentationFrame", CameraSegmentationFrame
)


@dataclass(eq=False, repr=False)
class CameraSegmentationFrameList(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x1bCameraSegmentationFrameList\x12C\n\x06frames\x18\x01 \x03(\x0b2+.waymo.open_dataset.CameraSegmentationFrameR\x06frames"

    frames: "list[CameraSegmentationFrame]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )


default_message_pool.register_message(
    "waymo.open_dataset", "CameraSegmentationFrameList", CameraSegmentationFrameList
)


@dataclass(eq=False, repr=False)
class CameraSegmentationLabel(betterproto2.Message):
    """
    Panoptic (instance + semantic) segmentation labels for a given camera image.
    Associations can also be provided between each instance ID and a globally
    unique ID across all frames.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x17CameraSegmentationLabel\x124\n\x16panoptic_label_divisor\x18\x01 \x01(\x05R\x14panopticLabelDivisor\x12%\n\x0epanoptic_label\x18\x02 \x01(\x0cR\rpanopticLabel\x12\x8e\x01\n instance_id_to_global_id_mapping\x18\x03 \x03(\x0b2G.waymo.open_dataset.CameraSegmentationLabel.InstanceIDToGlobalIDMappingR\x1binstanceIdToGlobalIdMapping\x12\x1f\n\x0bsequence_id\x18\x04 \x01(\tR\nsequenceId\x12.\n\x13num_cameras_covered\x18\x05 \x01(\x0cR\x11numCamerasCovered\x1a\xae\x01\n3CameraSegmentationLabel.InstanceIDToGlobalIDMapping\x12*\n\x11local_instance_id\x18\x01 \x01(\x05R\x0flocalInstanceId\x12,\n\x12global_instance_id\x18\x02 \x01(\x05R\x10globalInstanceId\x12\x1d\n\nis_tracked\x18\x03 \x01(\x08R\tisTracked"

    panoptic_label_divisor: "int" = betterproto2.field(1, betterproto2.TYPE_INT32)
    """
    The value used to separate instance_ids from different semantic classes.
    See the panoptic_label field for how this is used. Must be set to be
    greater than the maximum instance_id.
    """

    panoptic_label: "bytes" = betterproto2.field(2, betterproto2.TYPE_BYTES)
    """
    A uint16 png encoded image, with the same resolution as the corresponding
    camera image. Each pixel contains a panoptic segmentation label, which is
    computed as:
    semantic_class_id * panoptic_label_divisor + instance_id.
    We set instance_id = 0 for pixels for which there is no instance_id.
    NOTE: Instance IDs in this label are only consistent within this camera
    image. Use instance_id_to_global_id_mapping to get cross-camera consistent
    instance IDs.
    """

    instance_id_to_global_id_mapping: "list[CameraSegmentationLabelInstanceIdToGlobalIdMapping]" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, repeated=True
    )

    sequence_id: "str" = betterproto2.field(4, betterproto2.TYPE_STRING)
    """
    The sequence id for this label. The above instance_id_to_global_id_mapping
    is only valid with other labels with the same sequence id.
    """

    num_cameras_covered: "bytes" = betterproto2.field(5, betterproto2.TYPE_BYTES)
    """
    A uint8 png encoded image, with the same resolution as the corresponding
    camera image. The value on each pixel indicates the number of cameras that
    overlap with this pixel. Used for the weighted Segmentation and Tracking
    Quality (wSTQ) metric.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "CameraSegmentationLabel", CameraSegmentationLabel
)


@dataclass(eq=False, repr=False)
class CameraSegmentationLabelInstanceIdToGlobalIdMapping(betterproto2.Message):
    """
    A mapping between each panoptic label with an instance_id and a globally
    unique ID across all frames within the same sequence. This can be used to
    match instances across cameras and over time. i.e. instances belonging to
    the same object will map to the same global ID across all frames in the
    same sequence.
    NOTE: These unique IDs are not consistent with other IDs in the dataset,
    e.g. the bounding box IDs.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n3CameraSegmentationLabel.InstanceIDToGlobalIDMapping\x12*\n\x11local_instance_id\x18\x01 \x01(\x05R\x0flocalInstanceId\x12,\n\x12global_instance_id\x18\x02 \x01(\x05R\x10globalInstanceId\x12\x1d\n\nis_tracked\x18\x03 \x01(\x08R\tisTracked"

    local_instance_id: "int" = betterproto2.field(1, betterproto2.TYPE_INT32)

    global_instance_id: "int" = betterproto2.field(2, betterproto2.TYPE_INT32)

    is_tracked: "bool" = betterproto2.field(3, betterproto2.TYPE_BOOL)
    """
    If false, the corresponding instance will not have consistent global ids
    between frames.
    """


default_message_pool.register_message(
    "waymo.open_dataset",
    "CameraSegmentationLabel.InstanceIDToGlobalIDMapping",
    CameraSegmentationLabelInstanceIdToGlobalIdMapping,
)


@dataclass(eq=False, repr=False)
class CameraSegmentationMetrics(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x19CameraSegmentationMetrics\x12\x12\n\x04wstq\x18\x01 \x01(\x02R\x04wstq\x12\x10\n\x03waq\x18\x02 \x01(\x02R\x03waq\x12\x12\n\x04miou\x18\x03 \x01(\x02R\x04miou\x12\x19\n\x08frame_dt\x18\x05 \x01(\x05R\x07frameDt\x12\x1d\n\nruntime_ms\x18\x06 \x01(\x02R\truntimeMsJ\x04\x08\x04\x10\x05"

    wstq: "float" = betterproto2.field(1, betterproto2.TYPE_FLOAT)
    """
    Panoptic segmentation metrics.
    weighted Segmentation Tracking and Quality.
    """

    waq: "float" = betterproto2.field(2, betterproto2.TYPE_FLOAT)
    """
    weighted Association Quality.
    """

    miou: "float" = betterproto2.field(3, betterproto2.TYPE_FLOAT)
    """
    mean Intersection over Union.
    """

    frame_dt: "int" = betterproto2.field(5, betterproto2.TYPE_INT32)
    """
    User reported, number of frames between inference.
    """

    runtime_ms: "float" = betterproto2.field(6, betterproto2.TYPE_FLOAT)
    """
    Runtime for the method in milliseconds.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "CameraSegmentationMetrics", CameraSegmentationMetrics
)


@dataclass(eq=False, repr=False)
class CameraSegmentationSubmission(betterproto2.Message):
    """
    Next ID: 10.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x1cCameraSegmentationSubmission\x12!\n\x0caccount_name\x18\x01 \x01(\tR\x0baccountName\x12,\n\x12unique_method_name\x18\x02 \x01(\tR\x10uniqueMethodName\x12\x18\n\x07authors\x18\x03 \x03(\tR\x07authors\x12 \n\x0baffiliation\x18\x04 \x01(\tR\x0baffiliation\x12 \n\x0bdescription\x18\x05 \x01(\tR\x0bdescription\x12\x1f\n\x0bmethod_link\x18\x06 \x01(\tR\nmethodLink\x12\x19\n\x08frame_dt\x18\x07 \x01(\x05R\x07frameDt\x12\x1d\n\nruntime_ms\x18\x08 \x01(\x02R\truntimeMs\x12s\n\x1dpredicted_segmentation_labels\x18\t \x01(\x0b2/.waymo.open_dataset.CameraSegmentationFrameListR\x1bpredictedSegmentationLabels"

    account_name: "str" = betterproto2.field(1, betterproto2.TYPE_STRING)
    """
    This must be set as the full email used to register at waymo.com/open.
    """

    unique_method_name: "str" = betterproto2.field(2, betterproto2.TYPE_STRING)
    """
    This name needs to be short, descriptive and unique. Only the latest result
    of the method from a user will show up on the leaderboard.
    """

    authors: "list[str]" = betterproto2.field(
        3, betterproto2.TYPE_STRING, repeated=True
    )

    affiliation: "str" = betterproto2.field(4, betterproto2.TYPE_STRING)

    description: "str" = betterproto2.field(5, betterproto2.TYPE_STRING)

    method_link: "str" = betterproto2.field(6, betterproto2.TYPE_STRING)
    """
    Link to paper or other link that describes the method.
    """

    frame_dt: "int" = betterproto2.field(7, betterproto2.TYPE_INT32)
    """
    The number of frames skipped between each prediction during inference.
    Usually 0 (inference on every frame) or 1 (inference on every other frame).
    e.g. the validation and test groundtruth is provided with frame_dt = 1.
    """

    runtime_ms: "float" = betterproto2.field(8, betterproto2.TYPE_FLOAT)
    """
    (Optional) The time for the method to run in ms.
    """

    predicted_segmentation_labels: "CameraSegmentationFrameList | None" = (
        betterproto2.field(9, betterproto2.TYPE_MESSAGE, optional=True)
    )
    """
    Inference results.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "CameraSegmentationSubmission", CameraSegmentationSubmission
)


@dataclass(eq=False, repr=False)
class CameraTokens(betterproto2.Message):
    """
    Camera tokens for a single camera sensor.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x0cCameraTokens\x12D\n\x0bcamera_name\x18\x01 \x01(\x0e2#.waymo.open_dataset.CameraName.NameR\ncameraName\x12\x1a\n\x06tokens\x18\x02 \x03(\rR\x06tokensB\x02\x10\x01"

    camera_name: "CameraNameName" = betterproto2.field(
        1, betterproto2.TYPE_ENUM, default_factory=lambda: CameraNameName(0)
    )
    """
    Camera sensor name.
    """

    tokens: "list[int]" = betterproto2.field(2, betterproto2.TYPE_UINT32, repeated=True)
    """
    Camera tokens is a sequence of integers corresonding to codebook indices.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "CameraTokens", CameraTokens
)


@dataclass(eq=False, repr=False)
class ChallengeScenarioPredictions(betterproto2.Message):
    """
    A set of predictions for a single scenario.

    Oneofs:
        - prediction_set: The predictions for the scenario. For the motion prediction challenge,
            populate the predictions field. For the interaction prediction challenge,
            populate the joint_predictions_field.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x1cChallengeScenarioPredictions\x12\x1f\n\x0bscenario_id\x18\x01 \x01(\tR\nscenarioId\x12R\n\x12single_predictions\x18\x02 \x01(\x0b2!.waymo.open_dataset.PredictionSetH\x00R\x11singlePredictions\x12P\n\x10joint_prediction\x18\x03 \x01(\x0b2#.waymo.open_dataset.JointPredictionH\x00R\x0fjointPredictionB\x10\n\x0eprediction_set"

    scenario_id: "str" = betterproto2.field(1, betterproto2.TYPE_STRING)
    """
    The unique ID of the scenario being predicted. This ID must match the
    scenario_id field in the test or validation set tf.Example or scenario
    proto corresponding to this set of predictions.
    """

    single_predictions: "PredictionSet | None" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, optional=True, group="prediction_set"
    )
    """
    Single object predictions. This must be populated for the motion
    prediction challenge.
    """

    joint_prediction: "JointPrediction | None" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, optional=True, group="prediction_set"
    )
    """
    Joint predictions for the interacting objects. This must be populated for
    the interaction prediction challenge.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "ChallengeScenarioPredictions", ChallengeScenarioPredictions
)


@dataclass(eq=False, repr=False)
class CompressedFrameLaserData(betterproto2.Message):
    """
    Lidar data of a frame.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x18CompressedFrameLaserData\x12;\n\x06lasers\x18\x01 \x03(\x0b2#.waymo.open_dataset.CompressedLaserR\x06lasers\x12S\n\x12laser_calibrations\x18\x02 \x03(\x0b2$.waymo.open_dataset.LaserCalibrationR\x11laserCalibrations\x121\n\x04pose\x18\x03 \x01(\x0b2\x1d.waymo.open_dataset.TransformR\x04pose"

    lasers: "list[CompressedLaser]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The Lidar data for each timestamp.
    """

    laser_calibrations: "list[LaserCalibration]" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    Laser calibration data has the same length as that of lasers.
    """

    pose: "Transform | None" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Poses of the SDC corresponding to the track states for each step in the
    scenario, similar to the one in the Frame proto.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "CompressedFrameLaserData", CompressedFrameLaserData
)


@dataclass(eq=False, repr=False)
class CompressedLaser(betterproto2.Message):
    """
    Compressed Laser data.
    """

    @staticmethod
    def _serialized_pb():
        return b'\n\x0fCompressedLaser\x126\n\x04name\x18\x01 \x01(\x0e2".waymo.open_dataset.LaserName.NameR\x04name\x12G\n\nri_return1\x18\x02 \x01(\x0b2(.waymo.open_dataset.CompressedRangeImageR\triReturn1\x12G\n\nri_return2\x18\x03 \x01(\x0b2(.waymo.open_dataset.CompressedRangeImageR\triReturn2'

    name: "LaserNameName" = betterproto2.field(
        1, betterproto2.TYPE_ENUM, default_factory=lambda: LaserNameName(0)
    )

    ri_return1: "CompressedRangeImage | None" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, optional=True
    )

    ri_return2: "CompressedRangeImage | None" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, optional=True
    )


default_message_pool.register_message(
    "waymo.open_dataset", "CompressedLaser", CompressedLaser
)


@dataclass(eq=False, repr=False)
class CompressedRangeImage(betterproto2.Message):
    """
    Range image is a 2d tensor. The first dimension (rows) represents pitch.
    The second dimension represents yaw (columns).
    Zlib compressed range images include:
    Raw range image: Raw range image with a non-empty
    'range_image_pose_delta_compressed' which tells the vehicle pose of each
    range image cell.
    NOTE: 'range_image_pose_delta_compressed' is only populated for the first
    range image return. The second return has the exact the same range image pose
    as the first one.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x14CompressedRangeImage\x12?\n\x1crange_image_delta_compressed\x18\x01 \x01(\x0cR\x19rangeImageDeltaCompressed\x12H\n!range_image_pose_delta_compressed\x18\x04 \x01(\x0cR\x1drangeImagePoseDeltaCompressed"

    range_image_delta_compressed: "bytes" = betterproto2.field(
        1, betterproto2.TYPE_BYTES
    )
    """
    Zlib compressed [H, W, 4] serialized DeltaEncodedData message version which
    stores MatrixFloat.
    MatrixFloat range_image;
    range_image.ParseFromString(val);
    Inner dimensions are:
      * channel 0: range
      * channel 1: intensity
      * channel 2: elongation
      * channel 3: is in any no label zone.
    """

    range_image_pose_delta_compressed: "bytes" = betterproto2.field(
        4, betterproto2.TYPE_BYTES
    )
    """
    Zlib compressed [H, W, 4] serialized DeltaEncodedData message version which
    stores MatrixFloat.
    To decompress (Please see the documentation for lidar delta encoding):
    string val = delta_encoder.decompress(range_image_pose_compressed);
    MatrixFloat range_image_pose;
    range_image_pose.ParseFromString(val);
    Inner dimensions are [roll, pitch, yaw, x, y, z] represents a transform
    from vehicle frame to global frame for every range image pixel.
    This is ONLY populated for the first return. The second return is assumed
    to have exactly the same range_image_pose_compressed.

    The roll, pitch and yaw are specified as 3-2-1 Euler angle rotations,
    meaning that rotating from the navigation to vehicle frame consists of a
    yaw, then pitch and finally roll rotation about the z, y and x axes
    respectively. All rotations use the right hand rule and are positive
    in the counter clockwise direction.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "CompressedRangeImage", CompressedRangeImage
)


@dataclass(eq=False, repr=False)
class Config(betterproto2.Message):
    """
    Configuration to compute detection/tracking metrics.
    """

    @staticmethod
    def _serialized_pb():
        return b'\n\x06Config\x12#\n\rscore_cutoffs\x18\x01 \x03(\x02R\x0cscoreCutoffs\x129\n\x19num_desired_score_cutoffs\x18\x02 \x01(\x05R\x16numDesiredScoreCutoffs\x12a\n\x17breakdown_generator_ids\x18\x03 \x03(\x0e2).waymo.open_dataset.Breakdown.GeneratorIdR\x15breakdownGeneratorIds\x12B\n\x0cdifficulties\x18\x04 \x03(\x0b2\x1e.waymo.open_dataset.DifficultyR\x0cdifficulties\x12H\n\x0cmatcher_type\x18\x05 \x01(\x0e2%.waymo.open_dataset.MatcherProto.TypeR\x0bmatcherType\x12%\n\x0eiou_thresholds\x18\x06 \x03(\x02R\riouThresholds\x12=\n\x08box_type\x18\x07 \x01(\x0e2".waymo.open_dataset.Label.Box.TypeR\x07boxType\x126\n\x14desired_recall_delta\x18\x08 \x01(\x02:\x040.05R\x12desiredRecallDelta\x12f\n\x11let_metric_config\x18\x0c \x01(\x0b2:.waymo.open_dataset.Config.LongitudinalErrorTolerantConfigR\x0fletMetricConfig\x12&\n\rmin_precision\x18\t \x01(\x02:\x010R\x0cminPrecision\x124\n\x14min_heading_accuracy\x18\n \x01(\x02:\x02-1R\x12minHeadingAccuracy\x12E\n\x1finclude_details_in_measurements\x18\x0b \x01(\x08R\x1cincludeDetailsInMeasurements\x1a\xab\x06\n&Config.LongitudinalErrorTolerantConfig\x12\x18\n\x07enabled\x18\x01 \x01(\x08R\x07enabled\x12n\n\x0fsensor_location\x18\x02 \x01(\x0b2E.waymo.open_dataset.Config.LongitudinalErrorTolerantConfig.Location3DR\x0esensorLocation\x12J\n!longitudinal_tolerance_percentage\x18\x03 \x01(\x02R\x1flongitudinalTolerancePercentage\x12G\n min_longitudinal_tolerance_meter\x18\x04 \x01(\x02R\x1dminLongitudinalToleranceMeter\x12w\n\nalign_type\x18\x05 \x01(\x0e2D.waymo.open_dataset.Config.LongitudinalErrorTolerantConfig.AlignType:\x12TYPE_RANGE_ALIGNEDR\talignType\x1a]\n1Config.LongitudinalErrorTolerantConfig.Location3D\x12\x0c\n\x01x\x18\x01 \x01(\x01R\x01x\x12\x0c\n\x01y\x18\x02 \x01(\x01R\x01y\x12\x0c\n\x01z\x18\x03 \x01(\x01R\x01z"\x89\x02\n0Config.LongitudinalErrorTolerantConfig.AlignType\x12\x0e\n\x0cTYPE_UNKNOWN\x12\x14\n\x10TYPE_NOT_ALIGNED\x10\x01\x12\x16\n\x12TYPE_RANGE_ALIGNED\x10\x02\x12\x17\n\x13TYPE_CENTER_ALIGNED\x10\x03\x12#\n\x1fTYPE_FURTHER_ONLY_RANGE_ALIGNED\x10\x04\x12&\n"TYPE_ANY_CLOSER_ONLY_RANGE_ALIGNED\x10\x05\x121\n-TYPE_BETWEEN_ORIGIN_AND_GT_ONLY_RANGE_ALIGNED\x10\x06'

    score_cutoffs: "list[float]" = betterproto2.field(
        1, betterproto2.TYPE_FLOAT, repeated=True
    )
    """
    Score cutoffs used to remove predictions with lower Object::score during
    matching in order to compute precision-recall pairs at different operating
    points.
    """

    num_desired_score_cutoffs: "int" = betterproto2.field(2, betterproto2.TYPE_INT32)
    """
    If `score_cutoffs` above is not set, the cutoffs are generated based on the
    score distributions in the predictions and produce
    `num_desired_score_cutoffs`.
    NOTE: this field is to be deprecated. Manually set score_cutoffs above to
    [0:0.01:1].
    TODO: clean this up.
    """

    breakdown_generator_ids: "list[BreakdownGeneratorId]" = betterproto2.field(
        3, betterproto2.TYPE_ENUM, repeated=True
    )
    """
    Breakdown generator IDs. Note that users only need to specify the IDs but
    NOT other information about this generator such as number of shards.
    """

    difficulties: "list[Difficulty]" = betterproto2.field(
        4, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    This has the same size as breakdown_generator_ids. Each entry indicates the
    set of difficulty levels to be considered for each breakdown generator.
    """

    matcher_type: "MatcherProtoType" = betterproto2.field(
        5, betterproto2.TYPE_ENUM, default_factory=lambda: MatcherProtoType(0)
    )

    iou_thresholds: "list[float]" = betterproto2.field(
        6, betterproto2.TYPE_FLOAT, repeated=True
    )
    """
    Indexed by label type. Size = Label::TYPE_MAX+1. The thresholds must be
    within [0.0, 1.0].
    """

    box_type: "LabelBoxType" = betterproto2.field(
        7, betterproto2.TYPE_ENUM, default_factory=lambda: LabelBoxType(0)
    )

    desired_recall_delta: "float" = betterproto2.field(8, betterproto2.TYPE_FLOAT)
    """
    Desired recall delta when sampling the P/R curve to compute mean average
    precision.
    """

    let_metric_config: "ConfigLongitudinalErrorTolerantConfig | None" = (
        betterproto2.field(12, betterproto2.TYPE_MESSAGE, optional=True)
    )

    min_precision: "float" = betterproto2.field(9, betterproto2.TYPE_FLOAT)
    """
    //////////////////////////////////////////////////////////////////////////
    Users do not need to modify the following features.
    //////////////////////////////////////////////////////////////////////////
    If set, all precisions below this value is considered as 0.
    """

    min_heading_accuracy: "float" = betterproto2.field(10, betterproto2.TYPE_FLOAT)
    """
    Any matching with an heading accuracy lower than this is considered as
    false matching.
    """

    include_details_in_measurements: "bool" = betterproto2.field(
        11, betterproto2.TYPE_BOOL
    )
    """
    When enabled, the details in the matching such as index of the false
    positives, false negatives or true positives will be included.
    """


default_message_pool.register_message("waymo.open_dataset", "Config", Config)


@dataclass(eq=False, repr=False)
class ConfigLongitudinalErrorTolerantConfig(betterproto2.Message):
    """
    Longitudinal error tolerant (LET) metrics config for Camera-Only (Mono) 3D
    Detection.
    By enabling this metric, the prediction-groundtruth matching will be more
    tolerant to the longitudinal noise, rather than just use IoU.
    The tolerance is larger in the long range, but only along the line of sight
    from the sensor origin.
    """

    @staticmethod
    def _serialized_pb():
        return b'\n&Config.LongitudinalErrorTolerantConfig\x12\x18\n\x07enabled\x18\x01 \x01(\x08R\x07enabled\x12n\n\x0fsensor_location\x18\x02 \x01(\x0b2E.waymo.open_dataset.Config.LongitudinalErrorTolerantConfig.Location3DR\x0esensorLocation\x12J\n!longitudinal_tolerance_percentage\x18\x03 \x01(\x02R\x1flongitudinalTolerancePercentage\x12G\n min_longitudinal_tolerance_meter\x18\x04 \x01(\x02R\x1dminLongitudinalToleranceMeter\x12w\n\nalign_type\x18\x05 \x01(\x0e2D.waymo.open_dataset.Config.LongitudinalErrorTolerantConfig.AlignType:\x12TYPE_RANGE_ALIGNEDR\talignType\x1a]\n1Config.LongitudinalErrorTolerantConfig.Location3D\x12\x0c\n\x01x\x18\x01 \x01(\x01R\x01x\x12\x0c\n\x01y\x18\x02 \x01(\x01R\x01y\x12\x0c\n\x01z\x18\x03 \x01(\x01R\x01z"\x89\x02\n0Config.LongitudinalErrorTolerantConfig.AlignType\x12\x0e\n\x0cTYPE_UNKNOWN\x12\x14\n\x10TYPE_NOT_ALIGNED\x10\x01\x12\x16\n\x12TYPE_RANGE_ALIGNED\x10\x02\x12\x17\n\x13TYPE_CENTER_ALIGNED\x10\x03\x12#\n\x1fTYPE_FURTHER_ONLY_RANGE_ALIGNED\x10\x04\x12&\n"TYPE_ANY_CLOSER_ONLY_RANGE_ALIGNED\x10\x05\x121\n-TYPE_BETWEEN_ORIGIN_AND_GT_ONLY_RANGE_ALIGNED\x10\x06'

    enabled: "bool" = betterproto2.field(1, betterproto2.TYPE_BOOL)
    """
    When enabled, calculate the longitudinal error tolerant 3D AP
    (LET-3D-AP).
    """

    sensor_location: "ConfigLongitudinalErrorTolerantConfigLocation3D | None" = (
        betterproto2.field(2, betterproto2.TYPE_MESSAGE, optional=True)
    )
    """
    Location of the sensor used to infer the predictions (e.g., camera). The
    location is related to the vehicle origin. It is used to translate the
    centers of prediction and ground truth boxes to the sensor cooridinate
    system so that the range to the sensor origin can be calculated
    correctly.
    """

    longitudinal_tolerance_percentage: "float" = betterproto2.field(
        3, betterproto2.TYPE_FLOAT
    )
    """
    The percentage of allowed longitudinal error for a given ground truth
    object.
    The final longitudinal tolerance tol_lon in meters given a ground truth
    object with range r_gt is computed as:
    tol_r = max(longitudinal_tolerance_percentage* r_gt,
                min_range_tolerance_meter),
    where min_longitudinal_tolerance_meter is introduced to handle near-range
    ground truth objects so that it has a minimum longitudinal error
    tolerance in meters.
    A prediction bounding box can be matched with a ground truth bounding box
    only if the range error between them is less than the tolerance.
    """

    min_longitudinal_tolerance_meter: "float" = betterproto2.field(
        4, betterproto2.TYPE_FLOAT
    )

    align_type: "ConfigLongitudinalErrorTolerantConfigAlignType" = betterproto2.field(
        5,
        betterproto2.TYPE_ENUM,
        default_factory=lambda: ConfigLongitudinalErrorTolerantConfigAlignType(0),
    )


default_message_pool.register_message(
    "waymo.open_dataset",
    "Config.LongitudinalErrorTolerantConfig",
    ConfigLongitudinalErrorTolerantConfig,
)


@dataclass(eq=False, repr=False)
class ConfigLongitudinalErrorTolerantConfigLocation3D(betterproto2.Message):
    """
    Location in 3D space described in a Cartersian coordinate system.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n1Config.LongitudinalErrorTolerantConfig.Location3D\x12\x0c\n\x01x\x18\x01 \x01(\x01R\x01x\x12\x0c\n\x01y\x18\x02 \x01(\x01R\x01y\x12\x0c\n\x01z\x18\x03 \x01(\x01R\x01z"

    x: "float" = betterproto2.field(1, betterproto2.TYPE_DOUBLE)

    y: "float" = betterproto2.field(2, betterproto2.TYPE_DOUBLE)

    z: "float" = betterproto2.field(3, betterproto2.TYPE_DOUBLE)


default_message_pool.register_message(
    "waymo.open_dataset",
    "Config.LongitudinalErrorTolerantConfig.Location3D",
    ConfigLongitudinalErrorTolerantConfigLocation3D,
)


@dataclass(eq=False, repr=False)
class Context(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x07Context\x12\x12\n\x04name\x18\x01 \x01(\tR\x04name\x12V\n\x13camera_calibrations\x18\x02 \x03(\x0b2%.waymo.open_dataset.CameraCalibrationR\x12cameraCalibrations\x12S\n\x12laser_calibrations\x18\x03 \x03(\x0b2$.waymo.open_dataset.LaserCalibrationR\x11laserCalibrations\x127\n\x05stats\x18\x04 \x01(\x0b2!.waymo.open_dataset.Context.StatsR\x05stats\x1a\x8c\x03\n\rContext.Stats\x12]\n\x13laser_object_counts\x18\x01 \x03(\x0b2-.waymo.open_dataset.Context.Stats.ObjectCountR\x11laserObjectCounts\x12_\n\x14camera_object_counts\x18\x05 \x03(\x0b2-.waymo.open_dataset.Context.Stats.ObjectCountR\x12cameraObjectCounts\x12\x1e\n\x0btime_of_day\x18\x02 \x01(\tR\ttimeOfDay\x12\x1a\n\x08location\x18\x03 \x01(\tR\x08location\x12\x18\n\x07weather\x18\x04 \x01(\tR\x07weather\x1ae\n\x19Context.Stats.ObjectCount\x122\n\x04type\x18\x01 \x01(\x0e2\x1e.waymo.open_dataset.Label.TypeR\x04type\x12\x14\n\x05count\x18\x02 \x01(\x05R\x05count"

    name: "str" = betterproto2.field(1, betterproto2.TYPE_STRING)
    """
    A unique name that identifies the frame sequence.
    """

    camera_calibrations: "list[CameraCalibration]" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, repeated=True
    )

    laser_calibrations: "list[LaserCalibration]" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, repeated=True
    )

    stats: "ContextStats | None" = betterproto2.field(
        4, betterproto2.TYPE_MESSAGE, optional=True
    )


default_message_pool.register_message("waymo.open_dataset", "Context", Context)


@dataclass(eq=False, repr=False)
class ContextStats(betterproto2.Message):
    """
    Some stats for the run segment used.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\rContext.Stats\x12]\n\x13laser_object_counts\x18\x01 \x03(\x0b2-.waymo.open_dataset.Context.Stats.ObjectCountR\x11laserObjectCounts\x12_\n\x14camera_object_counts\x18\x05 \x03(\x0b2-.waymo.open_dataset.Context.Stats.ObjectCountR\x12cameraObjectCounts\x12\x1e\n\x0btime_of_day\x18\x02 \x01(\tR\ttimeOfDay\x12\x1a\n\x08location\x18\x03 \x01(\tR\x08location\x12\x18\n\x07weather\x18\x04 \x01(\tR\x07weather\x1ae\n\x19Context.Stats.ObjectCount\x122\n\x04type\x18\x01 \x01(\x0e2\x1e.waymo.open_dataset.Label.TypeR\x04type\x12\x14\n\x05count\x18\x02 \x01(\x05R\x05count"

    laser_object_counts: "list[ContextStatsObjectCount]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )

    camera_object_counts: "list[ContextStatsObjectCount]" = betterproto2.field(
        5, betterproto2.TYPE_MESSAGE, repeated=True
    )

    time_of_day: "str" = betterproto2.field(2, betterproto2.TYPE_STRING)
    """
    Day, Dawn/Dusk, or Night, determined from sun elevation.
    """

    location: "str" = betterproto2.field(3, betterproto2.TYPE_STRING)
    """
    Human readable location (e.g. CHD, SF) of the run segment.
    """

    weather: "str" = betterproto2.field(4, betterproto2.TYPE_STRING)
    """
    Currently either Sunny or Rain.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "Context.Stats", ContextStats
)


@dataclass(eq=False, repr=False)
class ContextStatsObjectCount(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x19Context.Stats.ObjectCount\x122\n\x04type\x18\x01 \x01(\x0e2\x1e.waymo.open_dataset.Label.TypeR\x04type\x12\x14\n\x05count\x18\x02 \x01(\x05R\x05count"

    type: "LabelType" = betterproto2.field(
        1, betterproto2.TYPE_ENUM, default_factory=lambda: LabelType(0)
    )

    count: "int" = betterproto2.field(2, betterproto2.TYPE_INT32)
    """
    The number of unique objects with the type in the segment.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "Context.Stats.ObjectCount", ContextStatsObjectCount
)


@dataclass(eq=False, repr=False)
class Crosswalk(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\tCrosswalk\x126\n\x07polygon\x18\x01 \x03(\x0b2\x1c.waymo.open_dataset.MapPointR\x07polygon"

    polygon: "list[MapPoint]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The polygon defining the outline of the crosswalk. The polygon is assumed
    to be closed (i.e. a segment exists between the last point and the first
    point).
    """


default_message_pool.register_message("waymo.open_dataset", "Crosswalk", Crosswalk)


@dataclass(eq=False, repr=False)
class DeltaEncodedData(betterproto2.Message):
    """
    Delta Encoded data structure. The protobuf compressed mask and residual data
    and the compressed data is encoded via zlib:
    compressed_bytes = zlib.compress(
     metadata + data_bytes + mask_bytes + residuals_bytes)
    The range_image_delta_compressed and range_image_pose_delta_compressed in the
    CompressedRangeImage are both encoded using this method.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x10DeltaEncodedData\x12\x1e\n\x08residual\x18\x01 \x03(\x12R\x08residualB\x02\x10\x01\x12\x16\n\x04mask\x18\x02 \x03(\rR\x04maskB\x02\x10\x01\x128\n\x08metadata\x18\x03 \x01(\x0b2\x1c.waymo.open_dataset.MetadataR\x08metadata"

    residual: "list[int]" = betterproto2.field(
        1, betterproto2.TYPE_SINT64, repeated=True
    )

    mask: "list[int]" = betterproto2.field(2, betterproto2.TYPE_UINT32, repeated=True)

    metadata: "Metadata | None" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, optional=True
    )


default_message_pool.register_message(
    "waymo.open_dataset", "DeltaEncodedData", DeltaEncodedData
)


@dataclass(eq=False, repr=False)
class DetectionMeasurement(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x14DetectionMeasurement\x12\x17\n\x07num_fps\x18\x01 \x01(\x05R\x06numFps\x12\x17\n\x07num_tps\x18\x02 \x01(\x05R\x06numTps\x12\x17\n\x07num_fns\x18\x03 \x01(\x05R\x06numFns\x12J\n\x07details\x18\x06 \x03(\x0b20.waymo.open_dataset.DetectionMeasurement.DetailsR\x07details\x12\x15\n\x06sum_ha\x18\x04 \x01(\x02R\x05sumHa\x12:\n\x19sum_longitudinal_affinity\x18\x07 \x01(\x02R\x17sumLongitudinalAffinity\x12!\n\x0cscore_cutoff\x18\x05 \x01(\x02R\x0bscoreCutoff\x1a\x8f\x02\n\x1cDetectionMeasurement.Details\x12\x15\n\x06fp_ids\x18\x01 \x03(\tR\x05fpIds\x12\x15\n\x06fn_ids\x18\x02 \x03(\tR\x05fnIds\x12\x1a\n\ttp_gt_ids\x18\x03 \x03(\tR\x07tpGtIds\x12\x1a\n\ttp_pr_ids\x18\x04 \x03(\tR\x07tpPrIds\x12\x17\n\x07tp_ious\x18\x05 \x03(\x02R\x06tpIous\x122\n\x15tp_heading_accuracies\x18\x06 \x03(\x02R\x13tpHeadingAccuracies\x12<\n\x1atp_longitudinal_affinities\x18\x07 \x03(\x02R\x18tpLongitudinalAffinities"

    num_fps: "int" = betterproto2.field(1, betterproto2.TYPE_INT32)
    """
    Number of false positives.
    """

    num_tps: "int" = betterproto2.field(2, betterproto2.TYPE_INT32)
    """
    Number of true positives.
    """

    num_fns: "int" = betterproto2.field(3, betterproto2.TYPE_INT32)
    """
    Number of false negatives.
    """

    details: "list[DetectionMeasurementDetails]" = betterproto2.field(
        6, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    If set, will include the ids of the fp/tp/fn objects. Each element
    corresponds to one frame of matching.
    """

    sum_ha: "float" = betterproto2.field(4, betterproto2.TYPE_FLOAT)
    """
    Sum of heading accuracy (ha) for all TPs.
    """

    sum_longitudinal_affinity: "float" = betterproto2.field(7, betterproto2.TYPE_FLOAT)
    """
    Sum of longitudinal affinity for all TPs.
    """

    score_cutoff: "float" = betterproto2.field(5, betterproto2.TYPE_FLOAT)
    """
    The score cutoff used to compute this measurement. Optional.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "DetectionMeasurement", DetectionMeasurement
)


@dataclass(eq=False, repr=False)
class DetectionMeasurementDetails(betterproto2.Message):
    """
    Detailed information regarding the results.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x1cDetectionMeasurement.Details\x12\x15\n\x06fp_ids\x18\x01 \x03(\tR\x05fpIds\x12\x15\n\x06fn_ids\x18\x02 \x03(\tR\x05fnIds\x12\x1a\n\ttp_gt_ids\x18\x03 \x03(\tR\x07tpGtIds\x12\x1a\n\ttp_pr_ids\x18\x04 \x03(\tR\x07tpPrIds\x12\x17\n\x07tp_ious\x18\x05 \x03(\x02R\x06tpIous\x122\n\x15tp_heading_accuracies\x18\x06 \x03(\x02R\x13tpHeadingAccuracies\x12<\n\x1atp_longitudinal_affinities\x18\x07 \x03(\x02R\x18tpLongitudinalAffinities"

    fp_ids: "list[str]" = betterproto2.field(1, betterproto2.TYPE_STRING, repeated=True)
    """
    False positive prediction ids.
    """

    fn_ids: "list[str]" = betterproto2.field(2, betterproto2.TYPE_STRING, repeated=True)
    """
    False negative ground truth ids.
    """

    tp_gt_ids: "list[str]" = betterproto2.field(
        3, betterproto2.TYPE_STRING, repeated=True
    )
    """
    True positive ground truth ids. Should be of the same length with
    tp_pr_ids, tp_ious. Each pair of ids of the same index correspond to
    the ids of ground truth object and prediction objects which are matched.
    """

    tp_pr_ids: "list[str]" = betterproto2.field(
        4, betterproto2.TYPE_STRING, repeated=True
    )
    """
    True positive prediction ids.
    """

    tp_ious: "list[float]" = betterproto2.field(
        5, betterproto2.TYPE_FLOAT, repeated=True
    )
    """
    IoU values of the true positive pairs.
    """

    tp_heading_accuracies: "list[float]" = betterproto2.field(
        6, betterproto2.TYPE_FLOAT, repeated=True
    )
    """
    Heading accuracies of the true positive pairs.
    """

    tp_longitudinal_affinities: "list[float]" = betterproto2.field(
        7, betterproto2.TYPE_FLOAT, repeated=True
    )
    """
    Longitudinal affinities of the true positive pairs.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "DetectionMeasurement.Details", DetectionMeasurementDetails
)


@dataclass(eq=False, repr=False)
class DetectionMeasurements(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x15DetectionMeasurements\x12L\n\x0cmeasurements\x18\x01 \x03(\x0b2(.waymo.open_dataset.DetectionMeasurementR\x0cmeasurements\x12;\n\tbreakdown\x18\x02 \x01(\x0b2\x1d.waymo.open_dataset.BreakdownR\tbreakdown"

    measurements: "list[DetectionMeasurement]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )

    breakdown: "Breakdown | None" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    The breakdown the detection measurements are computed for.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "DetectionMeasurements", DetectionMeasurements
)


@dataclass(eq=False, repr=False)
class DetectionMetrics(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b'\n\x10DetectionMetrics\x124\n\x16mean_average_precision\x18\x01 \x01(\x02R\x14meanAveragePrecision\x12J\n"mean_average_precision_ha_weighted\x18\x02 \x01(\x02R\x1emeanAveragePrecisionHaWeighted\x12o\n5mean_average_precision_longitudinal_affinity_weighted\x18\n \x01(\x02R0meanAveragePrecisionLongitudinalAffinityWeighted\x12\x1e\n\nprecisions\x18\x03 \x03(\x02R\nprecisions\x12\x18\n\x07recalls\x18\x04 \x03(\x02R\x07recalls\x124\n\x16precisions_ha_weighted\x18\x05 \x03(\x02R\x14precisionsHaWeighted\x12.\n\x13recalls_ha_weighted\x18\x06 \x03(\x02R\x11recallsHaWeighted\x12Y\n)precisions_longitudinal_affinity_weighted\x18\x0b \x03(\x02R&precisionsLongitudinalAffinityWeighted\x12S\n&recalls_longitudinal_affinity_weighted\x18\x0c \x03(\x02R#recallsLongitudinalAffinityWeighted\x12#\n\rscore_cutoffs\x18\x07 \x03(\x02R\x0cscoreCutoffs\x12;\n\tbreakdown\x18\x08 \x01(\x0b2\x1d.waymo.open_dataset.BreakdownR\tbreakdown\x12M\n\x0cmeasurements\x18\t \x01(\x0b2).waymo.open_dataset.DetectionMeasurementsR\x0cmeasurements'

    mean_average_precision: "float" = betterproto2.field(1, betterproto2.TYPE_FLOAT)

    mean_average_precision_ha_weighted: "float" = betterproto2.field(
        2, betterproto2.TYPE_FLOAT
    )
    """
    Heading accuracy weighted mean average precision.
    """

    mean_average_precision_longitudinal_affinity_weighted: "float" = betterproto2.field(
        10, betterproto2.TYPE_FLOAT
    )
    """
    Longitudinal affinity weighted mean average precision.
    """

    precisions: "list[float]" = betterproto2.field(
        3, betterproto2.TYPE_FLOAT, repeated=True
    )

    recalls: "list[float]" = betterproto2.field(
        4, betterproto2.TYPE_FLOAT, repeated=True
    )

    precisions_ha_weighted: "list[float]" = betterproto2.field(
        5, betterproto2.TYPE_FLOAT, repeated=True
    )

    recalls_ha_weighted: "list[float]" = betterproto2.field(
        6, betterproto2.TYPE_FLOAT, repeated=True
    )

    precisions_longitudinal_affinity_weighted: "list[float]" = betterproto2.field(
        11, betterproto2.TYPE_FLOAT, repeated=True
    )

    recalls_longitudinal_affinity_weighted: "list[float]" = betterproto2.field(
        12, betterproto2.TYPE_FLOAT, repeated=True
    )

    score_cutoffs: "list[float]" = betterproto2.field(
        7, betterproto2.TYPE_FLOAT, repeated=True
    )

    breakdown: "Breakdown | None" = betterproto2.field(
        8, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    The breakdown the detection metrics are computed for.
    """

    measurements: "DetectionMeasurements | None" = betterproto2.field(
        9, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Raw measurements.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "DetectionMetrics", DetectionMetrics
)


@dataclass(eq=False, repr=False)
class Difficulty(betterproto2.Message):
    """
    A set of difficulty levels.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\nDifficulty\x12A\n\x06levels\x18\x01 \x03(\x0e2).waymo.open_dataset.Label.DifficultyLevelR\x06levels"

    levels: "list[LabelDifficultyLevel]" = betterproto2.field(
        1, betterproto2.TYPE_ENUM, repeated=True
    )
    """
    If no levels are set, the highest difficulty level is assumed.
    """


default_message_pool.register_message("waymo.open_dataset", "Difficulty", Difficulty)


@dataclass(eq=False, repr=False)
class Driveway(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x08Driveway\x126\n\x07polygon\x18\x01 \x03(\x0b2\x1c.waymo.open_dataset.MapPointR\x07polygon"

    polygon: "list[MapPoint]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The polygon defining the outline of the driveway region. The polygon is
    assumed to be closed (i.e. a segment exists between the last point and the
    first point).
    """


default_message_pool.register_message("waymo.open_dataset", "Driveway", Driveway)


@dataclass(eq=False, repr=False)
class DynamicMapState(betterproto2.Message):
    """
    The dynamic map information at a single time step.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x0fDynamicMapState\x12K\n\x0blane_states\x18\x01 \x03(\x0b2*.waymo.open_dataset.TrafficSignalLaneStateR\nlaneStates"

    lane_states: "list[TrafficSignalLaneState]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The traffic signal states for all observed signals at this time step.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "DynamicMapState", DynamicMapState
)


@dataclass(eq=False, repr=False)
class DynamicState(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x0cDynamicState\x12+\n\x11timestamp_seconds\x18\x01 \x01(\x01R\x10timestampSeconds\x12K\n\x0blane_states\x18\x02 \x03(\x0b2*.waymo.open_dataset.TrafficSignalLaneStateR\nlaneStates"

    timestamp_seconds: "float" = betterproto2.field(1, betterproto2.TYPE_DOUBLE)
    """
    The timestamp associated with the dynamic feature data.
    """

    lane_states: "list[TrafficSignalLaneState]" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The set of traffic signal states for the associated time step.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "DynamicState", DynamicState
)


@dataclass(eq=False, repr=False)
class Frame(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b'\n\x05Frame\x125\n\x07context\x18\x01 \x01(\x0b2\x1b.waymo.open_dataset.ContextR\x07context\x12)\n\x10timestamp_micros\x18\x02 \x01(\x03R\x0ftimestampMicros\x121\n\x04pose\x18\x03 \x01(\x0b2\x1d.waymo.open_dataset.TransformR\x04pose\x127\n\x06images\x18\x04 \x03(\x0b2\x1f.waymo.open_dataset.CameraImageR\x06images\x121\n\x06lasers\x18\x05 \x03(\x0b2\x19.waymo.open_dataset.LaserR\x06lasers\x12<\n\x0claser_labels\x18\x06 \x03(\x0b2\x19.waymo.open_dataset.LabelR\x0blaserLabels\x12V\n\x16projected_lidar_labels\x18\t \x03(\x0b2 .waymo.open_dataset.CameraLabelsR\x14projectedLidarLabels\x12E\n\rcamera_labels\x18\x08 \x03(\x0b2 .waymo.open_dataset.CameraLabelsR\x0ccameraLabels\x12H\n\x0eno_label_zones\x18\x07 \x03(\x0b2".waymo.open_dataset.Polygon2dProtoR\x0cnoLabelZones\x12A\n\x0cmap_features\x18\n \x03(\x0b2\x1e.waymo.open_dataset.MapFeatureR\x0bmapFeatures\x12D\n\x0fmap_pose_offset\x18\x0b \x01(\x0b2\x1c.waymo.open_dataset.Vector3dR\rmapPoseOffset*\t\x08\xe8\x07\x10\x80\x80\x80\x80\x02'

    context: "Context | None" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    This context is the same for all frames belong to the same driving run
    segment. Use context.name to identify frames belong to the same driving
    segment. We do not store all frames from one driving segment in one proto
    to avoid huge protos.
    """

    timestamp_micros: "int" = betterproto2.field(2, betterproto2.TYPE_INT64)
    """
    Frame start time, which is the timestamp of the first top LiDAR scan
    within this frame. Note that this timestamp does not correspond to the
    provided vehicle pose (pose).
    """

    pose: "Transform | None" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Frame vehicle pose. Note that unlike in CameraImage, the Frame pose does
    not correspond to the provided timestamp (timestamp_micros). Instead, it
    roughly (but not exactly) corresponds to the vehicle pose in the middle of
    the given frame. The frame vehicle pose defines the coordinate system which
    the 3D laser labels are defined in.
    """

    images: "list[CameraImage]" = betterproto2.field(
        4, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The camera images.
    """

    lasers: "list[Laser]" = betterproto2.field(
        5, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The LiDAR sensor data.
    """

    laser_labels: "list[Label]" = betterproto2.field(
        6, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    Native 3D labels that correspond to the LiDAR sensor data. The 3D labels
    are defined w.r.t. the frame vehicle pose coordinate system (pose).
    """

    projected_lidar_labels: "list[CameraLabels]" = betterproto2.field(
        9, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The native 3D LiDAR labels (laser_labels) projected to camera images. A
    projected label is the smallest image axis aligned rectangle that can cover
    all projected points from the 3d LiDAR label. The projected label is
    ignored if the projection is fully outside a camera image. The projected
    label is clamped to the camera image if it is partially outside.
    """

    camera_labels: "list[CameraLabels]" = betterproto2.field(
        8, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    Native 2D camera labels. Note that if a camera identified by
    CameraLabels.name has an entry in this field, then it has been labeled,
    even though it is possible that there are no labeled objects in the
    corresponding image, which is identified by a zero sized
    CameraLabels.labels.
    """

    no_label_zones: "list[Polygon2DProto]" = betterproto2.field(
        7, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    No label zones in the *global* frame.
    """

    map_features: "list[MapFeature]" = betterproto2.field(
        10, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    Map features. Only the first frame in a segment will contain map data. This
    field will be empty for other frames as the map is identical for all
    frames.
    """

    map_pose_offset: "Vector3D | None" = betterproto2.field(
        11, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Map pose offset. This offset must be added to lidar points from this frame
    to compensate for pose drift and align with the map features.
    """


default_message_pool.register_message("waymo.open_dataset", "Frame", Frame)


@dataclass(eq=False, repr=False)
class FrameCameraTokens(betterproto2.Message):
    """
    Camera tokens for all sensors of a frame.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x11FrameCameraTokens\x12E\n\rcamera_tokens\x18\x01 \x03(\x0b2 .waymo.open_dataset.CameraTokensR\x0ccameraTokens"

    camera_tokens: "list[CameraTokens]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    Camera tokens for all sensors in a frame.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "FrameCameraTokens", FrameCameraTokens
)


@dataclass(eq=False, repr=False)
class JointPrediction(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x0fJointPrediction\x12X\n\x12joint_trajectories\x18\x01 \x03(\x0b2).waymo.open_dataset.ScoredJointTrajectoryR\x11jointTrajectories"

    joint_trajectories: "list[ScoredJointTrajectory]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    A set of up to 6 predictions with varying confidences - all for the same
    pair of objects. All prediction entries must contain trajectories for the
    same set of objects or an error will be returned. Any joint predictions
    past the first six will be discarded.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "JointPrediction", JointPrediction
)


@dataclass(eq=False, repr=False)
class JointScene(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\nJointScene\x12^\n\x16simulated_trajectories\x18\x01 \x03(\x0b2'.waymo.open_dataset.SimulatedTrajectoryR\x15simulatedTrajectories"

    simulated_trajectories: "list[SimulatedTrajectory]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    Collection of simulated objects trajectories defining a full simulated
    scene. This needs to be the product of a joint simulation of all the
    included objects. An object is to be included if is valid in the last
    history step of the original scenario (11th step).
    """


default_message_pool.register_message("waymo.open_dataset", "JointScene", JointScene)


@dataclass(eq=False, repr=False)
class JointTrajectories(betterproto2.Message):
    """
    A message containing a prediction for either a single object or a joint
    prediction for a set of objects.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x11JointTrajectories\x12H\n\x0ctrajectories\x18\x02 \x03(\x0b2$.waymo.open_dataset.SingleTrajectoryR\x0ctrajectories\x12\x1e\n\nconfidence\x18\x03 \x01(\x02R\nconfidence"

    trajectories: "list[SingleTrajectory]" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The trajectories for each object in the set being predicted. This may
    contain a single trajectory for a single object or a set of trajectories
    representing a joint prediction of a set of objects.
    """

    confidence: "float" = betterproto2.field(3, betterproto2.TYPE_FLOAT)
    """
    An optional confidence measure for this prediction.
    These should not be normalized across the set of trajectories.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "JointTrajectories", JointTrajectories
)


@dataclass(eq=False, repr=False)
class Label(betterproto2.Message):
    """


    Oneofs:
        - keypoints_oneof:
    """

    @staticmethod
    def _serialized_pb():
        return b'\n\x05Label\x12/\n\x03box\x18\x01 \x01(\x0b2\x1d.waymo.open_dataset.Label.BoxR\x03box\x12>\n\x08metadata\x18\x02 \x01(\x0b2".waymo.open_dataset.Label.MetadataR\x08metadata\x122\n\x04type\x18\x03 \x01(\x0e2\x1e.waymo.open_dataset.Label.TypeR\x04type\x12\x0e\n\x02id\x18\x04 \x01(\tR\x02id\x12g\n\x1adetection_difficulty_level\x18\x05 \x01(\x0e2).waymo.open_dataset.Label.DifficultyLevelR\x18detectionDifficultyLevel\x12e\n\x19tracking_difficulty_level\x18\x06 \x01(\x0e2).waymo.open_dataset.Label.DifficultyLevelR\x17trackingDifficultyLevel\x124\n\x17num_lidar_points_in_box\x18\x07 \x01(\x05R\x13numLidarPointsInBox\x12;\n\x1bnum_top_lidar_points_in_box\x18\r \x01(\x05R\x16numTopLidarPointsInBox\x12W\n\x0flaser_keypoints\x18\x08 \x01(\x0b2,.waymo.open_dataset.keypoints.LaserKeypointsH\x00R\x0elaserKeypoints\x12Z\n\x10camera_keypoints\x18\t \x01(\x0b2-.waymo.open_dataset.keypoints.CameraKeypointsH\x00R\x0fcameraKeypoints\x12G\n\x0bassociation\x18\n \x01(\x0b2%.waymo.open_dataset.Label.AssociationR\x0bassociation\x127\n\x18most_visible_camera_name\x18\x0b \x01(\tR\x15mostVisibleCameraName\x12I\n\x11camera_synced_box\x18\x0c \x01(\x0b2\x1d.waymo.open_dataset.Label.BoxR\x0fcameraSyncedBox\x1a\x88\x02\n\tLabel.Box\x12\x19\n\x08center_x\x18\x01 \x01(\x01R\x07centerX\x12\x19\n\x08center_y\x18\x02 \x01(\x01R\x07centerY\x12\x19\n\x08center_z\x18\x03 \x01(\x01R\x07centerZ\x12\x16\n\x06length\x18\x05 \x01(\x01R\x06length\x12\x14\n\x05width\x18\x04 \x01(\x01R\x05width\x12\x16\n\x06height\x18\x06 \x01(\x01R\x06height\x12\x18\n\x07heading\x18\x07 \x01(\x01R\x07heading"J\n\x0eLabel.Box.Type\x12\x0e\n\x0cTYPE_UNKNOWN\x12\x0b\n\x07TYPE_3D\x10\x01\x12\x0b\n\x07TYPE_2D\x10\x02\x12\x0e\n\nTYPE_AA_2D\x10\x03\x1a\xa6\x01\n\x0eLabel.Metadata\x12\x17\n\x07speed_x\x18\x01 \x01(\x01R\x06speedX\x12\x17\n\x07speed_y\x18\x02 \x01(\x01R\x06speedY\x12\x17\n\x07speed_z\x18\x05 \x01(\x01R\x06speedZ\x12\x17\n\x07accel_x\x18\x03 \x01(\x01R\x06accelX\x12\x17\n\x07accel_y\x18\x04 \x01(\x01R\x06accelY\x12\x17\n\x07accel_z\x18\x06 \x01(\x01R\x06accelZ\x1a;\n\x11Label.Association\x12&\n\x0flaser_object_id\x18\x01 \x01(\tR\rlaserObjectId"d\n\nLabel.Type\x12\x0e\n\x0cTYPE_UNKNOWN\x12\x10\n\x0cTYPE_VEHICLE\x10\x01\x12\x13\n\x0fTYPE_PEDESTRIAN\x10\x02\x12\r\n\tTYPE_SIGN\x10\x03\x12\x10\n\x0cTYPE_CYCLIST\x10\x04"<\n\x15Label.DifficultyLevel\x12\t\n\x07UNKNOWN\x12\x0b\n\x07LEVEL_1\x10\x01\x12\x0b\n\x07LEVEL_2\x10\x02B\x11\n\x0fkeypoints_oneof'

    box: "LabelBox | None" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, optional=True
    )

    metadata: "LabelMetadata | None" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, optional=True
    )

    type: "LabelType" = betterproto2.field(
        3, betterproto2.TYPE_ENUM, default_factory=lambda: LabelType(0)
    )

    id: "str" = betterproto2.field(4, betterproto2.TYPE_STRING)
    """
    Object ID.
    """

    detection_difficulty_level: "LabelDifficultyLevel" = betterproto2.field(
        5, betterproto2.TYPE_ENUM, default_factory=lambda: LabelDifficultyLevel(0)
    )
    """
    Difficulty level for detection problem.
    """

    tracking_difficulty_level: "LabelDifficultyLevel" = betterproto2.field(
        6, betterproto2.TYPE_ENUM, default_factory=lambda: LabelDifficultyLevel(0)
    )
    """
    Difficulty level for tracking problem.
    """

    num_lidar_points_in_box: "int" = betterproto2.field(7, betterproto2.TYPE_INT32)
    """
    The total number of lidar points in this box.
    """

    num_top_lidar_points_in_box: "int" = betterproto2.field(13, betterproto2.TYPE_INT32)
    """
    The total number of top lidar points in this box.
    """

    laser_keypoints: "keypoints.LaserKeypoints | None" = betterproto2.field(
        8, betterproto2.TYPE_MESSAGE, optional=True, group="keypoints_oneof"
    )
    """
    Used if the Label is a part of `Frame.laser_labels`.
    """

    camera_keypoints: "keypoints.CameraKeypoints | None" = betterproto2.field(
        9, betterproto2.TYPE_MESSAGE, optional=True, group="keypoints_oneof"
    )
    """
    Used if the Label is a part of `Frame.camera_labels`.
    """

    association: "LabelAssociation | None" = betterproto2.field(
        10, betterproto2.TYPE_MESSAGE, optional=True
    )

    most_visible_camera_name: "str" = betterproto2.field(11, betterproto2.TYPE_STRING)
    """
    Used by Lidar labels to store in which camera it is mostly visible.
    """

    camera_synced_box: "LabelBox | None" = betterproto2.field(
        12, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Used by Lidar labels to store a camera-synchronized box corresponding to
    the camera indicated by `most_visible_camera_name`. Currently, the boxes
    are shifted to the time when the most visible camera captures the center of
    the box, taking into account the rolling shutter of that camera.
    Specifically, given the object box living at the start of the Open Dataset
    frame (t_frame) with center position (c) and velocity (v), we aim to find
    the camera capture time (t_capture), when the camera indicated by
    `most_visible_camera_name` captures the center of the object. To this end,
     we solve the rolling shutter optimization considering both ego and object
     motion:
      t_capture = image_column_to_time(
          camera_projection(c + v * (t_capture - t_frame),
                            transform_vehicle(t_capture - t_ref),
                            cam_params)),
    where transform_vehicle(t_capture - t_frame) is the vehicle transform from
    a pose reference time t_ref to t_capture considering the ego motion, and
    cam_params is the camera extrinsic and intrinsic parameters.
    We then move the label box to t_capture by updating the center of the box
    as follows:
      c_camra_synced = c + v * (t_capture - t_frame),
    while keeping the box dimensions and heading direction.
    We use the camera_synced_box as the ground truth box for the 3D Camera-Only
    Detection Challenge. This makes the assumption that the users provide the
    detection at the same time as the most visible camera captures the object
    center.
    """


default_message_pool.register_message("waymo.open_dataset", "Label", Label)


@dataclass(eq=False, repr=False)
class LabelAssociation(betterproto2.Message):
    """
    Information to cross reference between labels for different modalities.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x11Label.Association\x12&\n\x0flaser_object_id\x18\x01 \x01(\tR\rlaserObjectId"

    laser_object_id: "str" = betterproto2.field(1, betterproto2.TYPE_STRING)
    """
    Currently only CameraLabels with class `TYPE_PEDESTRIAN` store
    information about associated lidar objects.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "Label.Association", LabelAssociation
)


@dataclass(eq=False, repr=False)
class LabelBox(betterproto2.Message):
    """
    Upright box, zero pitch and roll.
    """

    @staticmethod
    def _serialized_pb():
        return b'\n\tLabel.Box\x12\x19\n\x08center_x\x18\x01 \x01(\x01R\x07centerX\x12\x19\n\x08center_y\x18\x02 \x01(\x01R\x07centerY\x12\x19\n\x08center_z\x18\x03 \x01(\x01R\x07centerZ\x12\x16\n\x06length\x18\x05 \x01(\x01R\x06length\x12\x14\n\x05width\x18\x04 \x01(\x01R\x05width\x12\x16\n\x06height\x18\x06 \x01(\x01R\x06height\x12\x18\n\x07heading\x18\x07 \x01(\x01R\x07heading"J\n\x0eLabel.Box.Type\x12\x0e\n\x0cTYPE_UNKNOWN\x12\x0b\n\x07TYPE_3D\x10\x01\x12\x0b\n\x07TYPE_2D\x10\x02\x12\x0e\n\nTYPE_AA_2D\x10\x03'

    center_x: "float" = betterproto2.field(1, betterproto2.TYPE_DOUBLE)
    """
    Box coordinates in vehicle frame.
    """

    center_y: "float" = betterproto2.field(2, betterproto2.TYPE_DOUBLE)

    center_z: "float" = betterproto2.field(3, betterproto2.TYPE_DOUBLE)

    length: "float" = betterproto2.field(5, betterproto2.TYPE_DOUBLE)
    """
    Dimensions of the box. length: dim x. width: dim y. height: dim z.
    """

    width: "float" = betterproto2.field(4, betterproto2.TYPE_DOUBLE)

    height: "float" = betterproto2.field(6, betterproto2.TYPE_DOUBLE)

    heading: "float" = betterproto2.field(7, betterproto2.TYPE_DOUBLE)
    """
    The heading of the bounding box (in radians).  The heading is the angle
    required to rotate +x to the surface normal of the box front face. It is
    normalized to [-pi, pi).
    """


default_message_pool.register_message("waymo.open_dataset", "Label.Box", LabelBox)


@dataclass(eq=False, repr=False)
class LabelMetadata(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x0eLabel.Metadata\x12\x17\n\x07speed_x\x18\x01 \x01(\x01R\x06speedX\x12\x17\n\x07speed_y\x18\x02 \x01(\x01R\x06speedY\x12\x17\n\x07speed_z\x18\x05 \x01(\x01R\x06speedZ\x12\x17\n\x07accel_x\x18\x03 \x01(\x01R\x06accelX\x12\x17\n\x07accel_y\x18\x04 \x01(\x01R\x06accelY\x12\x17\n\x07accel_z\x18\x06 \x01(\x01R\x06accelZ"

    speed_x: "float" = betterproto2.field(1, betterproto2.TYPE_DOUBLE)

    speed_y: "float" = betterproto2.field(2, betterproto2.TYPE_DOUBLE)

    speed_z: "float" = betterproto2.field(5, betterproto2.TYPE_DOUBLE)

    accel_x: "float" = betterproto2.field(3, betterproto2.TYPE_DOUBLE)

    accel_y: "float" = betterproto2.field(4, betterproto2.TYPE_DOUBLE)

    accel_z: "float" = betterproto2.field(6, betterproto2.TYPE_DOUBLE)


default_message_pool.register_message(
    "waymo.open_dataset", "Label.Metadata", LabelMetadata
)


@dataclass(eq=False, repr=False)
class LaneCenter(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\nLaneCenter\x12&\n\x0fspeed_limit_mph\x18\x01 \x01(\x01R\rspeedLimitMph\x12;\n\x04type\x18\x02 \x01(\x0e2'.waymo.open_dataset.LaneCenter.LaneTypeR\x04type\x12$\n\rinterpolating\x18\x03 \x01(\x08R\rinterpolating\x128\n\x08polyline\x18\x08 \x03(\x0b2\x1c.waymo.open_dataset.MapPointR\x08polyline\x12#\n\x0bentry_lanes\x18\t \x03(\x03R\nentryLanesB\x02\x10\x01\x12!\n\nexit_lanes\x18\n \x03(\x03R\texitLanesB\x02\x10\x01\x12L\n\x0fleft_boundaries\x18\r \x03(\x0b2#.waymo.open_dataset.BoundarySegmentR\x0eleftBoundaries\x12N\n\x10right_boundaries\x18\x0e \x03(\x0b2#.waymo.open_dataset.BoundarySegmentR\x0frightBoundaries\x12G\n\x0eleft_neighbors\x18\x0b \x03(\x0b2 .waymo.open_dataset.LaneNeighborR\rleftNeighbors\x12I\n\x0fright_neighbors\x18\x0c \x03(\x0b2 .waymo.open_dataset.LaneNeighborR\x0erightNeighbors\"f\n\x13LaneCenter.LaneType\x12\x10\n\x0eTYPE_UNDEFINED\x12\x10\n\x0cTYPE_FREEWAY\x10\x01\x12\x17\n\x13TYPE_SURFACE_STREET\x10\x02\x12\x12\n\x0eTYPE_BIKE_LANE\x10\x03"

    speed_limit_mph: "float" = betterproto2.field(1, betterproto2.TYPE_DOUBLE)
    """
    The speed limit for this lane.
    """

    type: "LaneCenterLaneType" = betterproto2.field(
        2, betterproto2.TYPE_ENUM, default_factory=lambda: LaneCenterLaneType(0)
    )

    interpolating: "bool" = betterproto2.field(3, betterproto2.TYPE_BOOL)
    """
    True if the lane interpolates between two other lanes.
    """

    polyline: "list[MapPoint]" = betterproto2.field(
        8, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The polyline data for the lane. A polyline is a list of points with
    segments defined between consecutive points.
    """

    entry_lanes: "list[int]" = betterproto2.field(
        9, betterproto2.TYPE_INT64, repeated=True
    )
    """
    A list of IDs for lanes that this lane may be entered from.
    """

    exit_lanes: "list[int]" = betterproto2.field(
        10, betterproto2.TYPE_INT64, repeated=True
    )
    """
    A list of IDs for lanes that this lane may exit to.
    """

    left_boundaries: "list[BoundarySegment]" = betterproto2.field(
        13, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The boundaries to the left of this lane. There may be different boundary
    types along this lane. Each BoundarySegment defines a section of the lane
    with a given boundary feature to the left. Note that some lanes do not have
    any boundaries (i.e. lane centers in intersections).
    """

    right_boundaries: "list[BoundarySegment]" = betterproto2.field(
        14, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The boundaries to the right of this lane. See left_boundaries for details.
    """

    left_neighbors: "list[LaneNeighbor]" = betterproto2.field(
        11, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    A list of neighbors to the left of this lane. Neighbor lanes
    include only adjacent lanes going the same direction.
    """

    right_neighbors: "list[LaneNeighbor]" = betterproto2.field(
        12, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    A list of neighbors to the right of this lane. Neighbor lanes
    include only adjacent lanes going the same direction.
    """


default_message_pool.register_message("waymo.open_dataset", "LaneCenter", LaneCenter)


@dataclass(eq=False, repr=False)
class LaneNeighbor(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x0cLaneNeighbor\x12\x1d\n\nfeature_id\x18\x01 \x01(\x03R\tfeatureId\x12(\n\x10self_start_index\x18\x02 \x01(\x05R\x0eselfStartIndex\x12$\n\x0eself_end_index\x18\x03 \x01(\x05R\x0cselfEndIndex\x120\n\x14neighbor_start_index\x18\x04 \x01(\x05R\x12neighborStartIndex\x12,\n\x12neighbor_end_index\x18\x05 \x01(\x05R\x10neighborEndIndex\x12C\n\nboundaries\x18\x06 \x03(\x0b2#.waymo.open_dataset.BoundarySegmentR\nboundaries"

    feature_id: "int" = betterproto2.field(1, betterproto2.TYPE_INT64)
    """
    The feature ID of the neighbor lane.
    """

    self_start_index: "int" = betterproto2.field(2, betterproto2.TYPE_INT32)
    """
    The self adjacency segment.
    The other lane may only be a neighbor for only part of this lane. These
    indices define the points within this lane's polyline for which feature_id
    is a neighbor. If the lanes are neighbors at disjoint places (e.g., a
    median between them appears and then goes away) multiple neighbors will be
    listed. A lane change can only happen from this segment of this lane into
    the segment of the neighbor lane defined by neighbor_start_index and
    neighbor_end_index.
    """

    self_end_index: "int" = betterproto2.field(3, betterproto2.TYPE_INT32)

    neighbor_start_index: "int" = betterproto2.field(4, betterproto2.TYPE_INT32)
    """
    The neighbor adjacency segment.
    These indices define the valid portion of the neighbor lane's polyline
    where that lane is a neighbor to this lane. A lane change can only happen
    into this segment of the neighbor lane from the segment of this lane
    defined by self_start_index and self_end_index.
    """

    neighbor_end_index: "int" = betterproto2.field(5, betterproto2.TYPE_INT32)

    boundaries: "list[BoundarySegment]" = betterproto2.field(
        6, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    A list of segments within the self adjacency segment that have different
    boundaries between this lane and the neighbor lane. Each entry in this
    field contains the boundary type between this lane and the neighbor lane
    along with the indices into this lane's polyline where the boundary type
    begins and ends.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "LaneNeighbor", LaneNeighbor
)


@dataclass(eq=False, repr=False)
class Laser(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b'\n\x05Laser\x126\n\x04name\x18\x01 \x01(\x0e2".waymo.open_dataset.LaserName.NameR\x04name\x12=\n\nri_return1\x18\x02 \x01(\x0b2\x1e.waymo.open_dataset.RangeImageR\triReturn1\x12=\n\nri_return2\x18\x03 \x01(\x0b2\x1e.waymo.open_dataset.RangeImageR\triReturn2'

    name: "LaserNameName" = betterproto2.field(
        1, betterproto2.TYPE_ENUM, default_factory=lambda: LaserNameName(0)
    )

    ri_return1: "RangeImage | None" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, optional=True
    )

    ri_return2: "RangeImage | None" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, optional=True
    )


default_message_pool.register_message("waymo.open_dataset", "Laser", Laser)


@dataclass(eq=False, repr=False)
class LaserCalibration(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b'\n\x10LaserCalibration\x126\n\x04name\x18\x01 \x01(\x0e2".waymo.open_dataset.LaserName.NameR\x04name\x12+\n\x11beam_inclinations\x18\x02 \x03(\x01R\x10beamInclinations\x120\n\x14beam_inclination_min\x18\x03 \x01(\x01R\x12beamInclinationMin\x120\n\x14beam_inclination_max\x18\x04 \x01(\x01R\x12beamInclinationMax\x12;\n\textrinsic\x18\x05 \x01(\x0b2\x1d.waymo.open_dataset.TransformR\textrinsic'

    name: "LaserNameName" = betterproto2.field(
        1, betterproto2.TYPE_ENUM, default_factory=lambda: LaserNameName(0)
    )

    beam_inclinations: "list[float]" = betterproto2.field(
        2, betterproto2.TYPE_DOUBLE, repeated=True
    )
    """
    If non-empty, the beam pitch (in radians) is non-uniform. When constructing
    a range image, this mapping is used to map from beam pitch to range image
    row.  If this is empty, we assume a uniform distribution.
    """

    beam_inclination_min: "float" = betterproto2.field(3, betterproto2.TYPE_DOUBLE)
    """
    beam_inclination_{min,max} (in radians) are used to determine the mapping.
    """

    beam_inclination_max: "float" = betterproto2.field(4, betterproto2.TYPE_DOUBLE)

    extrinsic: "Transform | None" = betterproto2.field(
        5, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Lidar frame to vehicle frame.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "LaserCalibration", LaserCalibration
)


@dataclass(eq=False, repr=False)
class LaserName(betterproto2.Message):
    """
    'Laser' is used interchangeably with 'Lidar' in this file.
    """

    @staticmethod
    def _serialized_pb():
        return b'\n\tLaserName"X\n\x0eLaserName.Name\x12\t\n\x07UNKNOWN\x12\x07\n\x03TOP\x10\x01\x12\t\n\x05FRONT\x10\x02\x12\r\n\tSIDE_LEFT\x10\x03\x12\x0e\n\nSIDE_RIGHT\x10\x04\x12\x08\n\x04REAR\x10\x05'

    pass


default_message_pool.register_message("waymo.open_dataset", "LaserName", LaserName)


@dataclass(eq=False, repr=False)
class Map(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x03Map\x12A\n\x0cmap_features\x18\x01 \x03(\x0b2\x1e.waymo.open_dataset.MapFeatureR\x0bmapFeatures\x12G\n\x0edynamic_states\x18\x02 \x03(\x0b2 .waymo.open_dataset.DynamicStateR\rdynamicStates"

    map_features: "list[MapFeature]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The full set of map features.
    """

    dynamic_states: "list[DynamicState]" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    A set of dynamic states per time step. These are ordered in consecutive
    time steps.
    """


default_message_pool.register_message("waymo.open_dataset", "Map", Map)


@dataclass(eq=False, repr=False)
class MapFeature(betterproto2.Message):
    """


    Oneofs:
        - feature_data: Type specific data.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\nMapFeature\x12\x0e\n\x02id\x18\x01 \x01(\x03R\x02id\x124\n\x04lane\x18\x03 \x01(\x0b2\x1e.waymo.open_dataset.LaneCenterH\x00R\x04lane\x12;\n\troad_line\x18\x04 \x01(\x0b2\x1c.waymo.open_dataset.RoadLineH\x00R\x08roadLine\x12;\n\troad_edge\x18\x05 \x01(\x0b2\x1c.waymo.open_dataset.RoadEdgeH\x00R\x08roadEdge\x12;\n\tstop_sign\x18\x07 \x01(\x0b2\x1c.waymo.open_dataset.StopSignH\x00R\x08stopSign\x12=\n\tcrosswalk\x18\x08 \x01(\x0b2\x1d.waymo.open_dataset.CrosswalkH\x00R\tcrosswalk\x12>\n\nspeed_bump\x18\t \x01(\x0b2\x1d.waymo.open_dataset.SpeedBumpH\x00R\tspeedBump\x12:\n\x08driveway\x18\n \x01(\x0b2\x1c.waymo.open_dataset.DrivewayH\x00R\x08drivewayB\x0e\n\x0cfeature_data"

    id: "int" = betterproto2.field(1, betterproto2.TYPE_INT64)
    """
    A unique ID to identify this feature.
    """

    lane: "LaneCenter | None" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, optional=True, group="feature_data"
    )

    road_line: "RoadLine | None" = betterproto2.field(
        4, betterproto2.TYPE_MESSAGE, optional=True, group="feature_data"
    )

    road_edge: "RoadEdge | None" = betterproto2.field(
        5, betterproto2.TYPE_MESSAGE, optional=True, group="feature_data"
    )

    stop_sign: "StopSign | None" = betterproto2.field(
        7, betterproto2.TYPE_MESSAGE, optional=True, group="feature_data"
    )

    crosswalk: "Crosswalk | None" = betterproto2.field(
        8, betterproto2.TYPE_MESSAGE, optional=True, group="feature_data"
    )

    speed_bump: "SpeedBump | None" = betterproto2.field(
        9, betterproto2.TYPE_MESSAGE, optional=True, group="feature_data"
    )

    driveway: "Driveway | None" = betterproto2.field(
        10, betterproto2.TYPE_MESSAGE, optional=True, group="feature_data"
    )


default_message_pool.register_message("waymo.open_dataset", "MapFeature", MapFeature)


@dataclass(eq=False, repr=False)
class MapPoint(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x08MapPoint\x12\x0c\n\x01x\x18\x01 \x01(\x01R\x01x\x12\x0c\n\x01y\x18\x02 \x01(\x01R\x01y\x12\x0c\n\x01z\x18\x03 \x01(\x01R\x01z"

    x: "float" = betterproto2.field(1, betterproto2.TYPE_DOUBLE)
    """
    Position in meters. The origin is an arbitrary location.
    """

    y: "float" = betterproto2.field(2, betterproto2.TYPE_DOUBLE)

    z: "float" = betterproto2.field(3, betterproto2.TYPE_DOUBLE)


default_message_pool.register_message("waymo.open_dataset", "MapPoint", MapPoint)


@dataclass(eq=False, repr=False)
class MatcherProto(betterproto2.Message):
    """
    Different types of matchers can be supported. Each matcher has a unique ID.
    """

    @staticmethod
    def _serialized_pb():
        return b'\n\x0cMatcherProto"k\n\x11MatcherProto.Type\x12\x0e\n\x0cTYPE_UNKNOWN\x12\x12\n\x0eTYPE_HUNGARIAN\x10\x01\x12\x14\n\x10TYPE_SCORE_FIRST\x10\x02\x12\x1c\n\x18TYPE_HUNGARIAN_TEST_ONLY\x10d'

    pass


default_message_pool.register_message(
    "waymo.open_dataset", "MatcherProto", MatcherProto
)


@dataclass(eq=False, repr=False)
class MatrixFloat(betterproto2.Message):
    """
    Row-major matrix.
    Requires: data.size() = product(shape.dims()).
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x0bMatrixFloat\x12\x16\n\x04data\x18\x01 \x03(\x02R\x04dataB\x02\x10\x01\x125\n\x05shape\x18\x02 \x01(\x0b2\x1f.waymo.open_dataset.MatrixShapeR\x05shape"

    data: "list[float]" = betterproto2.field(1, betterproto2.TYPE_FLOAT, repeated=True)

    shape: "MatrixShape | None" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, optional=True
    )


default_message_pool.register_message("waymo.open_dataset", "MatrixFloat", MatrixFloat)


@dataclass(eq=False, repr=False)
class MatrixInt32(betterproto2.Message):
    """
    Row-major matrix.
    Requires: data.size() = product(shape.dims()).
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x0bMatrixInt32\x12\x16\n\x04data\x18\x01 \x03(\x05R\x04dataB\x02\x10\x01\x125\n\x05shape\x18\x02 \x01(\x0b2\x1f.waymo.open_dataset.MatrixShapeR\x05shape"

    data: "list[int]" = betterproto2.field(1, betterproto2.TYPE_INT32, repeated=True)

    shape: "MatrixShape | None" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, optional=True
    )


default_message_pool.register_message("waymo.open_dataset", "MatrixInt32", MatrixInt32)


@dataclass(eq=False, repr=False)
class MatrixShape(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x0bMatrixShape\x12\x12\n\x04dims\x18\x01 \x03(\x05R\x04dims"

    dims: "list[int]" = betterproto2.field(1, betterproto2.TYPE_INT32, repeated=True)
    """
    Dimensions for the Matrix messages defined below. Must not be empty.

    The order of entries in 'dims' matters, as it indicates the layout of the
    values in the tensor in-memory representation.

    The first entry in 'dims' is the outermost dimension used to lay out the
    values; the last entry is the innermost dimension.  This matches the
    in-memory layout of row-major matrices.
    """


default_message_pool.register_message("waymo.open_dataset", "MatrixShape", MatrixShape)


@dataclass(eq=False, repr=False)
class Metadata(betterproto2.Message):
    """
    Metadata used for delta encoder.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x08Metadata\x12\x14\n\x05shape\x18\x01 \x03(\x05R\x05shape\x12'\n\x0fquant_precision\x18\x02 \x03(\x02R\x0equantPrecision"

    shape: "list[int]" = betterproto2.field(1, betterproto2.TYPE_INT32, repeated=True)
    """
    Range image's shape information in the compressed data.
    """

    quant_precision: "list[float]" = betterproto2.field(
        2, betterproto2.TYPE_FLOAT, repeated=True
    )
    """
    Range image quantization precision for each range image channel.
    """


default_message_pool.register_message("waymo.open_dataset", "Metadata", Metadata)


@dataclass(eq=False, repr=False)
class MotionChallengeSubmission(betterproto2.Message):
    """
    A set of ScenarioPredictions protos. A ScenarioPredictions proto for each
    example in the test or validation set must be included for a valid
    submission.
    """

    @staticmethod
    def _serialized_pb():
        return b'\n\x19MotionChallengeSubmission\x12!\n\x0caccount_name\x18\x03 \x01(\tR\x0baccountName\x12,\n\x12unique_method_name\x18\x04 \x01(\tR\x10uniqueMethodName\x12\x18\n\x07authors\x18\x05 \x03(\tR\x07authors\x12 \n\x0baffiliation\x18\x06 \x01(\tR\x0baffiliation\x12 \n\x0bdescription\x18\x07 \x01(\tR\x0bdescription\x12\x1f\n\x0bmethod_link\x18\x08 \x01(\tR\nmethodLink\x12e\n\x0fsubmission_type\x18\x02 \x01(\x0e2<.waymo.open_dataset.MotionChallengeSubmission.SubmissionTypeR\x0esubmissionType\x12&\n\x0fuses_lidar_data\x18\t \x01(\x08R\rusesLidarData\x12(\n\x10uses_camera_data\x18\n \x01(\x08R\x0eusesCameraData\x12A\n\x1duses_public_model_pretraining\x18\x0b \x01(\x08R\x1ausesPublicModelPretraining\x12,\n\x12public_model_names\x18\r \x03(\tR\x10publicModelNames\x120\n\x14num_model_parameters\x18\x0c \x01(\tR\x12numModelParameters\x12c\n\x14scenario_predictions\x18\x01 \x03(\x0b20.waymo.open_dataset.ChallengeScenarioPredictionsR\x13scenarioPredictions"h\n(MotionChallengeSubmission.SubmissionType\x12\t\n\x07UNKNOWN\x12\x15\n\x11MOTION_PREDICTION\x10\x01\x12\x1a\n\x16INTERACTION_PREDICTION\x10\x02'

    account_name: "str" = betterproto2.field(3, betterproto2.TYPE_STRING)
    """
    This must be set as the full email used to register at waymo.com/open.
    """

    unique_method_name: "str" = betterproto2.field(4, betterproto2.TYPE_STRING)
    """
    This name needs to be short, descriptive and unique. Only the latest result
    of the method from a user will show up on the leaderboard.
    """

    authors: "list[str]" = betterproto2.field(
        5, betterproto2.TYPE_STRING, repeated=True
    )
    """
    Author information.
    """

    affiliation: "str" = betterproto2.field(6, betterproto2.TYPE_STRING)

    description: "str" = betterproto2.field(7, betterproto2.TYPE_STRING)
    """
    A brief description of the method.
    """

    method_link: "str" = betterproto2.field(8, betterproto2.TYPE_STRING)
    """
    Link to paper or other link that describes the method.
    """

    submission_type: "MotionChallengeSubmissionSubmissionType" = betterproto2.field(
        2,
        betterproto2.TYPE_ENUM,
        default_factory=lambda: MotionChallengeSubmissionSubmissionType(0),
    )
    """
    The challenge submission type.
    """

    uses_lidar_data: "bool" = betterproto2.field(9, betterproto2.TYPE_BOOL)
    """
    Set this to true if your model uses the lidar data provided in the motion
    dataset. This field is now REQUIRED for a valid submission.
    """

    uses_camera_data: "bool" = betterproto2.field(10, betterproto2.TYPE_BOOL)
    """
    Set this to true if your model uses the camera data provided in the motion
    dataset. This field is now REQUIRED for a valid submission.
    """

    uses_public_model_pretraining: "bool" = betterproto2.field(
        11, betterproto2.TYPE_BOOL
    )
    """
    Set this to true if your model used publicly available open-source
    LLM/VLM(s) for pre-training. This field is now REQUIRED for a valid
    submission.
    """

    public_model_names: "list[str]" = betterproto2.field(
        13, betterproto2.TYPE_STRING, repeated=True
    )
    """
    If any open-source model was used, specify their names and configuration.
    """

    num_model_parameters: "str" = betterproto2.field(12, betterproto2.TYPE_STRING)
    """
    Specify an estimate of the number of parameters of the model used to
    generate this submission. The number must be specified as an integer number
    followed by a multiplier suffix (from the set [K, M, B, T, ...], e.g.
    "200K"). This field is now REQUIRED for a valid submission.
    """

    scenario_predictions: "list[ChallengeScenarioPredictions]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The set of scenario predictions to evaluate. One entry should exist for
    every record in the test set.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "MotionChallengeSubmission", MotionChallengeSubmission
)


@dataclass(eq=False, repr=False)
class MotionExampleConversionConfig(betterproto2.Message):
    """
    A configuration for converting Scenario protos to tf.Example protos.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x1dMotionExampleConversionConfig\x12)\n\x0emax_num_agents\x18\x01 \x01(\x05:\x03128R\x0cmaxNumAgents\x126\n\x16max_num_modeled_agents\x18\n \x01(\x05:\x018R\x13maxNumModeledAgents\x12(\n\x0enum_past_steps\x18\x02 \x01(\x05:\x0211R\x0cnumPastSteps\x12,\n\x10num_future_steps\x18\x03 \x01(\x05:\x0280R\x0enumFutureSteps\x129\n\x15max_roadgraph_samples\x18\x05 \x01(\x05:\x0530000R\x13maxRoadgraphSamples\x12;\n\x17source_polyline_spacing\x18\x06 \x01(\x01:\x030.5R\x15sourcePolylineSpacing\x129\n\x17polyline_sample_spacing\x18\x07 \x01(\x01:\x011R\x15polylineSampleSpacing\x127\n\x16polygon_sample_spacing\x18\x08 \x01(\x01:\x011R\x14polygonSampleSpacing\x12Z\n)max_traffic_light_control_points_per_step\x18\t \x01(\x05:\x0216R#maxTrafficLightControlPointsPerStep"

    max_num_agents: "int" = betterproto2.field(1, betterproto2.TYPE_INT32)
    """
    The maximum number of agents to populate in the tf.Example.
    """

    max_num_modeled_agents: "int" = betterproto2.field(10, betterproto2.TYPE_INT32)
    """
    The maximum number of modeled agents to populate in the tf.Example. This
    field should not be changed from 8 for open dataset motion challenge uses.
    """

    num_past_steps: "int" = betterproto2.field(2, betterproto2.TYPE_INT32)
    """
    The number of past steps (including the current step) in each trajectory.
    The defaults correspond to the open motion dataset data - 11 past steps
    (includes the current step), and 80 future steps). Changing these values
    will make the data incompatible with the open dataset motion challenges.
    """

    num_future_steps: "int" = betterproto2.field(3, betterproto2.TYPE_INT32)
    """
    The number of future steps in each trajectory.
    """

    max_roadgraph_samples: "int" = betterproto2.field(5, betterproto2.TYPE_INT32)
    """
    The maximum number of map points to store in each example. This defines
    the sizes of the roadgraph_samples/* tensors. Any additional samples
    in the source Scenario protos will be truncated. Lane centers and
    lane boundaries are prioritized over other types. This parameter along with
    the polyline_sample_spacing and polygon_sample_spacing fields will
    determine if points are truncated. For reference, in the current waymo open
    motion dataset the vast majority of Scenarios have less than 60,000 samples
    at 0.5m spacing (not including polygon samples). Only a few outliers exceed
    this where the largest has approximately 75,000 samples at 0.5m.
    """

    source_polyline_spacing: "float" = betterproto2.field(6, betterproto2.TYPE_DOUBLE)
    """
    The input source polyline sample spacing. Do not change this from the
    default when using open dataset input data.
    """

    polyline_sample_spacing: "float" = betterproto2.field(7, betterproto2.TYPE_DOUBLE)
    """
    The roadgraph points will be re-sampled with this spacing. Note that
    decreasing this parameter may require an increase in the
    max_roadgraph_samples parameter to avoid truncating roadgraph data.
    If this is set to <= 0, the value in source_polyline_spacing will be used.
    """

    polygon_sample_spacing: "float" = betterproto2.field(8, betterproto2.TYPE_DOUBLE)
    """
    Features like speed bumps and crosswalks are defined only by polygon
    corner points. If this value is > 0, samples along the sides of the
    polygons will be added, spaced apart by this value. If this value is <= 0,
    only the polygon vertices will be added as sample points. Note that
    decreasing this parameter may require an increase in the
    max_roadgraph_samples parameter to avoid truncating roadgraph data.
    """

    max_traffic_light_control_points_per_step: "int" = betterproto2.field(
        9, betterproto2.TYPE_INT32
    )
    """
    The maximum number of traffic light points per time step.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "MotionExampleConversionConfig", MotionExampleConversionConfig
)


@dataclass(eq=False, repr=False)
class MotionMetrics(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\rMotionMetrics\x12P\n\x0fmetrics_bundles\x18\x01 \x03(\x0b2'.waymo.open_dataset.MotionMetricsBundleR\x0emetricsBundles"

    metrics_bundles: "list[MotionMetricsBundle]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    A set of metrics broken down by measurement time step and object type.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "MotionMetrics", MotionMetrics
)


@dataclass(eq=False, repr=False)
class MotionMetricsBundle(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x13MotionMetricsBundle\x12I\n\robject_filter\x18\x07 \x01(\x0e2$.waymo.open_dataset.Track.ObjectTypeR\x0cobjectFilter\x12)\n\x10measurement_step\x18\x06 \x01(\x05R\x0fmeasurementStep\x12\x17\n\x07min_ade\x18\x01 \x01(\x02R\x06minAde\x12\x17\n\x07min_fde\x18\x02 \x01(\x02R\x06minFde\x12\x1b\n\tmiss_rate\x18\x03 \x01(\x02R\x08missRate\x12!\n\x0coverlap_rate\x18\x04 \x01(\x02R\x0boverlapRate\x124\n\x16mean_average_precision\x18\x05 \x01(\x02R\x14meanAveragePrecision\x12=\n\x1bsoft_mean_average_precision\x18\x08 \x01(\x02R\x18softMeanAveragePrecision\x12a\n\x0ecustom_metrics\x18\t \x03(\x0b2:.waymo.open_dataset.MotionMetricsBundle.CustomMetricsEntryR\rcustomMetrics\x1a@\n\x12CustomMetricsEntry\x12\x10\n\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n\x05value\x18\x02 \x01(\x02R\x05value:\x028\x01"

    object_filter: "TrackObjectType" = betterproto2.field(
        7, betterproto2.TYPE_ENUM, default_factory=lambda: TrackObjectType(0)
    )
    """
    The object type these metrics were filtered by. All metrics below are
    only for this type of object. If not set, the metrics are aggregated for
    all types.
    """

    measurement_step: "int" = betterproto2.field(6, betterproto2.TYPE_INT32)
    """
    The prediction time step used to compute the metrics. The metrics are
    computed as if this was the last time step in the trajectory.
    """

    min_ade: "float" = betterproto2.field(1, betterproto2.TYPE_FLOAT)
    """
    For each object, the average difference from the ground truth in meters is
    computed up to the measurement time step is computed for all trajectory
    predictions for that object. The value with the minimum error is kept
    (minADE). The resulting values are accumulated for all predicted objects in
    all scenarios.
    """

    min_fde: "float" = betterproto2.field(2, betterproto2.TYPE_FLOAT)
    """
    For each object the error for a given trajectory at the measurement time
    step is computed for all trajectory predictions for that objects. The value
    with the minimum error is kept (minFDE). The mean of all measurements in
    the accumulator is the average minFDE.
    """

    miss_rate: "float" = betterproto2.field(3, betterproto2.TYPE_FLOAT)
    """
    The miss rate is calculated by computing the displacement from ground truth
    at the measurement time step. If the displacement is greater than the miss
    rate threshold it is considered a miss. The number of misses for all
    objects divided by the total number of objects is equal to the miss rate.
    """

    overlap_rate: "float" = betterproto2.field(4, betterproto2.TYPE_FLOAT)
    """
    Overlaps are detected as any intersection of the bounding boxes of the
    highest confidence predicted object trajectory with those of any other
    valid object at the same time step for time steps up to the measurement
    time step. Only objects that were valid at the prediction time step are
    considered. If one or more overlaps occur up to the measurement step it
    is considered a single overlap measurement. The total number of
    overlaps divided by the total number of objects is equal to the overall
    overlap rate.
    """

    mean_average_precision: "float" = betterproto2.field(5, betterproto2.TYPE_FLOAT)
    """
    The mAP metric is computed by accumulating true and false positive
    measurements based on thresholding the FDE at the measurement time step
    over all object predictions. The measurements are separated into buckets
    based on the trajectory shape. The mean average precision of each bucket is
    computed as described in "The PASCAL Visual Object Classes (VOC) Challenge"
    (Everingham, 2009, p. 11). using the newer method that includes all samples
    in the computation consistent with the current PASCAL challenge metrics.
    The mean of the AP value across all trajectory shape buckets is equal to
    this mAP value.
    """

    soft_mean_average_precision: "float" = betterproto2.field(
        8, betterproto2.TYPE_FLOAT
    )
    """
    Same as mean_average_precision but duplicate true positives per ground
    truth trajectory are ignored rather than counted as false positives.
    """

    custom_metrics: "dict[str, float]" = betterproto2.field(
        9,
        betterproto2.TYPE_MAP,
        map_types=(betterproto2.TYPE_STRING, betterproto2.TYPE_FLOAT),
    )
    """
    Custom metrics (those not already included above) can be stored in the
    following map, identified by name.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "MotionMetricsBundle", MotionMetricsBundle
)


@dataclass(eq=False, repr=False)
class MotionMetricsConfig(betterproto2.Message):
    """
    Configuration to compute motion metrics.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x13MotionMetricsConfig\x127\n\x16track_steps_per_second\x18\x01 \x01(\x05:\x0210R\x13trackStepsPerSecond\x12@\n\x1bprediction_steps_per_second\x18\x02 \x01(\x05:\x012R\x18predictionStepsPerSecond\x126\n\x15track_history_samples\x18\x03 \x01(\x05:\x0210R\x13trackHistorySamples\x124\n\x14track_future_samples\x18\x04 \x01(\x05:\x0280R\x12trackFutureSamples\x12/\n\x11speed_lower_bound\x18\x05 \x01(\x02:\x031.4R\x0fspeedLowerBound\x12.\n\x11speed_upper_bound\x18\x06 \x01(\x02:\x0211R\x0fspeedUpperBound\x12/\n\x11speed_scale_lower\x18\x07 \x01(\x02:\x030.5R\x0fspeedScaleLower\x12-\n\x11speed_scale_upper\x18\x08 \x01(\x02:\x011R\x0fspeedScaleUpper\x12n\n\x13step_configurations\x18\t \x03(\x0b2=.waymo.open_dataset.MotionMetricsConfig.MeasurementStepConfigR\x12stepConfigurations\x12*\n\x0fmax_predictions\x18\n \x01(\x05:\x016R\x0emaxPredictions\x1a\xcc\x01\n)MotionMetricsConfig.MeasurementStepConfig\x12)\n\x10measurement_step\x18\x01 \x01(\x05R\x0fmeasurementStep\x124\n\x16lateral_miss_threshold\x18\x02 \x01(\x02R\x14lateralMissThreshold\x12>\n\x1blongitudinal_miss_threshold\x18\x03 \x01(\x02R\x19longitudinalMissThreshold"

    track_steps_per_second: "int" = betterproto2.field(1, betterproto2.TYPE_INT32)
    """
    The sampling rates for the scenario track data and the prediction data. The
    track sampling must be an integer multiple of the prediction sampling.
    """

    prediction_steps_per_second: "int" = betterproto2.field(2, betterproto2.TYPE_INT32)

    track_history_samples: "int" = betterproto2.field(3, betterproto2.TYPE_INT32)
    """
    The number of samples for both the history and the future track data.
    Tracks must be of length track_history_samples + track_future_samples + 1
    (one extra for the current time step).
    Predictions must be length (track_history_samples + track_future_samples) *
    prediction_steps_per_second / track_steps_per_second (current time is not
    included in the predictions).
    IMPORTANT: Note that the first element of the prediction corresponds to
    time (1.0 / prediction_steps_per_second) NOT time 0.
    """

    track_future_samples: "int" = betterproto2.field(4, betterproto2.TYPE_INT32)

    speed_lower_bound: "float" = betterproto2.field(5, betterproto2.TYPE_FLOAT)
    """
    Parameters for miss rate and mAP threshold scaling as a function of the
    object initial speed. If the object speed is below speed_lower_bound, the
    scale factor for the thresholds will equal speed_scale_lower. Above
    speed_upper_bound, the scale factor will equal speed_scale_upper. In
    between the two bounds, the scale factor will be interpolated linearly
    between the lower and upper scale factors. Both the lateral and
    longitudinal displacement thresholds for miss rate and mAP will be scaled
    by this factor before the thresholds are applied.
    """

    speed_upper_bound: "float" = betterproto2.field(6, betterproto2.TYPE_FLOAT)

    speed_scale_lower: "float" = betterproto2.field(7, betterproto2.TYPE_FLOAT)

    speed_scale_upper: "float" = betterproto2.field(8, betterproto2.TYPE_FLOAT)

    step_configurations: "list[MotionMetricsConfigMeasurementStepConfig]" = (
        betterproto2.field(9, betterproto2.TYPE_MESSAGE, repeated=True)
    )
    """
    The prediction samples and parameters used to compute metrics at a specific
    time step. Time in seconds can be computed as (measurement_step + 1) /
    prediction_steps_per_second. Metrics are computed for each step in the list
    as if the given measurement_step were the last step in the predicted
    trajectory.
    """

    max_predictions: "int" = betterproto2.field(10, betterproto2.TYPE_INT32)
    """
    The maximum number of predictions to use as K in all min over K metrics
    computations.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "MotionMetricsConfig", MotionMetricsConfig
)


@dataclass(eq=False, repr=False)
class MotionMetricsConfigMeasurementStepConfig(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n)MotionMetricsConfig.MeasurementStepConfig\x12)\n\x10measurement_step\x18\x01 \x01(\x05R\x0fmeasurementStep\x124\n\x16lateral_miss_threshold\x18\x02 \x01(\x02R\x14lateralMissThreshold\x12>\n\x1blongitudinal_miss_threshold\x18\x03 \x01(\x02R\x19longitudinalMissThreshold"

    measurement_step: "int" = betterproto2.field(1, betterproto2.TYPE_INT32)
    """
    The prediction step to use to measure all metrics. The metrics are
    computed as if this were the last step in the predicted trajectory. Time
    in seconds can be computed as (measurement_step + 1) /
    prediction_steps_per_second.
    """

    lateral_miss_threshold: "float" = betterproto2.field(2, betterproto2.TYPE_FLOAT)
    """
    The threshold for lateral distance error in meters for miss rate and mAP
    computations.
    """

    longitudinal_miss_threshold: "float" = betterproto2.field(
        3, betterproto2.TYPE_FLOAT
    )
    """
    The threshold for longitudinal distance error in meters for miss rate and
    mAP computations.
    """


default_message_pool.register_message(
    "waymo.open_dataset",
    "MotionMetricsConfig.MeasurementStepConfig",
    MotionMetricsConfigMeasurementStepConfig,
)


@dataclass(eq=False, repr=False)
class MultimodalPrediction(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x14MultimodalPrediction\x12R\n\x11joint_predictions\x18\x01 \x03(\x0b2%.waymo.open_dataset.JointTrajectoriesR\x10jointPredictions"

    joint_predictions: "list[JointTrajectories]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    A set of predictions (or joint predictions) with varying confidences - all
    for the same object or group of objects. All prediction entries must
    contain trajectories for the same set of objects or an error will be
    returned. Any predictions past the max number of predictions set in the
    metrics config will be discarded.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "MultimodalPrediction", MultimodalPrediction
)


@dataclass(eq=False, repr=False)
class NoLabelZoneObject(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b'\n\x11NoLabelZoneObject\x126\n\x04zone\x18\x01 \x01(\x0b2".waymo.open_dataset.Polygon2dProtoR\x04zone\x12!\n\x0ccontext_name\x18\x02 \x01(\tR\x0bcontextName\x124\n\x16frame_timestamp_micros\x18\x03 \x01(\x03R\x14frameTimestampMicros'

    zone: "Polygon2DProto | None" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, optional=True
    )

    context_name: "str" = betterproto2.field(2, betterproto2.TYPE_STRING)

    frame_timestamp_micros: "int" = betterproto2.field(3, betterproto2.TYPE_INT64)


default_message_pool.register_message(
    "waymo.open_dataset", "NoLabelZoneObject", NoLabelZoneObject
)


@dataclass(eq=False, repr=False)
class Object(betterproto2.Message):
    """
    This is a wrapper on waymo.open_dataset.Label. We have another proto
    to add more information such as class confidence for metrics computation.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x06Object\x121\n\x06object\x18\x01 \x01(\x0b2\x19.waymo.open_dataset.LabelR\x06object\x12\x17\n\x05score\x18\x02 \x01(\x02:\x011R\x05score\x12(\n\x10overlap_with_nlz\x18\x03 \x01(\x08R\x0eoverlapWithNlz\x12!\n\x0ccontext_name\x18\x04 \x01(\tR\x0bcontextName\x124\n\x16frame_timestamp_micros\x18\x05 \x01(\x03R\x14frameTimestampMicros\x12D\n\x0bcamera_name\x18\x06 \x01(\x0e2#.waymo.open_dataset.CameraName.NameR\ncameraName"

    object: "Label | None" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, optional=True
    )

    score: "float" = betterproto2.field(2, betterproto2.TYPE_FLOAT)
    """
    The confidence within [0, 1] of the prediction. Defaults to 1.0 for
    ground truths.
    """

    overlap_with_nlz: "bool" = betterproto2.field(3, betterproto2.TYPE_BOOL)
    """
    Whether this object overlaps with any NLZ (no label zone).
    Users do not need to set this field when evaluating on the eval leaderboard
    as the leaderboard does this computation.
    """

    context_name: "str" = betterproto2.field(4, betterproto2.TYPE_STRING)
    """
    These must be set when evaluating on the leaderboard.
    This should be set to Context.name defined in
    dataset.proto::Context.
    """

    frame_timestamp_micros: "int" = betterproto2.field(5, betterproto2.TYPE_INT64)
    """
    This should be set to Frame.timestamp_micros defined in
    dataset.proto::Frame.
    """

    camera_name: "CameraNameName" = betterproto2.field(
        6, betterproto2.TYPE_ENUM, default_factory=lambda: CameraNameName(0)
    )
    """
    Optionally, if this object is used for camera image labels or predictions,
    this needs to be populated to uniquely identify which image this object is
    for.
    """


default_message_pool.register_message("waymo.open_dataset", "Object", Object)


@dataclass(eq=False, repr=False)
class Objects(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x07Objects\x124\n\x07objects\x18\x01 \x03(\x0b2\x1a.waymo.open_dataset.ObjectR\x07objects\x12X\n\x15no_label_zone_objects\x18\x02 \x03(\x0b2%.waymo.open_dataset.NoLabelZoneObjectR\x12noLabelZoneObjects"

    objects: "list[Object]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )

    no_label_zone_objects: "list[NoLabelZoneObject]" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    Users do not need to set this when evaluating on the leaderboard.
    """


default_message_pool.register_message("waymo.open_dataset", "Objects", Objects)


@dataclass(eq=False, repr=False)
class ObjectState(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x0bObjectState\x12\x19\n\x08center_x\x18\x02 \x01(\x01R\x07centerX\x12\x19\n\x08center_y\x18\x03 \x01(\x01R\x07centerY\x12\x19\n\x08center_z\x18\x04 \x01(\x01R\x07centerZ\x12\x16\n\x06length\x18\x05 \x01(\x02R\x06length\x12\x14\n\x05width\x18\x06 \x01(\x02R\x05width\x12\x16\n\x06height\x18\x07 \x01(\x02R\x06height\x12\x18\n\x07heading\x18\x08 \x01(\x02R\x07heading\x12\x1d\n\nvelocity_x\x18\t \x01(\x02R\tvelocityX\x12\x1d\n\nvelocity_y\x18\n \x01(\x02R\tvelocityY\x12\x14\n\x05valid\x18\x0b \x01(\x08R\x05valid"

    center_x: "float" = betterproto2.field(2, betterproto2.TYPE_DOUBLE)
    """
    Coordinates of the center of the object bounding box.
    """

    center_y: "float" = betterproto2.field(3, betterproto2.TYPE_DOUBLE)

    center_z: "float" = betterproto2.field(4, betterproto2.TYPE_DOUBLE)

    length: "float" = betterproto2.field(5, betterproto2.TYPE_FLOAT)
    """
    The dimensions of the bounding box in meters.
    """

    width: "float" = betterproto2.field(6, betterproto2.TYPE_FLOAT)

    height: "float" = betterproto2.field(7, betterproto2.TYPE_FLOAT)

    heading: "float" = betterproto2.field(8, betterproto2.TYPE_FLOAT)
    """
    The yaw angle in radians of the forward direction of the bounding box (the
    vector from the center of the box to the middle of the front box segment)
    counter clockwise from the X-axis (right hand system about the Z axis).
    This angle is normalized to [-pi, pi).
    """

    velocity_x: "float" = betterproto2.field(9, betterproto2.TYPE_FLOAT)
    """
    The velocity vector in m/s. This vector direction may be slightly different
    from the heading of the bounding box.
    """

    velocity_y: "float" = betterproto2.field(10, betterproto2.TYPE_FLOAT)

    valid: "bool" = betterproto2.field(11, betterproto2.TYPE_BOOL)
    """
    False if the state data is invalid or missing.
    """


default_message_pool.register_message("waymo.open_dataset", "ObjectState", ObjectState)


@dataclass(eq=False, repr=False)
class ObjectTrajectory(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x10ObjectTrajectory\x12\x1b\n\tobject_id\x18\x01 \x01(\x05R\x08objectId\x12>\n\ntrajectory\x18\x02 \x01(\x0b2\x1e.waymo.open_dataset.TrajectoryR\ntrajectory"

    object_id: "int" = betterproto2.field(1, betterproto2.TYPE_INT32)
    """
    The ID of the object being predicted. This must match the object_id field
    in the test or validation set tf.Example or scenario proto corresponding to
    this prediction. Note this must be the same as the object_id in the
    scenario track or the state/id field in the tf.Example, not the track
    index.
    """

    trajectory: "Trajectory | None" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    The trajectory for the object.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "ObjectTrajectory", ObjectTrajectory
)


@dataclass(eq=False, repr=False)
class OccupancyFlowMetrics(betterproto2.Message):
    """
    Occupancy and flow metrics averaged over all prediction waypoints.
    Please refer to occupancy_flow_metrics.py for an implementation of these
    metrics.
    """

    @staticmethod
    def _serialized_pb():
        return b'\n\x14OccupancyFlowMetrics\x12S\n%num_waypoints_with_observed_occupancy\x18\x08 \x01(\x05:\x010R!numWaypointsWithObservedOccupancy\x12S\n%num_waypoints_with_occluded_occupancy\x18\t \x01(\x05:\x010R!numWaypointsWithOccludedOccupancy\x128\n\x17num_waypoints_with_flow\x18\n \x01(\x05:\x010R\x14numWaypointsWithFlow\x122\n\x15vehicles_observed_auc\x18\x01 \x01(\x02R\x13vehiclesObservedAuc\x122\n\x15vehicles_observed_iou\x18\x02 \x01(\x02R\x13vehiclesObservedIou\x122\n\x15vehicles_occluded_auc\x18\x03 \x01(\x02R\x13vehiclesOccludedAuc\x122\n\x15vehicles_occluded_iou\x18\x04 \x01(\x02R\x13vehiclesOccludedIou\x12*\n\x11vehicles_flow_epe\x18\x05 \x01(\x02R\x0fvehiclesFlowEpe\x12J\n"vehicles_flow_warped_occupancy_auc\x18\x06 \x01(\x02R\x1evehiclesFlowWarpedOccupancyAuc\x12J\n"vehicles_flow_warped_occupancy_iou\x18\x07 \x01(\x02R\x1evehiclesFlowWarpedOccupancyIou'

    num_waypoints_with_observed_occupancy: "int" = betterproto2.field(
        8, betterproto2.TYPE_INT32
    )
    """
    The metrics stored in this proto are averages over all waypoints.  However,
    blank waypoints, which contain no occupancy or flow ground-truth, are
    excluded when computing the metrics.  The following fields record the
    number of waypoints which are used for computing each of the 3 categories
    of metrics.
    """

    num_waypoints_with_occluded_occupancy: "int" = betterproto2.field(
        9, betterproto2.TYPE_INT32
    )

    num_waypoints_with_flow: "int" = betterproto2.field(10, betterproto2.TYPE_INT32)

    vehicles_observed_auc: "float" = betterproto2.field(1, betterproto2.TYPE_FLOAT)
    """
    Treating occupancy in each grid cell as an independent binary prediction,
    this metric measures the area under the precision-recall curve of all
    grid cells in the future occupancy of currently-observed vehicles.
    """

    vehicles_observed_iou: "float" = betterproto2.field(2, betterproto2.TYPE_FLOAT)
    """
    Measures the soft intersection-over-union between ground-truth bounding
    boxes and predicted future occupancy grids of currently-observed vehicles.
    """

    vehicles_occluded_auc: "float" = betterproto2.field(3, betterproto2.TYPE_FLOAT)
    """
    Same as above, but for currently-occluded vehicles.
    NOTE: All agents in future timesteps are divided into the two categories
    (currently-observed and currently-occluded) depending on whether the agent
    is present (valid) at the current timestep.  Agents which are not valid
    at the current time, but become valid later are considered currently-
    occluded.  The model is expected to predict the two categories separately,
    and the occupancy metrics are also computed separately for the two
    categories.
    """

    vehicles_occluded_iou: "float" = betterproto2.field(4, betterproto2.TYPE_FLOAT)

    vehicles_flow_epe: "float" = betterproto2.field(5, betterproto2.TYPE_FLOAT)
    """
    End-point-error between ground-truth and predicted flow fields, averaged
    over all cells in the grid.  Flow end-point-error measures the Euclidean
    distance between the predicted and ground-truth flow vectors.
    """

    vehicles_flow_warped_occupancy_auc: "float" = betterproto2.field(
        6, betterproto2.TYPE_FLOAT
    )
    """
    The flow-warped occupancy metrics verify correctness of both predicted
    flow fields and predicted occupancy grids.

    Here is how the flow-warped occupancy metrics are computed for waypoint k:

    Let:
    ~O^b_k denote the predicted occupancy at waypoint k of observed vehicles,
    ~O^c_k denote the predicted occupancy at waypoint k of occluded vehicles,
    O^b_k denote the ground-truth occupancy at waypoint k of observed vehicles,
    O^c_k denote the ground-truth occupancy at waypoint k of occluded vehicles,
    ~F_k denote the predicted flow between waypoints k - 1 and k.

    First, we compute the ground-truth occupancy of all vehicles (currently
    observed or occluded) at waypoint k as

    O_k = O^b_k + O^c_k

    and at waypoint k - 1 as

    O_{k-1} = O^b_{k-1} + O^c_{k-1}.

    We also compute the predicted occupancy of all vehicles as

    ~O_k = ~O^b_k + ~O^c_k.

    If the predicted occupancies are accurate, we should have ~O_k == O_k.  The
    occupancy metrics defined above already evaluate this expectation.  To
    ensure correctness of predicted flow, ~F_k, we use it to warp the origin
    ground-truth occupancy of that flow field (O_{k-1}) as

    ~W_k = ~F_k o O_{k-1},

    where o indicates function application -- applying the flow field as a
    function to transform the occupancy.  If the predicted flow is accurate, it
    should be able to reach and cover the future occupancy O_k.  Note that
    since we predict backward flow fields, ~W_k may predict expansion of
    occupancy in different directions and reach a larger area beyond O_k.
    Therefore we multiply ~W_k element-wise with ~O_k, to get

    ~W_k * ~O_k.

    If the predicted occupancy and flow at waypoint k are accurate, this term
    should be equal to the ground-truth O_k.  In other words, for a grid cell
    to be marked as occupied in ~W_k * ~O_k, it should be supported by both
    occupancy and flow predictions.  Therefore, the flow-warped metrics compute
    AUC and Soft-IoU between ~W_k * ~O_k and ground-truth O_k.
    """

    vehicles_flow_warped_occupancy_iou: "float" = betterproto2.field(
        7, betterproto2.TYPE_FLOAT
    )


default_message_pool.register_message(
    "waymo.open_dataset", "OccupancyFlowMetrics", OccupancyFlowMetrics
)


@dataclass(eq=False, repr=False)
class OccupancyFlowTaskConfig(betterproto2.Message):
    """
    Configuration for all parameters defining the occupancy flow task.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x17OccupancyFlowTaskConfig\x12(\n\x0enum_past_steps\x18\x01 \x01(\x05:\x0210R\x0cnumPastSteps\x12,\n\x10num_future_steps\x18\x02 \x01(\x05:\x0280R\x0enumFutureSteps\x12&\n\rnum_waypoints\x18\x03 \x01(\x05:\x018R\x0cnumWaypoints\x128\n\x14cumulative_waypoints\x18\x04 \x01(\x08:\x05falseR\x13cumulativeWaypoints\x120\n\x11normalize_sdc_yaw\x18\x0c \x01(\x08:\x04trueR\x0fnormalizeSdcYaw\x12/\n\x11grid_height_cells\x18\x05 \x01(\x05:\x03256R\x0fgridHeightCells\x12-\n\x10grid_width_cells\x18\x06 \x01(\x05:\x03256R\x0egridWidthCells\x12&\n\rsdc_y_in_grid\x18\x07 \x01(\x05:\x03192R\nsdcYInGrid\x12&\n\rsdc_x_in_grid\x18\x08 \x01(\x05:\x03128R\nsdcXInGrid\x12-\n\x10pixels_per_meter\x18\t \x01(\x02:\x033.2R\x0epixelsPerMeter\x12B\n\x1cagent_points_per_side_length\x18\n \x01(\x05:\x0248R\x18agentPointsPerSideLength\x12@\n\x1bagent_points_per_side_width\x18\x0b \x01(\x05:\x0216R\x17agentPointsPerSideWidth"

    num_past_steps: "int" = betterproto2.field(1, betterproto2.TYPE_INT32)
    """
    The following default values reflect the size of sequences in the Waymo
    Open Motion Dataset.
    """

    num_future_steps: "int" = betterproto2.field(2, betterproto2.TYPE_INT32)

    num_waypoints: "int" = betterproto2.field(3, betterproto2.TYPE_INT32)
    """
    -- PREDICTION SIZE --

    Number of predicted waypoints (snapshots over time) for each scene.  The
    waypoints uniformly divide the future timesteps (num_future_steps) into
    num_waypoints equal intervals.
    """

    cumulative_waypoints: "bool" = betterproto2.field(4, betterproto2.TYPE_BOOL)
    """
    When cumulative_waypoints is false, ground-truth waypoints are created by
    sampling individual timesteps from the future timesteps.  For example,
    for num_futures_steps = 80 and num_waypoints = 8, ground-truth occupancy is
    taken from timesteps {10, 20, 30, ..., 80}, and ground-truth flow fields
    are constructed from the displacements between timesteps
    {0 -> 10, 10 -> 20, ..., 70 -> 80} where 0 is the current time and 1-80 are
    the future timesteps.

    When cumulative_waypoints is true, ground-truth waypoints are created by
    aggregating occupancy and flow over all the timesteps that fall inside
    each waypoint.  For example, the last waypoint's occupancy is constructed
    by accumulating occupancy over timesteps [71, 72, ..., 80] and the last
    waypoint's flow field is constructed by averaging all 10 flow fields
    between timesteps [61 -> 71, 62 -> 72, ..., 70 -> 80].

    The code provided in occupancy_flow_data.py implements the above logic to
    construct the ground truth.
    """

    normalize_sdc_yaw: "bool" = betterproto2.field(12, betterproto2.TYPE_BOOL)
    """
    -- PREDICTION RESOLUTION AND SCALE --

    Whether to rotate the scene such that the SDC is heading up in ground-truth
    grids.
    """

    grid_height_cells: "int" = betterproto2.field(5, betterproto2.TYPE_INT32)
    """
    Occupancy grids are organized [grid_height_cells, grid_width_cells, 1].
    Flow fields are organized as [grid_height_cells, grid_width_cells, 2].
    """

    grid_width_cells: "int" = betterproto2.field(6, betterproto2.TYPE_INT32)

    sdc_y_in_grid: "int" = betterproto2.field(7, betterproto2.TYPE_INT32)
    """
    The ground-truth occupancy and flow for all future waypoints are rendered
    with reference to the location of the autonomous vehicle at the current
    time.  The autonomous vehicle's current location is mapped to the following
    coordinates.
    """

    sdc_x_in_grid: "int" = betterproto2.field(8, betterproto2.TYPE_INT32)

    pixels_per_meter: "float" = betterproto2.field(9, betterproto2.TYPE_FLOAT)
    """
    Prediction scale.  With a value of 3.2, the 256x256 grid covers an 80mx80m
    area of the world.
    """

    agent_points_per_side_length: "int" = betterproto2.field(
        10, betterproto2.TYPE_INT32
    )
    """
    Ground-truth occupancy grids are constructed by sampling the specified
    number of points along the length and width from the interior of agent
    boxes and scattering those points on the grid.  Similarly, ground-truth
    flow fields are constructed from the (dx, dy) displacements of such points
    over time.
    """

    agent_points_per_side_width: "int" = betterproto2.field(11, betterproto2.TYPE_INT32)


default_message_pool.register_message(
    "waymo.open_dataset", "OccupancyFlowTaskConfig", OccupancyFlowTaskConfig
)


@dataclass(eq=False, repr=False)
class Polygon2DProto(betterproto2.Message):
    """
    Non-self-intersecting 2d polygons. This polygon is not necessarily convex.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x0ePolygon2dProto\x12\x0c\n\x01x\x18\x01 \x03(\x01R\x01x\x12\x0c\n\x01y\x18\x02 \x03(\x01R\x01y\x12\x0e\n\x02id\x18\x03 \x01(\tR\x02id"

    x: "list[float]" = betterproto2.field(1, betterproto2.TYPE_DOUBLE, repeated=True)

    y: "list[float]" = betterproto2.field(2, betterproto2.TYPE_DOUBLE, repeated=True)

    id: "str" = betterproto2.field(3, betterproto2.TYPE_STRING)
    """
    A globally unique ID.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "Polygon2dProto", Polygon2DProto
)


@dataclass(eq=False, repr=False)
class PredictionSet(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\rPredictionSet\x12L\n\x0bpredictions\x18\x01 \x03(\x0b2*.waymo.open_dataset.SingleObjectPredictionR\x0bpredictions"

    predictions: "list[SingleObjectPrediction]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    A list of predictions for the required objects in the scene. These must
    exactly match the objects in the tracks_to_predict field of the test
    scenario or tf.Example.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "PredictionSet", PredictionSet
)


@dataclass(eq=False, repr=False)
class RangeImage(betterproto2.Message):
    """
    Range image is a 2d tensor. The first dim (row) represents pitch. The second
    dim represents yaw.
    There are two types of range images:
    1. Raw range image: Raw range image with a non-empty
      'range_image_pose_compressed' which tells the vehicle pose of each
      range image cell.
    2. Virtual range image: Range image with an empty
      'range_image_pose_compressed'. This range image is constructed by
      transforming all lidar points into a fixed vehicle frame (usually the
      vehicle frame of the middle scan).
    NOTE: 'range_image_pose_compressed' is only populated for the first range
    image return. The second return has the exact the same range image pose as
    the first one.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\nRangeImage\x124\n\x16range_image_compressed\x18\x02 \x01(\x0cR\x14rangeImageCompressed\x12@\n\x1ccamera_projection_compressed\x18\x03 \x01(\x0cR\x1acameraProjectionCompressed\x12=\n\x1brange_image_pose_compressed\x18\x04 \x01(\x0cR\x18rangeImagePoseCompressed\x12=\n\x1brange_image_flow_compressed\x18\x05 \x01(\x0cR\x18rangeImageFlowCompressed\x12B\n\x1dsegmentation_label_compressed\x18\x06 \x01(\x0cR\x1bsegmentationLabelCompressed\x12D\n\x0brange_image\x18\x01 \x01(\x0b2\x1f.waymo.open_dataset.MatrixFloatR\nrangeImageB\x02\x18\x01"

    range_image_compressed: "bytes" = betterproto2.field(2, betterproto2.TYPE_BYTES)
    """
    Zlib compressed [H, W, 4] serialized version of MatrixFloat.
    To decompress:
    string val = ZlibDecompress(range_image_compressed);
    MatrixFloat range_image;
    range_image.ParseFromString(val);
    Inner dimensions are:
      * channel 0: range
      * channel 1: intensity
      * channel 2: elongation
      * channel 3: is in any no label zone.
    """

    camera_projection_compressed: "bytes" = betterproto2.field(
        3, betterproto2.TYPE_BYTES
    )
    """
    Lidar point to camera image projections. A point can be projected to
    multiple camera images. We pick the first two at the following order:
    [FRONT, FRONT_LEFT, FRONT_RIGHT, SIDE_LEFT, SIDE_RIGHT].

    Zlib compressed [H, W, 6] serialized version of MatrixInt32.
    To decompress:
    string val = ZlibDecompress(camera_projection_compressed);
    MatrixInt32 camera_projection;
    camera_projection.ParseFromString(val);
    Inner dimensions are:
      * channel 0: CameraName.Name of 1st projection. Set to UNKNOWN if no
          projection.
      * channel 1: x (axis along image width)
      * channel 2: y (axis along image height)
      * channel 3: CameraName.Name of 2nd projection. Set to UNKNOWN if no
          projection.
      * channel 4: x (axis along image width)
      * channel 5: y (axis along image height)
    Note: pixel 0 corresponds to the left edge of the first pixel in the image.
    """

    range_image_pose_compressed: "bytes" = betterproto2.field(
        4, betterproto2.TYPE_BYTES
    )
    """
    Zlib compressed [H, W, 6] serialized version of MatrixFloat.
    To decompress:
    string val = ZlibDecompress(range_image_pose_compressed);
    MatrixFloat range_image_pose;
    range_image_pose.ParseFromString(val);
    Inner dimensions are [roll, pitch, yaw, x, y, z] represents a transform
    from vehicle frame to global frame for every range image pixel.
    This is ONLY populated for the first return. The second return is assumed
    to have exactly the same range_image_pose_compressed.

    The roll, pitch and yaw are specified as 3-2-1 Euler angle rotations,
    meaning that rotating from the navigation to vehicle frame consists of a
    yaw, then pitch and finally roll rotation about the z, y and x axes
    respectively. All rotations use the right hand rule and are positive
    in the counter clockwise direction.
    """

    range_image_flow_compressed: "bytes" = betterproto2.field(
        5, betterproto2.TYPE_BYTES
    )
    """
    Zlib compressed [H, W, 5] serialized version of MatrixFloat.
    To decompress:
    string val = ZlibDecompress(range_image_flow_compressed);
    MatrixFloat range_image_flow;
    range_image_flow.ParseFromString(val);
    Inner dimensions are [vx, vy, vz, pointwise class].

    If the point is not annotated with scene flow information, class is set
    to -1. A point is not annotated if it is in a no-label zone or if its label
    bounding box does not have a corresponding match in the previous frame,
    making it infeasible to estimate the motion of the point.
    Otherwise, (vx, vy, vz) are velocity along (x, y, z)-axis for this point
    and class is set to one of the following values:
     -1: no-flow-label, the point has no flow information.
      0:  unlabeled or "background,", i.e., the point is not contained in a
          bounding box.
      1: vehicle, i.e., the point corresponds to a vehicle label box.
      2: pedestrian, i.e., the point corresponds to a pedestrian label box.
      3: sign, i.e., the point corresponds to a sign label box.
      4: cyclist, i.e., the point corresponds to a cyclist label box.
    """

    segmentation_label_compressed: "bytes" = betterproto2.field(
        6, betterproto2.TYPE_BYTES
    )
    """
    Zlib compressed [H, W, 2] serialized version of MatrixInt32.
    To decompress:
    string val = ZlibDecompress(segmentation_label_compressed);
    MatrixInt32 segmentation_label.
    segmentation_label.ParseFromString(val);
    Inner dimensions are [instance_id, semantic_class].

    NOTE:
    1. Only TOP LiDAR has segmentation labels.
    2. Not every frame has segmentation labels. This field is not set if a
       frame is not labeled.
    3. There can be points missing segmentation labels within a labeled frame.
       Their label are set to TYPE_NOT_LABELED when that happens.
    """

    range_image: "MatrixFloat | None" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Deprecated, do not use.
    """

    def __post_init__(self) -> None:
        super().__post_init__()
        if self.is_set("range_image"):
            warnings.warn("RangeImage.range_image is deprecated", DeprecationWarning)


default_message_pool.register_message("waymo.open_dataset", "RangeImage", RangeImage)


@dataclass(eq=False, repr=False)
class RequiredPrediction(betterproto2.Message):
    """
    An object that must be predicted for the scenario.
    """

    @staticmethod
    def _serialized_pb():
        return b'\n\x12RequiredPrediction\x12\x1f\n\x0btrack_index\x18\x01 \x01(\x05R\ntrackIndex\x12V\n\ndifficulty\x18\x02 \x01(\x0e26.waymo.open_dataset.RequiredPrediction.DifficultyLevelR\ndifficulty"F\n"RequiredPrediction.DifficultyLevel\x12\x06\n\x04NONE\x12\x0b\n\x07LEVEL_1\x10\x01\x12\x0b\n\x07LEVEL_2\x10\x02'

    track_index: "int" = betterproto2.field(1, betterproto2.TYPE_INT32)
    """
    An index into the Scenario `tracks` field for the object to be predicted.
    """

    difficulty: "RequiredPredictionDifficultyLevel" = betterproto2.field(
        2,
        betterproto2.TYPE_ENUM,
        default_factory=lambda: RequiredPredictionDifficultyLevel(0),
    )
    """
    The difficulty level for this object.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "RequiredPrediction", RequiredPrediction
)


@dataclass(eq=False, repr=False)
class RoadEdge(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b'\n\x08RoadEdge\x12=\n\x04type\x18\x01 \x01(\x0e2).waymo.open_dataset.RoadEdge.RoadEdgeTypeR\x04type\x128\n\x08polyline\x18\x02 \x03(\x0b2\x1c.waymo.open_dataset.MapPointR\x08polyline"_\n\x15RoadEdge.RoadEdgeType\x12\x0e\n\x0cTYPE_UNKNOWN\x12\x1b\n\x17TYPE_ROAD_EDGE_BOUNDARY\x10\x01\x12\x19\n\x15TYPE_ROAD_EDGE_MEDIAN\x10\x02'

    type: "RoadEdgeRoadEdgeType" = betterproto2.field(
        1, betterproto2.TYPE_ENUM, default_factory=lambda: RoadEdgeRoadEdgeType(0)
    )
    """
    The type of road edge.
    """

    polyline: "list[MapPoint]" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The polyline defining the road edge. A polyline is a list of points with
    segments defined between consecutive points.
    """


default_message_pool.register_message("waymo.open_dataset", "RoadEdge", RoadEdge)


@dataclass(eq=False, repr=False)
class RoadLine(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b'\n\x08RoadLine\x12=\n\x04type\x18\x01 \x01(\x0e2).waymo.open_dataset.RoadLine.RoadLineTypeR\x04type\x128\n\x08polyline\x18\x02 \x03(\x0b2\x1c.waymo.open_dataset.MapPointR\x08polyline"\x99\x02\n\x15RoadLine.RoadLineType\x12\x0e\n\x0cTYPE_UNKNOWN\x12\x1c\n\x18TYPE_BROKEN_SINGLE_WHITE\x10\x01\x12\x1b\n\x17TYPE_SOLID_SINGLE_WHITE\x10\x02\x12\x1b\n\x17TYPE_SOLID_DOUBLE_WHITE\x10\x03\x12\x1d\n\x19TYPE_BROKEN_SINGLE_YELLOW\x10\x04\x12\x1d\n\x19TYPE_BROKEN_DOUBLE_YELLOW\x10\x05\x12\x1c\n\x18TYPE_SOLID_SINGLE_YELLOW\x10\x06\x12\x1c\n\x18TYPE_SOLID_DOUBLE_YELLOW\x10\x07\x12\x1e\n\x1aTYPE_PASSING_DOUBLE_YELLOW\x10\x08'

    type: "RoadLineRoadLineType" = betterproto2.field(
        1, betterproto2.TYPE_ENUM, default_factory=lambda: RoadLineRoadLineType(0)
    )
    """
    The type of the lane boundary.
    """

    polyline: "list[MapPoint]" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The polyline defining the road edge. A polyline is a list of points with
    segments defined between consecutive points.
    """


default_message_pool.register_message("waymo.open_dataset", "RoadLine", RoadLine)


@dataclass(eq=False, repr=False)
class Scenario(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x08Scenario\x12\x1f\n\x0bscenario_id\x18\x05 \x01(\tR\nscenarioId\x12-\n\x12timestamps_seconds\x18\x01 \x03(\x01R\x11timestampsSeconds\x12,\n\x12current_time_index\x18\n \x01(\x05R\x10currentTimeIndex\x121\n\x06tracks\x18\x02 \x03(\x0b2\x19.waymo.open_dataset.TrackR\x06tracks\x12Q\n\x12dynamic_map_states\x18\x07 \x03(\x0b2#.waymo.open_dataset.DynamicMapStateR\x10dynamicMapStates\x12A\n\x0cmap_features\x18\x08 \x03(\x0b2\x1e.waymo.open_dataset.MapFeatureR\x0bmapFeatures\x12&\n\x0fsdc_track_index\x18\x06 \x01(\x05R\rsdcTrackIndex\x12.\n\x13objects_of_interest\x18\x04 \x03(\x05R\x11objectsOfInterest\x12R\n\x11tracks_to_predict\x18\x0b \x03(\x0b2&.waymo.open_dataset.RequiredPredictionR\x0ftracksToPredict\x12k\n\x1bcompressed_frame_laser_data\x18\x0c \x03(\x0b2,.waymo.open_dataset.CompressedFrameLaserDataR\x18compressedFrameLaserData\x12U\n\x13frame_camera_tokens\x18\r \x03(\x0b2%.waymo.open_dataset.FrameCameraTokensR\x11frameCameraTokensJ\x04\x08\t\x10\n"

    scenario_id: "str" = betterproto2.field(5, betterproto2.TYPE_STRING)
    """
    The unique ID for this scenario.
    """

    timestamps_seconds: "list[float]" = betterproto2.field(
        1, betterproto2.TYPE_DOUBLE, repeated=True
    )
    """
    Timestamps corresponding to the track states for each step in the scenario.
    The length of this field is equal to tracks[i].states_size() for all tracks
    i and equal to the length of the dynamic_map_states_field.
    """

    current_time_index: "int" = betterproto2.field(10, betterproto2.TYPE_INT32)
    """
    The index into timestamps_seconds for the current time. All time steps
    after this index are future data to be predicted. All steps before this
    index are history data.
    """

    tracks: "list[Track]" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    Tracks for all objects in the scenario. All object tracks in all scenarios
    in the dataset have the same number of object states. In this way, the
    tracks field forms a 2 dimensional grid with objects on one axis and time
    on the other. Each state can be associated with a timestamp in the
    'timestamps_seconds' field by its index. E.g., tracks[i].states[j] indexes
    the i^th agent's state at time timestamps_seconds[j].
    """

    dynamic_map_states: "list[DynamicMapState]" = betterproto2.field(
        7, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The dynamic map states in the scenario (e.g. traffic signal states).
    This field has the same length as timestamps_seconds. Each entry in this
    field can be associated with a timestamp in the 'timestamps_seconds' field
    by its index. E.g., dynamic_map_states[i] indexes the dynamic map state at
    time timestamps_seconds[i].
    """

    map_features: "list[MapFeature]" = betterproto2.field(
        8, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The set of static map features for the scenario.
    """

    sdc_track_index: "int" = betterproto2.field(6, betterproto2.TYPE_INT32)
    """
    The index into the tracks field of the autonomous vehicle object.
    """

    objects_of_interest: "list[int]" = betterproto2.field(
        4, betterproto2.TYPE_INT32, repeated=True
    )
    """
    A list of objects IDs in the scene detected to have interactive behavior.
    The objects in this list form an interactive group. These IDs correspond
    to IDs in the tracks field above.
    """

    tracks_to_predict: "list[RequiredPrediction]" = betterproto2.field(
        11, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    A list of tracks to generate predictions for. For the challenges, exactly
    these objects must be predicted in each scenario for test and validation
    submissions. This field is populated in the training set only as a
    suggestion of objects to train on.
    """

    compressed_frame_laser_data: "list[CompressedFrameLaserData]" = betterproto2.field(
        12, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    Per time step Lidar data. This contains lidar up to the current time step
    such that compressed_frame_laser_data[i] corresponds to the states at
    timestamps_seconds[i] where i <= current_time_index.
    This field is not populated in all versions of the dataset.
    """

    frame_camera_tokens: "list[FrameCameraTokens]" = betterproto2.field(
        13, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    Per time step camera tokens. This contains camera tokens up to the current
    time step such that frame_camera_tokens[i] corresponds to the states at
    timestamps_seconds[i] where i <= current_time_index.
    This field is not populated in all versions of the dataset.
    """


default_message_pool.register_message("waymo.open_dataset", "Scenario", Scenario)


@dataclass(eq=False, repr=False)
class ScenarioPredictions(betterproto2.Message):
    """
    A set of predictions used for metrics evaluation.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x13ScenarioPredictions\x12\x1f\n\x0bscenario_id\x18\x01 \x01(\tR\nscenarioId\x12`\n\x17multi_modal_predictions\x18\x02 \x03(\x0b2(.waymo.open_dataset.MultimodalPredictionR\x15multiModalPredictions"

    scenario_id: "str" = betterproto2.field(1, betterproto2.TYPE_STRING)
    """
    The unique ID of the scenario being predicted. This ID must match the
    scenario_id field in the test or validation set tf.Example or scenario
    proto corresponding to this set of predictions.
    """

    multi_modal_predictions: "list[MultimodalPrediction]" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The predictions for the scenario. These represent either single object
    predictions or joint predictions for a group of objects.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "ScenarioPredictions", ScenarioPredictions
)


@dataclass(eq=False, repr=False)
class ScenarioRollouts(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x10ScenarioRollouts\x12\x1f\n\x0bscenario_id\x18\x01 \x01(\tR\nscenarioId\x12A\n\x0cjoint_scenes\x18\x02 \x03(\x0b2\x1e.waymo.open_dataset.JointSceneR\x0bjointScenes"

    scenario_id: "str" = betterproto2.field(1, betterproto2.TYPE_STRING)
    """
    String ID of the original scenario proto used as initial conditions.
    """

    joint_scenes: "list[JointScene]" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    Collection of multiple `JointScene`s simulated from the same initial
    conditions (corresponding to the original Scenario proto). This needs to
    include exactly 32 parallel simulations.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "ScenarioRollouts", ScenarioRollouts
)


@dataclass(eq=False, repr=False)
class ScoredJointTrajectory(betterproto2.Message):
    """
    A message containing a prediction for either a single object or a joint
    prediction for a set of objects.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x15ScoredJointTrajectory\x12H\n\x0ctrajectories\x18\x02 \x03(\x0b2$.waymo.open_dataset.ObjectTrajectoryR\x0ctrajectories\x12\x1e\n\nconfidence\x18\x03 \x01(\x02R\nconfidence"

    trajectories: "list[ObjectTrajectory]" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The trajectories for the objects in the scenario being predicted. For the
    interactive challenge, this must contain exactly 2 trajectories
    for the pair of objects listed in the tracks_to_predict field of the
    Scenario or tf.Example proto.
    """

    confidence: "float" = betterproto2.field(3, betterproto2.TYPE_FLOAT)
    """
    An optional confidence measure for this joint prediction. These confidence
    scores should reflect confidence in the existence of the trajectory across
    scenes, not normalized within a scene or per-agent.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "ScoredJointTrajectory", ScoredJointTrajectory
)


@dataclass(eq=False, repr=False)
class ScoredTrajectory(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x10ScoredTrajectory\x12>\n\ntrajectory\x18\x01 \x01(\x0b2\x1e.waymo.open_dataset.TrajectoryR\ntrajectory\x12\x1e\n\nconfidence\x18\x02 \x01(\x02R\nconfidence"

    trajectory: "Trajectory | None" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    The object predicted trajectory.
    """

    confidence: "float" = betterproto2.field(2, betterproto2.TYPE_FLOAT)
    """
    An optional confidence measure for this joint prediction. These confidence
    scores should reflect confidence in the existence of the trajectory across
    scenes, not normalized within a scene or per-agent.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "ScoredTrajectory", ScoredTrajectory
)


@dataclass(eq=False, repr=False)
class Segmentation(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b'\n\x0cSegmentation"\xd0\x03\n\x11Segmentation.Type\x12\x10\n\x0eTYPE_UNDEFINED\x12\x0c\n\x08TYPE_CAR\x10\x01\x12\x0e\n\nTYPE_TRUCK\x10\x02\x12\x0c\n\x08TYPE_BUS\x10\x03\x12\x16\n\x12TYPE_OTHER_VEHICLE\x10\x04\x12\x15\n\x11TYPE_MOTORCYCLIST\x10\x05\x12\x12\n\x0eTYPE_BICYCLIST\x10\x06\x12\x13\n\x0fTYPE_PEDESTRIAN\x10\x07\x12\r\n\tTYPE_SIGN\x10\x08\x12\x16\n\x12TYPE_TRAFFIC_LIGHT\x10\t\x12\r\n\tTYPE_POLE\x10\n\x12\x1a\n\x16TYPE_CONSTRUCTION_CONE\x10\x0b\x12\x10\n\x0cTYPE_BICYCLE\x10\x0c\x12\x13\n\x0fTYPE_MOTORCYCLE\x10\r\x12\x11\n\rTYPE_BUILDING\x10\x0e\x12\x13\n\x0fTYPE_VEGETATION\x10\x0f\x12\x13\n\x0fTYPE_TREE_TRUNK\x10\x10\x12\r\n\tTYPE_CURB\x10\x11\x12\r\n\tTYPE_ROAD\x10\x12\x12\x14\n\x10TYPE_LANE_MARKER\x10\x13\x12\x15\n\x11TYPE_OTHER_GROUND\x10\x14\x12\x11\n\rTYPE_WALKABLE\x10\x15\x12\x11\n\rTYPE_SIDEWALK\x10\x16'

    pass


default_message_pool.register_message(
    "waymo.open_dataset", "Segmentation", Segmentation
)


@dataclass(eq=False, repr=False)
class SegmentationFrame(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x11SegmentationFrame\x12J\n\x13segmentation_labels\x18\x01 \x03(\x0b2\x19.waymo.open_dataset.LaserR\x12segmentationLabels\x12!\n\x0ccontext_name\x18\x02 \x01(\tR\x0bcontextName\x124\n\x16frame_timestamp_micros\x18\x03 \x01(\x03R\x14frameTimestampMicros"

    segmentation_labels: "list[Laser]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    Segmentation labels by lasers.
    """

    context_name: "str" = betterproto2.field(2, betterproto2.TYPE_STRING)
    """
    These must be set when evaluating on the leaderboard.
    This should be set to Context.name defined in
    dataset.proto::Context.
    """

    frame_timestamp_micros: "int" = betterproto2.field(3, betterproto2.TYPE_INT64)
    """
    This should be set to Frame.timestamp_micros defined in
    dataset.proto::Frame.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "SegmentationFrame", SegmentationFrame
)


@dataclass(eq=False, repr=False)
class SegmentationFrameList(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x15SegmentationFrameList\x12=\n\x06frames\x18\x01 \x03(\x0b2%.waymo.open_dataset.SegmentationFrameR\x06frames"

    frames: "list[SegmentationFrame]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )


default_message_pool.register_message(
    "waymo.open_dataset", "SegmentationFrameList", SegmentationFrameList
)


@dataclass(eq=False, repr=False)
class SegmentationMeasurements(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x18SegmentationMeasurements\x12$\n\rintersections\x18\x01 \x03(\x03R\rintersections\x12\x16\n\x06unions\x18\x02 \x03(\x03R\x06unions"

    intersections: "list[int]" = betterproto2.field(
        1, betterproto2.TYPE_INT64, repeated=True
    )
    """
    Stats for each class. The length of each field should be the num_class.
    The number of points with matching prediction and groundtruth for this
    class.
    """

    unions: "list[int]" = betterproto2.field(2, betterproto2.TYPE_INT64, repeated=True)
    """
    The total number of points for this class in both prediction and
    groundtruth.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "SegmentationMeasurements", SegmentationMeasurements
)


@dataclass(eq=False, repr=False)
class SegmentationMetrics(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x13SegmentationMetrics\x12\\\n\rper_class_iou\x18\x01 \x03(\x0b28.waymo.open_dataset.SegmentationMetrics.PerClassIouEntryR\x0bperClassIou\x12\x12\n\x04miou\x18\x02 \x01(\x02R\x04miou\x12i\n\x19segmentation_measurements\x18\x03 \x01(\x0b2,.waymo.open_dataset.SegmentationMeasurementsR\x18segmentationMeasurements\x1a>\n\x10PerClassIouEntry\x12\x10\n\x03key\x18\x01 \x01(\x05R\x03key\x12\x14\n\x05value\x18\x02 \x01(\x02R\x05value:\x028\x01"

    per_class_iou: "dict[int, float]" = betterproto2.field(
        1,
        betterproto2.TYPE_MAP,
        map_types=(betterproto2.TYPE_INT32, betterproto2.TYPE_FLOAT),
    )
    """
    Per class IOU (Intersection Over Union). Keyed by class index.
    """

    miou: "float" = betterproto2.field(2, betterproto2.TYPE_FLOAT)

    segmentation_measurements: "SegmentationMeasurements | None" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, optional=True
    )


default_message_pool.register_message(
    "waymo.open_dataset", "SegmentationMetrics", SegmentationMetrics
)


@dataclass(eq=False, repr=False)
class SegmentationMetricsConfig(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x19SegmentationMetricsConfig\x12X\n\x12segmentation_types\x18\x01 \x03(\x0e2%.waymo.open_dataset.Segmentation.TypeR\x11segmentationTypesB\x02\x10\x01"

    segmentation_types: "list[SegmentationType]" = betterproto2.field(
        1, betterproto2.TYPE_ENUM, repeated=True
    )
    """
    The list of segmentation_types to eval.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "SegmentationMetricsConfig", SegmentationMetricsConfig
)


@dataclass(eq=False, repr=False)
class SemanticSegmentationSubmission(betterproto2.Message):
    """
    If your inference results are too large to fit in one proto, you can shard
    them to multiple files by sharding the inference_results field.
    Next ID: 11.
    """

    @staticmethod
    def _serialized_pb():
        return b'\n\x1eSemanticSegmentationSubmission\x12!\n\x0caccount_name\x18\x01 \x01(\tR\x0baccountName\x12,\n\x12unique_method_name\x18\x02 \x01(\tR\x10uniqueMethodName\x12\x18\n\x07authors\x18\x03 \x03(\tR\x07authors\x12 \n\x0baffiliation\x18\x04 \x01(\tR\x0baffiliation\x12 \n\x0bdescription\x18\x05 \x01(\tR\x0bdescription\x12\x1f\n\x0bmethod_link\x18\x06 \x01(\tR\nmethodLink\x12^\n\x0bsensor_type\x18\x07 \x01(\x0e2=.waymo.open_dataset.SemanticSegmentationSubmission.SensorTypeR\nsensorType\x12J\n"number_past_frames_exclude_current\x18\x08 \x01(\x05R\x1enumberPastFramesExcludeCurrent\x12N\n$number_future_frames_exclude_current\x18\t \x01(\x05R numberFutureFramesExcludeCurrent\x12V\n\x11inference_results\x18\n \x01(\x0b2).waymo.open_dataset.SegmentationFrameListR\x10inferenceResults"\x90\x01\n)SemanticSegmentationSubmission.SensorType\x12\t\n\x07INVALID\x12\r\n\tLIDAR_ALL\x10\x01\x12\r\n\tLIDAR_TOP\x10\x02\x12\x0e\n\nCAMERA_ALL\x10\x03\x12\x14\n\x10CAMERA_LIDAR_TOP\x10\x04\x12\x14\n\x10CAMERA_LIDAR_ALL\x10\x05'

    account_name: "str" = betterproto2.field(1, betterproto2.TYPE_STRING)
    """
    This must be set as the full email used to register at waymo.com/open.
    """

    unique_method_name: "str" = betterproto2.field(2, betterproto2.TYPE_STRING)
    """
    This name needs to be short, descriptive and unique. Only the latest result
    of the method from a user will show up on the leaderboard.
    """

    authors: "list[str]" = betterproto2.field(
        3, betterproto2.TYPE_STRING, repeated=True
    )

    affiliation: "str" = betterproto2.field(4, betterproto2.TYPE_STRING)

    description: "str" = betterproto2.field(5, betterproto2.TYPE_STRING)

    method_link: "str" = betterproto2.field(6, betterproto2.TYPE_STRING)
    """
    Link to paper or other link that describes the method.
    """

    sensor_type: "SemanticSegmentationSubmissionSensorType" = betterproto2.field(
        7,
        betterproto2.TYPE_ENUM,
        default_factory=lambda: SemanticSegmentationSubmissionSensorType(0),
    )

    number_past_frames_exclude_current: "int" = betterproto2.field(
        8, betterproto2.TYPE_INT32
    )
    """
    Number of frames used.
    """

    number_future_frames_exclude_current: "int" = betterproto2.field(
        9, betterproto2.TYPE_INT32
    )

    inference_results: "SegmentationFrameList | None" = betterproto2.field(
        10, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Inference results.
    """


default_message_pool.register_message(
    "waymo.open_dataset",
    "SemanticSegmentationSubmission",
    SemanticSegmentationSubmission,
)


@dataclass(eq=False, repr=False)
class SimAgentMetrics(betterproto2.Message):
    """
    Aggregation (at the dataset-level or scenario-level) of the lower-level
    features into proper metrics.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x0fSimAgentMetrics\x12\x1f\n\x0bscenario_id\x18\x01 \x01(\tR\nscenarioId\x12\x1e\n\nmetametric\x18\x02 \x01(\x02R\nmetametric\x12<\n\x1aaverage_displacement_error\x18\x03 \x01(\x02R\x18averageDisplacementError\x12C\n\x1emin_average_displacement_error\x18\r \x01(\x02R\x1bminAverageDisplacementError\x126\n\x17linear_speed_likelihood\x18\x04 \x01(\x02R\x15linearSpeedLikelihood\x12D\n\x1elinear_acceleration_likelihood\x18\x05 \x01(\x02R\x1clinearAccelerationLikelihood\x128\n\x18angular_speed_likelihood\x18\x06 \x01(\x02R\x16angularSpeedLikelihood\x12F\n\x1fangular_acceleration_likelihood\x18\x07 \x01(\x02R\x1dangularAccelerationLikelihood\x12P\n%distance_to_nearest_object_likelihood\x18\x08 \x01(\x02R!distanceToNearestObjectLikelihood\x12F\n\x1fcollision_indication_likelihood\x18\t \x01(\x02R\x1dcollisionIndicationLikelihood\x12?\n\x1ctime_to_collision_likelihood\x18\n \x01(\x02R\x19timeToCollisionLikelihood\x12F\n distance_to_road_edge_likelihood\x18\x0b \x01(\x02R\x1cdistanceToRoadEdgeLikelihood\x12B\n\x1doffroad_indication_likelihood\x18\x0c \x01(\x02R\x1boffroadIndicationLikelihood\x128\n\x18simulated_collision_rate\x18\x0e \x01(\x02R\x16simulatedCollisionRate\x124\n\x16simulated_offroad_rate\x18\x0f \x01(\x02R\x14simulatedOffroadRate"

    scenario_id: "str" = betterproto2.field(1, betterproto2.TYPE_STRING)
    """
    If these metrics are at the scenario-level, specify the ID of the scenario
    they relate to. If not specified, represent the aggregation at the
    dataset level of the per-scenario metrics.
    """

    metametric: "float" = betterproto2.field(2, betterproto2.TYPE_FLOAT)
    """
    The meta-metric, i.e. the weighted aggregation of all the lower-level
    features. This score is used to rank the submissions for the Sim Agents
    challenge.
    """

    average_displacement_error: "float" = betterproto2.field(3, betterproto2.TYPE_FLOAT)
    """
    Average displacement error (average or minimum over simulations).
    """

    min_average_displacement_error: "float" = betterproto2.field(
        13, betterproto2.TYPE_FLOAT
    )

    linear_speed_likelihood: "float" = betterproto2.field(4, betterproto2.TYPE_FLOAT)
    """
    Dynamic features, i.e. speeds and accelerations.
    """

    linear_acceleration_likelihood: "float" = betterproto2.field(
        5, betterproto2.TYPE_FLOAT
    )

    angular_speed_likelihood: "float" = betterproto2.field(6, betterproto2.TYPE_FLOAT)

    angular_acceleration_likelihood: "float" = betterproto2.field(
        7, betterproto2.TYPE_FLOAT
    )

    distance_to_nearest_object_likelihood: "float" = betterproto2.field(
        8, betterproto2.TYPE_FLOAT
    )
    """
    Interactive features.
    """

    collision_indication_likelihood: "float" = betterproto2.field(
        9, betterproto2.TYPE_FLOAT
    )

    time_to_collision_likelihood: "float" = betterproto2.field(
        10, betterproto2.TYPE_FLOAT
    )

    distance_to_road_edge_likelihood: "float" = betterproto2.field(
        11, betterproto2.TYPE_FLOAT
    )
    """
    Map-based features: distance to road edge, offroad indication.
    """

    offroad_indication_likelihood: "float" = betterproto2.field(
        12, betterproto2.TYPE_FLOAT
    )

    simulated_collision_rate: "float" = betterproto2.field(14, betterproto2.TYPE_FLOAT)
    """
    Fraction of simulated objects that collide for at least one step with any
    other simulated object.
    """

    simulated_offroad_rate: "float" = betterproto2.field(15, betterproto2.TYPE_FLOAT)
    """
    Fraction of simulated objects that drive offroad for at least one step.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "SimAgentMetrics", SimAgentMetrics
)


@dataclass(eq=False, repr=False)
class SimAgentMetricsConfig(betterproto2.Message):
    """
    Configuration for the Sim Agents metrics.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x15SimAgentMetricsConfig\x12Z\n\x0clinear_speed\x18\x01 \x01(\x0b27.waymo.open_dataset.SimAgentMetricsConfig.FeatureConfigR\x0blinearSpeed\x12h\n\x13linear_acceleration\x18\x02 \x01(\x0b27.waymo.open_dataset.SimAgentMetricsConfig.FeatureConfigR\x12linearAcceleration\x12\\\n\rangular_speed\x18\x03 \x01(\x0b27.waymo.open_dataset.SimAgentMetricsConfig.FeatureConfigR\x0cangularSpeed\x12j\n\x14angular_acceleration\x18\x04 \x01(\x0b27.waymo.open_dataset.SimAgentMetricsConfig.FeatureConfigR\x13angularAcceleration\x12t\n\x1adistance_to_nearest_object\x18\x05 \x01(\x0b27.waymo.open_dataset.SimAgentMetricsConfig.FeatureConfigR\x17distanceToNearestObject\x12j\n\x14collision_indication\x18\x06 \x01(\x0b27.waymo.open_dataset.SimAgentMetricsConfig.FeatureConfigR\x13collisionIndication\x12c\n\x11time_to_collision\x18\x07 \x01(\x0b27.waymo.open_dataset.SimAgentMetricsConfig.FeatureConfigR\x0ftimeToCollision\x12j\n\x15distance_to_road_edge\x18\x08 \x01(\x0b27.waymo.open_dataset.SimAgentMetricsConfig.FeatureConfigR\x12distanceToRoadEdge\x12f\n\x12offroad_indication\x18\t \x01(\x0b27.waymo.open_dataset.SimAgentMetricsConfig.FeatureConfigR\x11offroadIndication\x1a\xb8\x03\n#SimAgentMetricsConfig.FeatureConfig\x12[\n\thistogram\x18\x01 \x01(\x0b2;.waymo.open_dataset.SimAgentMetricsConfig.HistogramEstimateH\x00R\thistogram\x12h\n\x0ekernel_density\x18\x02 \x01(\x0b2?.waymo.open_dataset.SimAgentMetricsConfig.KernelDensityEstimateH\x00R\rkernelDensity\x12[\n\tbernoulli\x18\x03 \x01(\x0b2;.waymo.open_dataset.SimAgentMetricsConfig.BernoulliEstimateH\x00R\tbernoulli\x123\n\x15independent_timesteps\x18\x04 \x01(\x08R\x14independentTimesteps\x12+\n\x11metametric_weight\x18\x05 \x01(\x02R\x10metametricWeightB\x0b\n\testimator\x1a\xc3\x01\n'SimAgentMetricsConfig.HistogramEstimate\x12\x17\n\x07min_val\x18\x01 \x01(\x02R\x06minVal\x12\x17\n\x07max_val\x18\x02 \x01(\x02R\x06maxVal\x12\x19\n\x08num_bins\x18\x03 \x01(\x05R\x07numBins\x12K\n\x1eadditive_smoothing_pseudocount\x18\x04 \x01(\x02:\x050.001R\x1cadditiveSmoothingPseudocount\x1aK\n+SimAgentMetricsConfig.KernelDensityEstimate\x12\x1c\n\tbandwidth\x18\x01 \x01(\x02R\tbandwidth\x1av\n'SimAgentMetricsConfig.BernoulliEstimate\x12K\n\x1eadditive_smoothing_pseudocount\x18\x04 \x01(\x02:\x050.001R\x1cadditiveSmoothingPseudocount"

    linear_speed: "SimAgentMetricsConfigFeatureConfig | None" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Dynamics features.
    """

    linear_acceleration: "SimAgentMetricsConfigFeatureConfig | None" = (
        betterproto2.field(2, betterproto2.TYPE_MESSAGE, optional=True)
    )

    angular_speed: "SimAgentMetricsConfigFeatureConfig | None" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, optional=True
    )

    angular_acceleration: "SimAgentMetricsConfigFeatureConfig | None" = (
        betterproto2.field(4, betterproto2.TYPE_MESSAGE, optional=True)
    )

    distance_to_nearest_object: "SimAgentMetricsConfigFeatureConfig | None" = (
        betterproto2.field(5, betterproto2.TYPE_MESSAGE, optional=True)
    )
    """
    Interactive features.
    """

    collision_indication: "SimAgentMetricsConfigFeatureConfig | None" = (
        betterproto2.field(6, betterproto2.TYPE_MESSAGE, optional=True)
    )

    time_to_collision: "SimAgentMetricsConfigFeatureConfig | None" = betterproto2.field(
        7, betterproto2.TYPE_MESSAGE, optional=True
    )

    distance_to_road_edge: "SimAgentMetricsConfigFeatureConfig | None" = (
        betterproto2.field(8, betterproto2.TYPE_MESSAGE, optional=True)
    )
    """
    Map-based features.
    """

    offroad_indication: "SimAgentMetricsConfigFeatureConfig | None" = (
        betterproto2.field(9, betterproto2.TYPE_MESSAGE, optional=True)
    )


default_message_pool.register_message(
    "waymo.open_dataset", "SimAgentMetricsConfig", SimAgentMetricsConfig
)


@dataclass(eq=False, repr=False)
class SimAgentMetricsConfigBernoulliEstimate(betterproto2.Message):
    """
    The Bernoulli estimator is used for boolean features, e.g. collision.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n'SimAgentMetricsConfig.BernoulliEstimate\x12K\n\x1eadditive_smoothing_pseudocount\x18\x04 \x01(\x02:\x050.001R\x1cadditiveSmoothingPseudocount"

    additive_smoothing_pseudocount: "float" = betterproto2.field(
        4, betterproto2.TYPE_FLOAT
    )
    """
    Additive smoothing to apply to the underlying 2-bins histogram, to avoid
    infinite values for empty bins.
    """


default_message_pool.register_message(
    "waymo.open_dataset",
    "SimAgentMetricsConfig.BernoulliEstimate",
    SimAgentMetricsConfigBernoulliEstimate,
)


@dataclass(eq=False, repr=False)
class SimAgentMetricsConfigFeatureConfig(betterproto2.Message):
    """
    Each of the features used to evaluated sim-agents has one of the following
    configs.

    Oneofs:
        - estimator: To estimate the likelihood of the logged features under the
            simulated distribution of features, an approximator of such distribution
            is needed. For continuous values we support histogram-based and
            kernel-density-based estimators.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n#SimAgentMetricsConfig.FeatureConfig\x12[\n\thistogram\x18\x01 \x01(\x0b2;.waymo.open_dataset.SimAgentMetricsConfig.HistogramEstimateH\x00R\thistogram\x12h\n\x0ekernel_density\x18\x02 \x01(\x0b2?.waymo.open_dataset.SimAgentMetricsConfig.KernelDensityEstimateH\x00R\rkernelDensity\x12[\n\tbernoulli\x18\x03 \x01(\x0b2;.waymo.open_dataset.SimAgentMetricsConfig.BernoulliEstimateH\x00R\tbernoulli\x123\n\x15independent_timesteps\x18\x04 \x01(\x08R\x14independentTimesteps\x12+\n\x11metametric_weight\x18\x05 \x01(\x02R\x10metametricWeightB\x0b\n\testimator"

    histogram: "SimAgentMetricsConfigHistogramEstimate | None" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, optional=True, group="estimator"
    )

    kernel_density: "SimAgentMetricsConfigKernelDensityEstimate | None" = (
        betterproto2.field(
            2, betterproto2.TYPE_MESSAGE, optional=True, group="estimator"
        )
    )

    bernoulli: "SimAgentMetricsConfigBernoulliEstimate | None" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, optional=True, group="estimator"
    )

    independent_timesteps: "bool" = betterproto2.field(4, betterproto2.TYPE_BOOL)
    """
    Based on this flag, the distribution of simulated features will be
    aggregated over time to approximate one single (per-scenario, per-object)
    distribution instead of `N_STEP` per-step distributions.
    Example: When using `independent_timesteps=False` for speed, each logged
    step will be evaluated under the speed distribution of the 32 parallel
    simulations at that specific step.
    When `independent_timesteps=True`, each logged step will be evaluated
    against the same distribution over all the steps (32 * 80 total samples).
    """

    metametric_weight: "float" = betterproto2.field(5, betterproto2.TYPE_FLOAT)
    """
    For each of the features, we extract a likelihood score in the range
    [0,1]. The meta-metric (i.e. how all the submission are finally scored
    and ranked) is just a weighted average of these scores.
    """


default_message_pool.register_message(
    "waymo.open_dataset",
    "SimAgentMetricsConfig.FeatureConfig",
    SimAgentMetricsConfigFeatureConfig,
)


@dataclass(eq=False, repr=False)
class SimAgentMetricsConfigHistogramEstimate(betterproto2.Message):
    """
    Configuration for the histogram-based likelihood estimation.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n'SimAgentMetricsConfig.HistogramEstimate\x12\x17\n\x07min_val\x18\x01 \x01(\x02R\x06minVal\x12\x17\n\x07max_val\x18\x02 \x01(\x02R\x06maxVal\x12\x19\n\x08num_bins\x18\x03 \x01(\x05R\x07numBins\x12K\n\x1eadditive_smoothing_pseudocount\x18\x04 \x01(\x02:\x050.001R\x1cadditiveSmoothingPseudocount"

    min_val: "float" = betterproto2.field(1, betterproto2.TYPE_FLOAT)
    """
    Extremes on which the histogram is defined. The default configuration
    provided for the challenge has these values carefully set based on
    ground truth data. Any user submission exceeding these thresholds will be
    clipped, resulting in lower score for the submission.
    """

    max_val: "float" = betterproto2.field(2, betterproto2.TYPE_FLOAT)

    num_bins: "int" = betterproto2.field(3, betterproto2.TYPE_INT32)
    """
    Number of bins for the histogram to be discretized into.
    """

    additive_smoothing_pseudocount: "float" = betterproto2.field(
        4, betterproto2.TYPE_FLOAT
    )
    """
    Additive smoothing to apply to the histogram, to avoid infinite values
    when 1+ bins are empty.
    """


default_message_pool.register_message(
    "waymo.open_dataset",
    "SimAgentMetricsConfig.HistogramEstimate",
    SimAgentMetricsConfigHistogramEstimate,
)


@dataclass(eq=False, repr=False)
class SimAgentMetricsConfigKernelDensityEstimate(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n+SimAgentMetricsConfig.KernelDensityEstimate\x12\x1c\n\tbandwidth\x18\x01 \x01(\x02R\tbandwidth"

    bandwidth: "float" = betterproto2.field(1, betterproto2.TYPE_FLOAT)
    """
    Bandwidth for the Kernel Density estimation. For more details,
    check sklearn documentation:
    https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html
    This field needs to be set and needs to be strictly positive, otherwise
    an error is raised at runtime.
    """


default_message_pool.register_message(
    "waymo.open_dataset",
    "SimAgentMetricsConfig.KernelDensityEstimate",
    SimAgentMetricsConfigKernelDensityEstimate,
)


@dataclass(eq=False, repr=False)
class SimAgentsBucketedMetrics(betterproto2.Message):
    """
    Bucketed version of the sim agent metrics. This aggregated message is used
    in the challenge leaderboard to provide an easy to read but still informative
    metric output format.
    All the bucketed metrics are rescaled to be in the range [0, 1], but still
    according to the meta-metric weights defined in the metrics config.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\x18SimAgentsBucketedMetrics\x12.\n\x13realism_meta_metric\x18\x01 \x01(\x02R\x11realismMetaMetric\x12+\n\x11kinematic_metrics\x18\x02 \x01(\x02R\x10kinematicMetrics\x12/\n\x13interactive_metrics\x18\x05 \x01(\x02R\x12interactiveMetrics\x12*\n\x11map_based_metrics\x18\x06 \x01(\x02R\x0fmapBasedMetrics\x12\x17\n\x07min_ade\x18\x07 \x01(\x02R\x06minAde\x128\n\x18simulated_collision_rate\x18\x08 \x01(\x02R\x16simulatedCollisionRate\x124\n\x16simulated_offroad_rate\x18\t \x01(\x02R\x14simulatedOffroadRate"

    realism_meta_metric: "float" = betterproto2.field(1, betterproto2.TYPE_FLOAT)
    """
    Realism meta-metric.
    """

    kinematic_metrics: "float" = betterproto2.field(2, betterproto2.TYPE_FLOAT)
    """
    Kinematic metrics: a linear combination of the kinematic-related
    likelihoods, namely `linear_speed`, `linear_acceleration`, `angular_speed`
    and `angular_acceleration`.
    """

    interactive_metrics: "float" = betterproto2.field(5, betterproto2.TYPE_FLOAT)
    """
    Interactive metrics: a linear combination of the object-interaction
    likelihoods, namely `distance_to_nearest_object`, `collision_indication`
    and `time_to_collision`.
    """

    map_based_metrics: "float" = betterproto2.field(6, betterproto2.TYPE_FLOAT)
    """
    Map-based metrics: a linear combination of the map-related likelihoods,
    namely `distance_to_road_edge` and `offroad_indication`.
    """

    min_ade: "float" = betterproto2.field(7, betterproto2.TYPE_FLOAT)
    """
    MinADE.
    """

    simulated_collision_rate: "float" = betterproto2.field(8, betterproto2.TYPE_FLOAT)
    """
    Fraction of simulated objects that collide for at least one step with any
    other simulated object.
    """

    simulated_offroad_rate: "float" = betterproto2.field(9, betterproto2.TYPE_FLOAT)
    """
    Fraction of simulated objects that drive offroad for at least one step.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "SimAgentsBucketedMetrics", SimAgentsBucketedMetrics
)


@dataclass(eq=False, repr=False)
class SimAgentsChallengeSubmission(betterproto2.Message):
    """
    Message packaging a full submission to the challenge.
    """

    @staticmethod
    def _serialized_pb():
        return b'\n\x1cSimAgentsChallengeSubmission\x12Q\n\x11scenario_rollouts\x18\x01 \x03(\x0b2$.waymo.open_dataset.ScenarioRolloutsR\x10scenarioRollouts\x12h\n\x0fsubmission_type\x18\x02 \x01(\x0e2?.waymo.open_dataset.SimAgentsChallengeSubmission.SubmissionTypeR\x0esubmissionType\x12!\n\x0caccount_name\x18\x03 \x01(\tR\x0baccountName\x12,\n\x12unique_method_name\x18\x04 \x01(\tR\x10uniqueMethodName\x12\x18\n\x07authors\x18\x05 \x03(\tR\x07authors\x12 \n\x0baffiliation\x18\x06 \x01(\tR\x0baffiliation\x12 \n\x0bdescription\x18\x07 \x01(\tR\x0bdescription\x12\x1f\n\x0bmethod_link\x18\x08 \x01(\tR\nmethodLink\x12&\n\x0fuses_lidar_data\x18\t \x01(\x08R\rusesLidarData\x12(\n\x10uses_camera_data\x18\n \x01(\x08R\x0eusesCameraData\x12A\n\x1duses_public_model_pretraining\x18\x0b \x01(\x08R\x1ausesPublicModelPretraining\x12,\n\x12public_model_names\x18\r \x03(\tR\x10publicModelNames\x120\n\x14num_model_parameters\x18\x0c \x01(\tR\x12numModelParameters\x12g\n1acknowledge_complies_with_closed_loop_requirement\x18\x0e \x01(\x08R,acknowledgeCompliesWithClosedLoopRequirement"S\n+SimAgentsChallengeSubmission.SubmissionType\x12\t\n\x07UNKNOWN\x12\x19\n\x15SIM_AGENTS_SUBMISSION\x10\x01'

    scenario_rollouts: "list[ScenarioRollouts]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The set of scenario rollouts to evaluate. One entry should exist for
    every record in the test set.
    """

    submission_type: "SimAgentsChallengeSubmissionSubmissionType" = betterproto2.field(
        2,
        betterproto2.TYPE_ENUM,
        default_factory=lambda: SimAgentsChallengeSubmissionSubmissionType(0),
    )
    """
    Identifier of the submission type. Has to be set for the submission to be
    valid.
    """

    account_name: "str" = betterproto2.field(3, betterproto2.TYPE_STRING)
    """
    This must be set as the full email used to register at waymo.com/open.
    """

    unique_method_name: "str" = betterproto2.field(4, betterproto2.TYPE_STRING)
    """
    This name needs to be short, descriptive and unique. Only the latest result
    of the method from a user will show up on the leaderboard.
    """

    authors: "list[str]" = betterproto2.field(
        5, betterproto2.TYPE_STRING, repeated=True
    )
    """
    Author information.
    """

    affiliation: "str" = betterproto2.field(6, betterproto2.TYPE_STRING)

    description: "str" = betterproto2.field(7, betterproto2.TYPE_STRING)
    """
    A brief description of the method.
    """

    method_link: "str" = betterproto2.field(8, betterproto2.TYPE_STRING)
    """
    Link to paper or other link that describes the method.
    """

    uses_lidar_data: "bool" = betterproto2.field(9, betterproto2.TYPE_BOOL)
    """
    Set this to true if your model uses the lidar data provided in the motion
    dataset. This field is now REQUIRED for a valid submission.
    """

    uses_camera_data: "bool" = betterproto2.field(10, betterproto2.TYPE_BOOL)
    """
    Set this to true if your model uses the camera data provided in the motion
    dataset. This field is now REQUIRED for a valid submission.
    """

    uses_public_model_pretraining: "bool" = betterproto2.field(
        11, betterproto2.TYPE_BOOL
    )
    """
    Set this to true if your model used publicly available open-source
    LLM/VLM(s) for pre-training. This field is now REQUIRED for a valid
    submission.
    """

    public_model_names: "list[str]" = betterproto2.field(
        13, betterproto2.TYPE_STRING, repeated=True
    )
    """
    If any open-source model was used, specify their names and configuration.
    """

    num_model_parameters: "str" = betterproto2.field(12, betterproto2.TYPE_STRING)
    """
    Specify an estimate of the number of parameters of the model used to
    generate this submission. The number must be specified as an integer number
    followed by a multiplier suffix (from the set [K, M, B, T, ...], e.g.
    "200K"). This field is now REQUIRED for a valid submission.
    """

    acknowledge_complies_with_closed_loop_requirement: "bool" = betterproto2.field(
        14, betterproto2.TYPE_BOOL
    )
    """
    Several submissions for the 2023 challenge did not comply with the
    closed-loop at 10Hz requirement we specified both on the website
    https://waymo.com/open/challenges/2024/sim-agents/ and the NeurIPS paper
    https://arxiv.org/abs/2305.12032, Section 3 "Task constraints". Please make
    sure your method complies with these rules before submitting, to ensure
    our leaderboard is fair.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "SimAgentsChallengeSubmission", SimAgentsChallengeSubmission
)


@dataclass(eq=False, repr=False)
class SimulatedTrajectory(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x13SimulatedTrajectory\x12\x1d\n\x08center_x\x18\x02 \x03(\x02R\x07centerXB\x02\x10\x01\x12\x1d\n\x08center_y\x18\x03 \x03(\x02R\x07centerYB\x02\x10\x01\x12\x1d\n\x08center_z\x18\x04 \x03(\x02R\x07centerZB\x02\x10\x01\x12\x1c\n\x07heading\x18\x05 \x03(\x02R\x07headingB\x02\x10\x01\x12\x1b\n\tobject_id\x18\x06 \x01(\x05R\x08objectId"

    center_x: "list[float]" = betterproto2.field(
        2, betterproto2.TYPE_FLOAT, repeated=True
    )
    """
    The simulated trajectory for a single object, including position and
    heading. The (x, y, z) coordinates identify the centroid of the modeled
    object, defined in the same coordinate frame as the original input
    scenario. Heading is defined in radians, counterclockwise from East.
    See https://waymo.com/open/data/motion/ for more info.
    The length of these fields must be exactly 80, encoding the 8 seconds of
    future simulation at the same frequency of the Scenario proto (10Hz).
    These objects will only be considered if they are valid at the
    `current_time_index` step (which is hardcoded to 10, with 0-indexing).
    These objects will be assumed to be valid for the whole duration of the
    simulation after `current_time_index`, maintaining the latest box sizes
    (width, length and height) observed in the original scenario at the
    `current_time_index`.
    """

    center_y: "list[float]" = betterproto2.field(
        3, betterproto2.TYPE_FLOAT, repeated=True
    )

    center_z: "list[float]" = betterproto2.field(
        4, betterproto2.TYPE_FLOAT, repeated=True
    )

    heading: "list[float]" = betterproto2.field(
        5, betterproto2.TYPE_FLOAT, repeated=True
    )

    object_id: "int" = betterproto2.field(6, betterproto2.TYPE_INT32)
    """
    ID of the object.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "SimulatedTrajectory", SimulatedTrajectory
)


@dataclass(eq=False, repr=False)
class SingleObjectPrediction(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x16SingleObjectPrediction\x12\x1b\n\tobject_id\x18\x01 \x01(\x05R\x08objectId\x12H\n\x0ctrajectories\x18\x02 \x03(\x0b2$.waymo.open_dataset.ScoredTrajectoryR\x0ctrajectories"

    object_id: "int" = betterproto2.field(1, betterproto2.TYPE_INT32)
    """
    The ID of the object being predicted. This must match the object_id field
    in the test or validation set tf.Example or scenario proto corresponding to
    this prediction. Note this must be the same as the object_id in the
    scenario track or the state/id field in the tf.Example, not the track
    index.
    """

    trajectories: "list[ScoredTrajectory]" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    A set of up to 6 trajectory predictions for this object with varying
    confidences. Any predictions past the first six will be discarded.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "SingleObjectPrediction", SingleObjectPrediction
)


@dataclass(eq=False, repr=False)
class SingleTrajectory(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x10SingleTrajectory\x12\x1b\n\tobject_id\x18\x01 \x01(\x05R\x08objectId\x12\x1d\n\x08center_x\x18\x02 \x03(\x02R\x07centerXB\x02\x10\x01\x12\x1d\n\x08center_y\x18\x03 \x03(\x02R\x07centerYB\x02\x10\x01"

    object_id: "int" = betterproto2.field(1, betterproto2.TYPE_INT32)
    """
    The ID of the object being predicted. This must match the object_id field
    in the test or validation set tf.Example or scenario proto corresponding to
    this prediction.
    """

    center_x: "list[float]" = betterproto2.field(
        2, betterproto2.TYPE_FLOAT, repeated=True
    )
    """
    The predicted trajectory positions.
    """

    center_y: "list[float]" = betterproto2.field(
        3, betterproto2.TYPE_FLOAT, repeated=True
    )


default_message_pool.register_message(
    "waymo.open_dataset", "SingleTrajectory", SingleTrajectory
)


@dataclass(eq=False, repr=False)
class SpeedBump(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\tSpeedBump\x126\n\x07polygon\x18\x01 \x03(\x0b2\x1c.waymo.open_dataset.MapPointR\x07polygon"

    polygon: "list[MapPoint]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The polygon defining the outline of the speed bump. The polygon is assumed
    to be closed (i.e. a segment exists between the last point and the first
    point).
    """


default_message_pool.register_message("waymo.open_dataset", "SpeedBump", SpeedBump)


@dataclass(eq=False, repr=False)
class StopSign(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x08StopSign\x12\x12\n\x04lane\x18\x01 \x03(\x03R\x04lane\x128\n\x08position\x18\x02 \x01(\x0b2\x1c.waymo.open_dataset.MapPointR\x08position"

    lane: "list[int]" = betterproto2.field(1, betterproto2.TYPE_INT64, repeated=True)
    """
    The IDs of lane features controlled by this stop sign.
    """

    position: "MapPoint | None" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    The position of the stop sign.
    """


default_message_pool.register_message("waymo.open_dataset", "StopSign", StopSign)


@dataclass(eq=False, repr=False)
class Submission(betterproto2.Message):
    """
    If your inference results are too large to fit in one proto, you can shard
    them to multiple files by sharding the inference_results field.
    Next ID: 17.
    """

    @staticmethod
    def _serialized_pb():
        return b'\n\nSubmission\x127\n\x04task\x18\x01 \x01(\x0e2#.waymo.open_dataset.Submission.TaskR\x04task\x12!\n\x0caccount_name\x18\r \x01(\tR\x0baccountName\x12,\n\x12unique_method_name\x18\x02 \x01(\tR\x10uniqueMethodName\x12\x18\n\x07authors\x18\x03 \x03(\tR\x07authors\x12 \n\x0baffiliation\x18\x04 \x01(\tR\x0baffiliation\x12 \n\x0bdescription\x18\x05 \x01(\tR\x0bdescription\x12\x1f\n\x0bmethod_link\x18\x06 \x01(\tR\nmethodLink\x12.\n\x13docker_image_source\x18\x10 \x01(\tR\x11dockerImageSource\x12J\n\x0bsensor_type\x18\x0c \x01(\x0e2).waymo.open_dataset.Submission.SensorTypeR\nsensorType\x12J\n"number_past_frames_exclude_current\x18\t \x01(\x05R\x1enumberPastFramesExcludeCurrent\x12N\n$number_future_frames_exclude_current\x18\n \x01(\x05R numberFutureFramesExcludeCurrent\x12H\n\x11inference_results\x18\x0b \x01(\x0b2\x1b.waymo.open_dataset.ObjectsR\x10inferenceResults\x12A\n\x0cobject_types\x18\x0e \x03(\x0e2\x1e.waymo.open_dataset.Label.TypeR\x0bobjectTypes\x12%\n\x0elatency_second\x18\x0f \x01(\x02R\rlatencySecond"\x97\x01\n\x0fSubmission.Task\x12\t\n\x07UNKNOWN\x12\x10\n\x0cDETECTION_2D\x10\x01\x12\x10\n\x0cDETECTION_3D\x10\x02\x12\x0f\n\x0bTRACKING_2D\x10\x03\x12\x0f\n\x0bTRACKING_3D\x10\x04\x12\x15\n\x11DOMAIN_ADAPTATION\x10\x05\x12\x1c\n\x18CAMERA_ONLY_DETECTION_3D\x10\x06"|\n\x15Submission.SensorType\x12\t\n\x07INVALID\x12\r\n\tLIDAR_ALL\x10\x01\x12\r\n\tLIDAR_TOP\x10\x02\x12\x0e\n\nCAMERA_ALL\x10\x03\x12\x14\n\x10CAMERA_LIDAR_TOP\x10\x04\x12\x14\n\x10CAMERA_LIDAR_ALL\x10\x05J\x04\x08\x07\x10\x08J\x04\x08\x08\x10\t'

    task: "SubmissionTask" = betterproto2.field(
        1, betterproto2.TYPE_ENUM, default_factory=lambda: SubmissionTask(0)
    )
    """
    This specifies which task this submission is for.
    """

    account_name: "str" = betterproto2.field(13, betterproto2.TYPE_STRING)
    """
    This must be set as the full email used to register at waymo.com/open.
    """

    unique_method_name: "str" = betterproto2.field(2, betterproto2.TYPE_STRING)
    """
    This name needs to be short, descriptive and unique. Only the latest result
    of the method from a user will show up on the leaderboard.
    """

    authors: "list[str]" = betterproto2.field(
        3, betterproto2.TYPE_STRING, repeated=True
    )

    affiliation: "str" = betterproto2.field(4, betterproto2.TYPE_STRING)

    description: "str" = betterproto2.field(5, betterproto2.TYPE_STRING)

    method_link: "str" = betterproto2.field(6, betterproto2.TYPE_STRING)
    """
    Link to paper or other link that describes the method.
    """

    docker_image_source: "str" = betterproto2.field(16, betterproto2.TYPE_STRING)
    """
    Link to the latency submission Docker image stored in Google Storage bucket
    or pushed to Google Container/Artifact Registry.
    Google Storage bucket example:
      gs://example_bucket_name/example_folder/example_docker_image.tar.gz
    Google Container/Artifact Registry example:
      us-west1-docker.pkg.dev/example-registry-name/example-folder/example-image@sha256:example-sha256-hash
    Follow latency/README.md to create a docker file.
    """

    sensor_type: "SubmissionSensorType" = betterproto2.field(
        12, betterproto2.TYPE_ENUM, default_factory=lambda: SubmissionSensorType(0)
    )

    number_past_frames_exclude_current: "int" = betterproto2.field(
        9, betterproto2.TYPE_INT32
    )
    """
    Number of frames used.
    """

    number_future_frames_exclude_current: "int" = betterproto2.field(
        10, betterproto2.TYPE_INT32
    )

    inference_results: "Objects | None" = betterproto2.field(
        11, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Inference results.
    """

    object_types: "list[LabelType]" = betterproto2.field(
        14, betterproto2.TYPE_ENUM, repeated=True
    )
    """
    Object types this submission contains. By default, we assume all types.
    """

    latency_second: "float" = betterproto2.field(15, betterproto2.TYPE_FLOAT)
    """
    Self-reported end to end inference latency in seconds. This is NOT shown on
    the leaderboard for now. But it is still recommended to set this. Do not
    confuse this with the `docker_image_source` field above. That is needed to
    evaluate your model latency on our server.
    """


default_message_pool.register_message("waymo.open_dataset", "Submission", Submission)


@dataclass(eq=False, repr=False)
class Track(betterproto2.Message):
    """
    The object states for a single object through the scenario.
    """

    @staticmethod
    def _serialized_pb():
        return b'\n\x05Track\x12\x0e\n\x02id\x18\x01 \x01(\x05R\x02id\x12E\n\x0bobject_type\x18\x02 \x01(\x0e2$.waymo.open_dataset.Track.ObjectTypeR\nobjectType\x127\n\x06states\x18\x03 \x03(\x0b2\x1f.waymo.open_dataset.ObjectStateR\x06states"i\n\x10Track.ObjectType\x12\x0c\n\nTYPE_UNSET\x12\x10\n\x0cTYPE_VEHICLE\x10\x01\x12\x13\n\x0fTYPE_PEDESTRIAN\x10\x02\x12\x10\n\x0cTYPE_CYCLIST\x10\x03\x12\x0e\n\nTYPE_OTHER\x10\x04'

    id: "int" = betterproto2.field(1, betterproto2.TYPE_INT32)
    """
    The unique ID of the object being tracked. The IDs start from zero and are
    non-negative.
    """

    object_type: "TrackObjectType" = betterproto2.field(
        2, betterproto2.TYPE_ENUM, default_factory=lambda: TrackObjectType(0)
    )
    """
    The type of object being tracked.
    """

    states: "list[ObjectState]" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    The object states through the track. States include the 3D bounding boxes
    and velocities.
    """


default_message_pool.register_message("waymo.open_dataset", "Track", Track)


@dataclass(eq=False, repr=False)
class TrackingMeasurement(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x13TrackingMeasurement\x12\x1d\n\nnum_misses\x18\x01 \x01(\x05R\tnumMisses\x12\x17\n\x07num_fps\x18\x02 \x01(\x05R\x06numFps\x12%\n\x0enum_mismatches\x18\x03 \x01(\x05R\rnumMismatches\x12#\n\rmatching_cost\x18\x04 \x01(\x01R\x0cmatchingCost\x12\x1f\n\x0bnum_matches\x18\x05 \x01(\x05R\nnumMatches\x12$\n\x0enum_objects_gt\x18\x06 \x01(\x05R\x0cnumObjectsGt\x12!\n\x0cscore_cutoff\x18\x07 \x01(\x02R\x0bscoreCutoff\x12I\n\x07details\x18\x08 \x03(\x0b2/.waymo.open_dataset.TrackingMeasurement.DetailsR\x07details\x1a\x95\x01\n\x1bTrackingMeasurement.Details\x12\x1e\n\x0bfp_pred_ids\x18\x01 \x03(\tR\tfpPredIds\x12\x1a\n\tfn_gt_ids\x18\x02 \x03(\tR\x07fnGtIds\x12\x1a\n\ttp_gt_ids\x18\x03 \x03(\tR\x07tpGtIds\x12\x1e\n\x0btp_pred_ids\x18\x04 \x03(\tR\ttpPredIds"

    num_misses: "int" = betterproto2.field(1, betterproto2.TYPE_INT32)
    """
    The number of misses (false negatives).
    """

    num_fps: "int" = betterproto2.field(2, betterproto2.TYPE_INT32)
    """
    The number of false positives.
    """

    num_mismatches: "int" = betterproto2.field(3, betterproto2.TYPE_INT32)
    """
    The number of mismatches.
    """

    matching_cost: "float" = betterproto2.field(4, betterproto2.TYPE_DOUBLE)
    """
    The sum of matching costs for all matched objects.
    """

    num_matches: "int" = betterproto2.field(5, betterproto2.TYPE_INT32)
    """
    Total number of matched objects.
    """

    num_objects_gt: "int" = betterproto2.field(6, betterproto2.TYPE_INT32)
    """
    Total number of ground truth objects (i.e. labeled objects).
    """

    score_cutoff: "float" = betterproto2.field(7, betterproto2.TYPE_FLOAT)
    """
    The score cutoff used to compute this measurement.
    """

    details: "list[TrackingMeasurementDetails]" = betterproto2.field(
        8, betterproto2.TYPE_MESSAGE, repeated=True
    )
    """
    If set, will include the ids of the fp/tp/fn objects. Each element
    corresponds to one frame of matching.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "TrackingMeasurement", TrackingMeasurement
)


@dataclass(eq=False, repr=False)
class TrackingMeasurementDetails(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x1bTrackingMeasurement.Details\x12\x1e\n\x0bfp_pred_ids\x18\x01 \x03(\tR\tfpPredIds\x12\x1a\n\tfn_gt_ids\x18\x02 \x03(\tR\x07fnGtIds\x12\x1a\n\ttp_gt_ids\x18\x03 \x03(\tR\x07tpGtIds\x12\x1e\n\x0btp_pred_ids\x18\x04 \x03(\tR\ttpPredIds"

    fp_pred_ids: "list[str]" = betterproto2.field(
        1, betterproto2.TYPE_STRING, repeated=True
    )
    """
    False positive prediction ids.
    """

    fn_gt_ids: "list[str]" = betterproto2.field(
        2, betterproto2.TYPE_STRING, repeated=True
    )
    """
    False negative ground truth ids.
    """

    tp_gt_ids: "list[str]" = betterproto2.field(
        3, betterproto2.TYPE_STRING, repeated=True
    )
    """
    True positive ground truth ids. Should be of the same length with
    tp_pr_ids, tp_ious. Each pair of ids of the same index correspond to
    the ids of ground truth object and prediction objects which are matched.
    """

    tp_pred_ids: "list[str]" = betterproto2.field(
        4, betterproto2.TYPE_STRING, repeated=True
    )
    """
    True positive prediction ids.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "TrackingMeasurement.Details", TrackingMeasurementDetails
)


@dataclass(eq=False, repr=False)
class TrackingMeasurements(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x14TrackingMeasurements\x12K\n\x0cmeasurements\x18\x01 \x03(\x0b2'.waymo.open_dataset.TrackingMeasurementR\x0cmeasurements\x12;\n\tbreakdown\x18\x02 \x01(\x0b2\x1d.waymo.open_dataset.BreakdownR\tbreakdown"

    measurements: "list[TrackingMeasurement]" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, repeated=True
    )

    breakdown: "Breakdown | None" = betterproto2.field(
        2, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    The breakdown this measurements are computed for.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "TrackingMeasurements", TrackingMeasurements
)


@dataclass(eq=False, repr=False)
class TrackingMetrics(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x0fTrackingMetrics\x12\x12\n\x04mota\x18\x01 \x01(\x02R\x04mota\x12\x12\n\x04motp\x18\x02 \x01(\x02R\x04motp\x12\x12\n\x04miss\x18\x03 \x01(\x02R\x04miss\x12\x1a\n\x08mismatch\x18\x04 \x01(\x02R\x08mismatch\x12\x0e\n\x02fp\x18\x05 \x01(\x02R\x02fp\x12$\n\x0enum_objects_gt\x18\t \x01(\x05R\x0cnumObjectsGt\x12!\n\x0cscore_cutoff\x18\x06 \x01(\x02R\x0bscoreCutoff\x12;\n\tbreakdown\x18\x07 \x01(\x0b2\x1d.waymo.open_dataset.BreakdownR\tbreakdown\x12L\n\x0cmeasurements\x18\x08 \x01(\x0b2(.waymo.open_dataset.TrackingMeasurementsR\x0cmeasurements"

    mota: "float" = betterproto2.field(1, betterproto2.TYPE_FLOAT)
    """
    Multiple object tracking accuracy (sum of miss, mismatch and fp).
    """

    motp: "float" = betterproto2.field(2, betterproto2.TYPE_FLOAT)
    """
    Multiple object tracking precision (matching_cost / num_matches).
    """

    miss: "float" = betterproto2.field(3, betterproto2.TYPE_FLOAT)
    """
    Miss ratio (num_misses / num_objects_gt).
    """

    mismatch: "float" = betterproto2.field(4, betterproto2.TYPE_FLOAT)
    """
    Mismatch ratio (num_mismatches / num_objects_gt).
    """

    fp: "float" = betterproto2.field(5, betterproto2.TYPE_FLOAT)
    """
    False positive ratio (num_fps / num_objects_gt).
    """

    num_objects_gt: "int" = betterproto2.field(9, betterproto2.TYPE_INT32)
    """
    Total number of ground truth objects (i.e. labeled objects).
    """

    score_cutoff: "float" = betterproto2.field(6, betterproto2.TYPE_FLOAT)

    breakdown: "Breakdown | None" = betterproto2.field(
        7, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    The breakdown this metrics are computed for.
    """

    measurements: "TrackingMeasurements | None" = betterproto2.field(
        8, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Raw measurements.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "TrackingMetrics", TrackingMetrics
)


@dataclass(eq=False, repr=False)
class TrafficSignalLaneState(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b'\n\x16TrafficSignalLaneState\x12\x12\n\x04lane\x18\x01 \x01(\x03R\x04lane\x12F\n\x05state\x18\x02 \x01(\x0e20.waymo.open_dataset.TrafficSignalLaneState.StateR\x05state\x12;\n\nstop_point\x18\x03 \x01(\x0b2\x1c.waymo.open_dataset.MapPointR\tstopPoint"\x85\x02\n\x1cTrafficSignalLaneState.State\x12\x14\n\x12LANE_STATE_UNKNOWN\x12\x19\n\x15LANE_STATE_ARROW_STOP\x10\x01\x12\x1c\n\x18LANE_STATE_ARROW_CAUTION\x10\x02\x12\x17\n\x13LANE_STATE_ARROW_GO\x10\x03\x12\x13\n\x0fLANE_STATE_STOP\x10\x04\x12\x16\n\x12LANE_STATE_CAUTION\x10\x05\x12\x11\n\rLANE_STATE_GO\x10\x06\x12\x1c\n\x18LANE_STATE_FLASHING_STOP\x10\x07\x12\x1f\n\x1bLANE_STATE_FLASHING_CAUTION\x10\x08'

    lane: "int" = betterproto2.field(1, betterproto2.TYPE_INT64)
    """
    The ID for the MapFeature corresponding to the lane controlled by this
    traffic signal state.
    """

    state: "TrafficSignalLaneStateState" = betterproto2.field(
        2,
        betterproto2.TYPE_ENUM,
        default_factory=lambda: TrafficSignalLaneStateState(0),
    )
    """
    The state of the traffic signal.
    """

    stop_point: "MapPoint | None" = betterproto2.field(
        3, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    The stopping point along the lane controlled by the traffic signal.
    This is the point where dynamic objects must stop when the signal is in a
    stop state.
    """


default_message_pool.register_message(
    "waymo.open_dataset", "TrafficSignalLaneState", TrafficSignalLaneState
)


@dataclass(eq=False, repr=False)
class Trajectory(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\nTrajectory\x12\x1d\n\x08center_x\x18\x02 \x03(\x02R\x07centerXB\x02\x10\x01\x12\x1d\n\x08center_y\x18\x03 \x03(\x02R\x07centerYB\x02\x10\x01"

    center_x: "list[float]" = betterproto2.field(
        2, betterproto2.TYPE_FLOAT, repeated=True
    )
    """
    The predicted trajectory positions.
    For the Waymo prediction challenges, these fields must be exactly
    length 16 - 8 seconds with 2 steps per second starting at timestamp 1.5
    (step 15) in the scenario.
    IMPORTANT: For the challenges, the first entry in each of these fields must
    correspond to time step 15 in the scenario NOT step 10 or 11 (i.e. the
    entries in these fields must correspond to steps 15, 20, 25, ... 85, 90 in
    the scenario).
    """

    center_y: "list[float]" = betterproto2.field(
        3, betterproto2.TYPE_FLOAT, repeated=True
    )


default_message_pool.register_message("waymo.open_dataset", "Trajectory", Trajectory)


@dataclass(eq=False, repr=False)
class Transform(betterproto2.Message):
    """
    4x4 row major transform matrix that tranforms 3d points from one frame to
    another.
    """

    @staticmethod
    def _serialized_pb():
        return b"\n\tTransform\x12\x1c\n\ttransform\x18\x01 \x03(\x01R\ttransform"

    transform: "list[float]" = betterproto2.field(
        1, betterproto2.TYPE_DOUBLE, repeated=True
    )


default_message_pool.register_message("waymo.open_dataset", "Transform", Transform)


@dataclass(eq=False, repr=False)
class Vector2D(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x08Vector2d\x12\x0c\n\x01x\x18\x01 \x01(\x01R\x01x\x12\x0c\n\x01y\x18\x02 \x01(\x01R\x01y"

    x: "float" = betterproto2.field(1, betterproto2.TYPE_DOUBLE)

    y: "float" = betterproto2.field(2, betterproto2.TYPE_DOUBLE)


default_message_pool.register_message("waymo.open_dataset", "Vector2d", Vector2D)


@dataclass(eq=False, repr=False)
class Vector3D(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x08Vector3d\x12\x0c\n\x01x\x18\x01 \x01(\x01R\x01x\x12\x0c\n\x01y\x18\x02 \x01(\x01R\x01y\x12\x0c\n\x01z\x18\x03 \x01(\x01R\x01z"

    x: "float" = betterproto2.field(1, betterproto2.TYPE_DOUBLE)

    y: "float" = betterproto2.field(2, betterproto2.TYPE_DOUBLE)

    z: "float" = betterproto2.field(3, betterproto2.TYPE_DOUBLE)


default_message_pool.register_message("waymo.open_dataset", "Vector3d", Vector3D)


@dataclass(eq=False, repr=False)
class Velocity(betterproto2.Message):
    @staticmethod
    def _serialized_pb():
        return b"\n\x08Velocity\x12\x0f\n\x03v_x\x18\x01 \x01(\x02R\x02vX\x12\x0f\n\x03v_y\x18\x02 \x01(\x02R\x02vY\x12\x0f\n\x03v_z\x18\x03 \x01(\x02R\x02vZ\x12\x0f\n\x03w_x\x18\x04 \x01(\x01R\x02wX\x12\x0f\n\x03w_y\x18\x05 \x01(\x01R\x02wY\x12\x0f\n\x03w_z\x18\x06 \x01(\x01R\x02wZ"

    v_x: "float" = betterproto2.field(1, betterproto2.TYPE_FLOAT)
    """
    Velocity in m/s.
    """

    v_y: "float" = betterproto2.field(2, betterproto2.TYPE_FLOAT)

    v_z: "float" = betterproto2.field(3, betterproto2.TYPE_FLOAT)

    w_x: "float" = betterproto2.field(4, betterproto2.TYPE_DOUBLE)
    """
    Angular velocity in rad/s.
    """

    w_y: "float" = betterproto2.field(5, betterproto2.TYPE_DOUBLE)

    w_z: "float" = betterproto2.field(6, betterproto2.TYPE_DOUBLE)


default_message_pool.register_message("waymo.open_dataset", "Velocity", Velocity)


from . import keypoints
